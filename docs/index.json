[{"content":" Exercise Betrachten Sie folgendes Modell, das den Zusammenhang von PS-Zahl und Spritverbrauch untersucht (Datensatz mtcars).\nAber zuerst zentrieren wir den metrischen Prädiktor hp, um den Achsenabschnitt besser interpretieren zu können.\nmtcars \u0026lt;- mtcars %\u0026gt;% mutate(hp_z = hp - mean(hp)) library(rstanarm) lm1 \u0026lt;- stan_glm(mpg ~ hp_z, data = mtcars, refresh = 0) summary(lm1) Estimates: mean sd 10% 50% 90% (Intercept) 20.1 0.7 19.2 20.1 21.0 hp_z -0.1 0.0 -0.1 -0.1 -0.1 sigma 4.0 0.5 3.4 3.9 4.7  Jetzt können wir aus dem Achsenabschnitt (Intercept) herauslesen, dass ein Auto mit hp_z = 0 - also mit mittlerer PS-Zahl - vielleicht gut 20 Meilen weit mit einer Gallone Sprit kommt.\nZur Verdeutlichung ein Diagramm zum Modell:\nmtcars %\u0026gt;% ggplot() + aes(x = hp_z, y = mpg) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39; Adjustieren Sie im Modell die PS-Zahl um die Art des Schaltgetriebes (am), so dass das neue Modell den statistischen Effekt (nicht notwendig auch kausal) der PS-Zahl bereinigt bzw. unabhängig von der Art des Schaltgetriebes widerspiegelt!\nHinweise:\n am=0 ist ein Auto mit Automatikgetriebe. Wir gehen davon aus, dass der Regressionseffekt gleich stark ist auf allen (beiden) Stufen von am. M.a.W.: Es liegt kein Interaktionseffekt vor.           \n Solution library(rstanarm) lm2 \u0026lt;- stan_glm(mpg ~ hp_z + am, data = mtcars, refresh = 0) summary(lm2) Estimates: mean sd 10% 50% 90% (Intercept) 26.6 1.5 24.7 26.6 28.5 hp -0.1 0.0 -0.1 -0.1 0.0 am 5.3 1.1 3.8 5.3 6.6 sigma 3.0 0.4 2.5 3.0 3.5  Die Spalte mean gibt den mittleren geschätzten Wert für den jeweiligen Koeffizienten an, also den Schätzwert zum Koeffizienten.\nDie Koeffizienten zeigen, dass der Achsenabschnitt für Autos mit Automatikgetriebe um etwa 5 Meilen geringer ist als für Autos mit manueller Schaltung: Ein durchschnittliches Auto mit manueller Schaltung kommt also etwa 5 Meilen weiter als ein Auto mit Automatikschaltung, glaubt unser Modell.\nmtcars %\u0026gt;% mutate(am = factor(am)) %\u0026gt;% ggplot() + aes(x = hp_z, y = mpg, color = am) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39; Man könnte hier noch einen Interaktionseffekt ergänzen.\nCategories:\n qm2 qm2-thema01 ws22   ","permalink":"http://example.org/post/adjustieren1/adjustieren1/","summary":"Exercise Betrachten Sie folgendes Modell, das den Zusammenhang von PS-Zahl und Spritverbrauch untersucht (Datensatz mtcars).\nAber zuerst zentrieren wir den metrischen Prädiktor hp, um den Achsenabschnitt besser interpretieren zu können.\nmtcars \u0026lt;- mtcars %\u0026gt;% mutate(hp_z = hp - mean(hp)) library(rstanarm) lm1 \u0026lt;- stan_glm(mpg ~ hp_z, data = mtcars, refresh = 0) summary(lm1) Estimates: mean sd 10% 50% 90% (Intercept) 20.1 0.7 19.2 20.1 21.0 hp_z -0.1 0.0 -0.1 -0.1 -0.","title":"adjustieren1"},{"content":" Exercise Für Statistiken (Stichprobe) verwendet man meist lateinische Buchstaben; für Parameter (Population) verwendet man meist (die entsprechenden) griechischen Buchstaben.\nVervollständigen Sie folgende Tabelle entsprechend!\n  Kennwert Statistik Parameter    Mittelwert \\(\\bar{X}\\) NA  Mittelwertsdifferenz \\(\\bar{X}_1-\\bar{X}_2\\) NA  Streuung sd NA  Anteil p NA  Korrelation r NA  Regressionsgewicht b NA             \n Solution   Kennwert Statistik Parameter    Mittelwert \\[\\bar{X}\\] \\[\\mu\\]  Mittelwertsdifferenz \\[d=\\bar{X}_1-\\bar{X}_2\\] \\[\\mu_1\\]- \\[\\mu_2\\]  Streuung sd \\[\\sigma\\]  Anteil p \\[\\pi\\]  Korrelation r \\[\\rho\\]  Regressionsgewicht b \\[\\beta\\]    Categories:\n qm2 qm2-thema01   ","permalink":"http://example.org/post/griech-buchstaben/griech-buchstaben-inferenz/","summary":"Exercise Für Statistiken (Stichprobe) verwendet man meist lateinische Buchstaben; für Parameter (Population) verwendet man meist (die entsprechenden) griechischen Buchstaben.\nVervollständigen Sie folgende Tabelle entsprechend!\n  Kennwert Statistik Parameter    Mittelwert \\(\\bar{X}\\) NA  Mittelwertsdifferenz \\(\\bar{X}_1-\\bar{X}_2\\) NA  Streuung sd NA  Anteil p NA  Korrelation r NA  Regressionsgewicht b NA             \n Solution   Kennwert Statistik Parameter    Mittelwert \\[\\bar{X}\\] \\[\\mu\\]  Mittelwertsdifferenz \\[d=\\bar{X}_1-\\bar{X}_2\\] \\[\\mu_1\\]- \\[\\mu_2\\]  Streuung sd \\[\\sigma\\]  Anteil p \\[\\pi\\]  Korrelation r \\[\\rho\\]  Regressionsgewicht b \\[\\beta\\]    Categories:","title":"Griech-Buchstaben-Inferenz"},{"content":" Exercise Die Inferenzstatistik ist eine Sammlung an Verfahren zur Bemessung von Unsicherheit in statistischen Schlüssen.\nFür welche Statistiken - also Kennzahlen der Deskriptivstatistik wie etwa \\(\\bar{X}, sd, r\\) - kann man die Inferenzstatistik verwenden?\n Für welche Forschungsfragen oder -bereiche kann man die Inferenzstatistik verwenden?\n Gibt es besondere Fälle, in denen man nicht die Inferenzstatistik verwenden möchte? Wenn ja, welche?\n           \n Solution Für (grundsätzlich) alle: Für jede Statistik kann man prinzipiell von der jeweiligen Stichprobe (auf Basis derer die Statistik berechnet wurde) auf eine zugehörige Grundgesamtheit schließen.\n Für (grundsätzlich) alle: Die Methoden der Inferenzstatistik sind prinzipiell unabhängig von den Spezifika bestimmter Forschungsfragen oder -bereiche. In den meisten Forschungsfragen ist man daran interessiert allgemeingültige Aussagen zu treffen. Da Statistiken sich nur auf eine Stichprobe - also einen zumeist nur kleinen Teil einer Grundgesamtheit beziehen - wird man sich kaum mit einer Statistik zufrieden geben, sondern nach Inferenzstatistik verlangen.\n In einigen Ausnahmefällen wird man auf eine Inferenzstatistik verzichten. Etwa wenn man bereits eine Vollerhebung durchgeführt hat, z.B. alle Mitarbeitis eines Unternehmens befragt hat, dann kennt man ja bereits den wahren Populationswert. Ein anderer Fall ist, wenn man nicht an Verallgemeinerungen interessiert ist: Kennt man etwa die Überlebenschance \\(p\\) des Titanic-Unglücks, so ist es fraglich auf welche Grundgesamtheit man die Statistik \\(p\\) bzw. zu welchem Paramter \\(\\pi\\) (kleines Pi) man generalisieren möchte.\n  Categories:\n qm2 qm2-thema01   ","permalink":"http://example.org/post/inferenz-fuer-alle/inferenz-fuer-alle/","summary":"Exercise Die Inferenzstatistik ist eine Sammlung an Verfahren zur Bemessung von Unsicherheit in statistischen Schlüssen.\nFür welche Statistiken - also Kennzahlen der Deskriptivstatistik wie etwa \\(\\bar{X}, sd, r\\) - kann man die Inferenzstatistik verwenden?\n Für welche Forschungsfragen oder -bereiche kann man die Inferenzstatistik verwenden?\n Gibt es besondere Fälle, in denen man nicht die Inferenzstatistik verwenden möchte? Wenn ja, welche?","title":"Inferenz-fuer-alle"},{"content":" Exercise Man kann angeben, wie genau eine Schätzung von Regressionskoeffizienten die Grundgesamtheit widerspiegelt. Zumeist wird dazu der Standardfehler (engl. standard error, SE) verwendet.\nIn dieser Übung untersuchen wir, wie sich der SE als Funktion der Stichprobengröße, \\(n\\), verhält.\nErstellen Sie dazu folgenden Datensatz:\nlibrary(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✔ ggplot2 3.3.6 ✔ purrr 0.3.4 ## ✔ tibble 3.1.7 ✔ dplyr 1.0.9 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.0 ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() n \u0026lt;- 2^4 d \u0026lt;- tibble(x = rnorm(n = n), # im Default: mean = 0, sd = 1 y = x + rnorm(n, mean = 0, sd = .5)) Hier ist das Ergebnis. Uns interessiert v.a. Std. Error für den Prädiktor x:\nlm(y ~ x, data = d) %\u0026gt;% summary() ## ## Call: ## lm(formula = y ~ x, data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.4691 -0.1671 0.1412 0.3928 1.0587 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.1400 0.1726 0.811 0.431 ## x 0.9091 0.1454 6.254 2.11e-05 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.6801 on 14 degrees of freedom ## Multiple R-squared: 0.7364, Adjusted R-squared: 0.7176 ## F-statistic: 39.11 on 1 and 14 DF, p-value: 2.114e-05 Hier haben wir eine Tabelle mit zwei Variablen, x und y, definiert mit n=16.\nVerdoppeln Sie die Stichprobengröße 5 Mal und betrachten Sie, wie sich die Schätzgenauigkeit, gemessen über den SE, verändert. Berechnen Sie dazu für jedes n eine Regression mit x als Prädiktor und y als AV!\nBei welcher Stichprobengröße ist SE am kleinsten?\nAnswerlist  \\(2^5\\) \\(2^6\\) \\(2^7\\) \\(2^8\\) \\(2^9\\)           \n  Solution Probieren wir es aus!\nErste Verdopplung, \\(n=2^5\\):\nn \u0026lt;- 2^5 d5 \u0026lt;- tibble(x = rnorm(n = n), # im Default: mean = 0, sd = 1 y = x + rnorm(n, mean = 0, sd = .5)) lm5 \u0026lt;- lm(y ~ x, data = d5) lm5 %\u0026gt;% summary() ## ## Call: ## lm(formula = y ~ x, data = d5) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.68715 -0.28669 -0.00344 0.19131 0.94701 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -0.01049 0.07392 -0.142 0.888 ## x 1.08799 0.07182 15.150 1.35e-15 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.4181 on 30 degrees of freedom ## Multiple R-squared: 0.8844, Adjusted R-squared: 0.8805 ## F-statistic: 229.5 on 1 and 30 DF, p-value: 1.346e-15 Man kann sich den Standardfehler komfortabler ausgeben lassen, wenn man das Paket broom verwendet:\nlibrary(broom) lm5 %\u0026gt;% tidy() ## # A tibble: 2 × 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) -0.0105 0.0739 -0.142 8.88e- 1 ## 2 x 1.09 0.0718 15.1 1.35e-15 Dann könnte man z.B. die Spalte std.error selektieren und nach term==x filtern:\nlm5 %\u0026gt;% tidy() %\u0026gt;% filter(term == \u0026quot;x\u0026quot;) %\u0026gt;% select(std.error)  ## # A tibble: 1 × 1 ## std.error ## \u0026lt;dbl\u0026gt; ## 1 0.0718 Jetzt mit den anderen Stichprobengrößen:\nn \u0026lt;- 2^6 d \u0026lt;- tibble(x = rnorm(n = n), # im Default: mean = 0, sd = 1 y = x + rnorm(n, mean = 0, sd = .5)) mein_lm \u0026lt;- lm(y ~ x, data = d) mein_lm %\u0026gt;% tidy() %\u0026gt;% filter(term == \u0026quot;x\u0026quot;) %\u0026gt;% select(std.error)  ## # A tibble: 1 × 1 ## std.error ## \u0026lt;dbl\u0026gt; ## 1 0.0829 n \u0026lt;- 2^7 d \u0026lt;- tibble(x = rnorm(n = n), # im Default: mean = 0, sd = 1 y = x + rnorm(n, mean = 0, sd = .5)) mein_lm \u0026lt;- lm(y ~ x, data = d) mein_lm %\u0026gt;% tidy() %\u0026gt;% filter(term == \u0026quot;x\u0026quot;) %\u0026gt;% select(std.error)  ## # A tibble: 1 × 1 ## std.error ## \u0026lt;dbl\u0026gt; ## 1 0.0425 n \u0026lt;- 2^8 d \u0026lt;- tibble(x = rnorm(n = n), # im Default: mean = 0, sd = 1 y = x + rnorm(n, mean = 0, sd = .5)) mein_lm \u0026lt;- lm(y ~ x, data = d) mein_lm %\u0026gt;% tidy() %\u0026gt;% filter(term == \u0026quot;x\u0026quot;) %\u0026gt;% select(std.error)  ## # A tibble: 1 × 1 ## std.error ## \u0026lt;dbl\u0026gt; ## 1 0.0308 n \u0026lt;- 2^9 d \u0026lt;- tibble(x = rnorm(n = n), # im Default: mean = 0, sd = 1 y = x + rnorm(n, mean = 0, sd = .5)) mein_lm \u0026lt;- lm(y ~ x, data = d) mein_lm %\u0026gt;% tidy() %\u0026gt;% filter(term == \u0026quot;x\u0026quot;) %\u0026gt;% select(std.error)  ## # A tibble: 1 × 1 ## std.error ## \u0026lt;dbl\u0026gt; ## 1 0.0228 Answerlist  Falsch Falsch Falsch Falsch Wahr. Die größte Stichprobe impliziert den kleinsten SE, ceteris paribus.  Categories:\n qm2 qm2-thema01 ws22    ","permalink":"http://example.org/post/lm-standardfehler/lm-standardfehler/","summary":"Exercise Man kann angeben, wie genau eine Schätzung von Regressionskoeffizienten die Grundgesamtheit widerspiegelt. Zumeist wird dazu der Standardfehler (engl. standard error, SE) verwendet.\nIn dieser Übung untersuchen wir, wie sich der SE als Funktion der Stichprobengröße, \\(n\\), verhält.\nErstellen Sie dazu folgenden Datensatz:\nlibrary(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✔ ggplot2 3.3.6 ✔ purrr 0.3.4 ## ✔ tibble 3.1.7 ✔ dplyr 1.0.9 ## ✔ tidyr 1.","title":"lm-Standardfehler"},{"content":" Exercise Wir suchen ein Modell, das einen nichtlinearen Zusammenhang von PS-Zahl und Spritverbrauch darstellt (Datensatz mtcars).\nGeben Sie dafür ein mögliches Modell an! Nutzen Sie den R-Befehl lm.\n         \n Solution mtcars \u0026lt;- mtcars %\u0026gt;% mutate(mpg_log = log(mpg)) lm1 \u0026lt;- lm(mpg_log ~ hp, data = mtcars) summary(lm1) ## ## Call: ## lm(formula = mpg_log ~ hp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.41577 -0.06583 -0.01737 0.09827 0.39621 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 3.4604669 0.0785838 44.035 \u0026lt; 2e-16 *** ## hp -0.0034287 0.0004867 -7.045 7.85e-08 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.1858 on 30 degrees of freedom ## Multiple R-squared: 0.6233, Adjusted R-squared: 0.6107 ## F-statistic: 49.63 on 1 and 30 DF, p-value: 7.853e-08 Visualisieren wir die Vorhersagen des Modells:\nmtcars \u0026lt;- mtcars %\u0026gt;% mutate(pred = predict(lm1)) mtcars %\u0026gt;% ggplot() + aes(x = hp) + geom_line(aes( y = pred), color = \u0026quot;blue\u0026quot;) + geom_point(aes(y = mpg_log)) + labs(y = \u0026quot;log(mpg)\u0026quot;, title = \u0026quot;Vorhersage von log-mpg in einem Log-Y-Modell\u0026quot;) Möchte man auf der Y-Achse mpg und nicht log(mpg) anzeigen, muss man den Logarithmus wieder “auflösen”, das erreicht man mit der Umkehrfunktion des Logarithmus, das Exponentieren (man “delogarithmiert”):\n\\[\\begin{aligned} log(y) \u0026amp;= x \\qquad | \\text{Y in Log-Form}\\\\ exp(log(y)) \u0026amp;= exp(x) \\qquad | \\text{Jetzt exponenzieren wir beide Seiten}\\\\ y = exp(x) \\end{aligned}\\]\nDabei gilt \\(exp(x) = e^x\\), mit \\(e\\) als Eulersche Zahl (2.71…).\nmtcars \u0026lt;- mtcars %\u0026gt;% mutate(pred_delog = exp(pred)) # delogarithmieren mtcars %\u0026gt;% ggplot() + aes(x = hp) + geom_line(aes( y = pred_delog), color = \u0026quot;blue\u0026quot;) + geom_point(aes(y = mpg_log)) + labs(y = \u0026quot;mpg\u0026quot;, title = \u0026quot;Vorhersage von mpg in einem Log-Y-Modell\u0026quot;) Categories:\n qm2 qm2-thema01 ws22   ","permalink":"http://example.org/post/nichtlineareregr1/nichtlineare-regr1/","summary":"Exercise Wir suchen ein Modell, das einen nichtlinearen Zusammenhang von PS-Zahl und Spritverbrauch darstellt (Datensatz mtcars).\nGeben Sie dafür ein mögliches Modell an! Nutzen Sie den R-Befehl lm.\n         \n Solution mtcars \u0026lt;- mtcars %\u0026gt;% mutate(mpg_log = log(mpg)) lm1 \u0026lt;- lm(mpg_log ~ hp, data = mtcars) summary(lm1) ## ## Call: ## lm(formula = mpg_log ~ hp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.","title":"nichtlineare-regr1"},{"content":" Exercise Erstellen Sie eine Analyse, die einem typischen Vorhersageprojekt entspricht!\nNutzen Sie den Datensatz palmerpenguins!\nSagen Sie die Variable body_mass_g vorher.\nHinweise:\n Halten Sie die Analyse einfach. Teilen Sie Test- vs. Train-Set hälftig auf. Teilen Sie Analysis vs. Assessment-Set 3:1 auf.           \n Solution Pakete laden:\nlibrary(tidymodels) ## ── Attaching packages ────────────────────────────────────── tidymodels 0.2.0 ── ## ✔ broom 0.8.0 ✔ recipes 0.2.0 ## ✔ dials 0.1.1 ✔ rsample 0.1.1 ## ✔ dplyr 1.0.9 ✔ tibble 3.1.7 ## ✔ ggplot2 3.3.6 ✔ tidyr 1.2.0 ## ✔ infer 1.0.2 ✔ tune 0.2.0 ## ✔ modeldata 0.1.1 ✔ workflows 0.2.6 ## ✔ parsnip 0.2.1 ✔ workflowsets 0.2.1 ## ✔ purrr 0.3.4 ✔ yardstick 1.0.0 ## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ── ## ✖ purrr::discard() masks scales::discard() ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ✖ recipes::step() masks stats::step() ## • Search for functions across packages at https://www.tidymodels.org/find/ library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ✔ stringr 1.4.0 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ readr::col_factor() masks scales::col_factor() ## ✖ purrr::discard() masks scales::discard() ## ✖ dplyr::filter() masks stats::filter() ## ✖ stringr::fixed() masks recipes::fixed() ## ✖ dplyr::lag() masks stats::lag() ## ✖ readr::spec() masks yardstick::spec() library(easystats) ## # Attaching packages: easystats 0.5.0 (red = needs update) ## ✖ insight 0.17.1.8 ✔ datawizard 0.4.1.3 ## ✔ bayestestR 0.12.1.1 ✖ performance 0.9.0.6 ## ✔ parameters 0.18.1.2 ✔ effectsize 0.7.0 ## ✔ modelbased 0.8.1.1 ✔ correlation 0.8.1.1 ## ✖ see 0.7.0.2 ✔ report 0.5.1.2 ## ## Restart the R-Session and update packages in red with \u0026#39;easystats::easystats_update()\u0026#39;. data(\u0026quot;penguins\u0026quot;, package = \u0026quot;palmerpenguins\u0026quot;) Zeilen mischen und Train- vs. Testset aufteilen:\npenguins2 \u0026lt;- penguins %\u0026gt;% sample_n(size = nrow(.)) d_train \u0026lt;- penguins2 %\u0026gt;% slice(1:(344/2)) d_test \u0026lt;- penguins2 %\u0026gt;% slice(173:nrow(penguins)) Das Trainset weiter aufteilen:\nd_split \u0026lt;- initial_split(d_train) d_analysis \u0026lt;- training(d_split) d_assessment \u0026lt;- testing(d_split) Rezept definieren:\nrec1 \u0026lt;- recipe(body_mass_g ~ ., data = d_analysis) %\u0026gt;% step_impute_knn(all_predictors()) %\u0026gt;% step_normalize(all_numeric(), -all_outcomes()) Rezept prüfen:\nd_analysis_baked \u0026lt;- rec1 %\u0026gt;% prep() %\u0026gt;% bake(new_data = NULL) describe_distribution(d_analysis_baked) ## Variable | Mean | SD | IQR | Range | Skewness | Kurtosis | n | n_Missing ## ------------------------------------------------------------------------------------------------------------- ## bill_length_mm | -5.23e-16 | 1.00 | 1.79 | [-2.09, 1.65] | -0.13 | -1.22 | 129 | 0 ## bill_depth_mm | 5.14e-16 | 1.00 | 1.61 | [-1.97, 2.09] | -0.14 | -0.95 | 129 | 0 ## flipper_length_mm | 4.38e-16 | 1.00 | 1.66 | [-1.77, 2.13] | 0.41 | -0.94 | 129 | 0 ## year | -1.11e-14 | 1.00 | 2.52 | [-1.21, 1.31] | 0.07 | -1.41 | 129 | 0 ## body_mass_g | 4164.73 | 749.70 | 1137.50 | [2700.00, 5800.00] | 0.37 | -0.68 | 129 | 0 Workflow und CV definieren:\nm1 \u0026lt;- linear_reg() wf1 \u0026lt;- workflow() %\u0026gt;% add_recipe(rec1) %\u0026gt;% add_model(m1) cv_scheme \u0026lt;- vfold_cv(d_analysis, v = 2) Fitten (hier kein Tuning):\nfit1 \u0026lt;- wf1 %\u0026gt;% tune_grid(resamples = cv_scheme) ## Warning: No tuning parameters have been detected, performance will be evaluated ## using the resamples with no tuning. Did you want to [tune()] parameters? Finalisieren:\nshow_best(fit1) ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. ## # A tibble: 1 × 6 ## .metric .estimator mean n std_err .config ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 rmse standard 293. 2 9.97 Preprocessor1_Model1 wf1_final \u0026lt;- wf1 %\u0026gt;% finalize_workflow(show_best(fit1)) ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. wf1_final ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: linear_reg() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 2 Recipe Steps ## ## • step_impute_knn() ## • step_normalize() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Linear Regression Model Specification (regression) ## ## Computational engine: lm Modellgüte:\nfit1_final \u0026lt;- wf1_final %\u0026gt;% last_fit(d_split) collect_metrics(fit1_final) ## # A tibble: 2 × 4 ## .metric .estimator .estimate .config ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 rmse standard 287. Preprocessor1_Model1 ## 2 rsq standard 0.863 Preprocessor1_Model1 fit1_train \u0026lt;- wf1_final %\u0026gt;% fit(d_train) fit1_test \u0026lt;- fit1_train %\u0026gt;% predict(d_test) head(fit1_test) ## # A tibble: 6 × 1 ## .pred ## \u0026lt;dbl\u0026gt; ## 1 4714. ## 2 4060. ## 3 3407. ## 4 3311. ## 5 4238. ## 6 4919. Vgl https://workflows.tidymodels.org/reference/predict-workflow.html\nSubmitten:\nsubm_df \u0026lt;- d_test %\u0026gt;% mutate(id = 173:344) %\u0026gt;% bind_cols(fit1_test) %\u0026gt;% select(id, .pred) %\u0026gt;% rename(pred = .pred) Und als CSV-Datei speichern:\n#write_csv(subm_df, file = \u0026quot;submission_blabla.csv\u0026quot;) Categories:\n R ds1 sose22   ","permalink":"http://example.org/post/predictioncontest1/predictioncontest1/","summary":"Exercise Erstellen Sie eine Analyse, die einem typischen Vorhersageprojekt entspricht!\nNutzen Sie den Datensatz palmerpenguins!\nSagen Sie die Variable body_mass_g vorher.\nHinweise:\n Halten Sie die Analyse einfach. Teilen Sie Test- vs. Train-Set hälftig auf. Teilen Sie Analysis vs. Assessment-Set 3:1 auf.           \n Solution Pakete laden:\nlibrary(tidymodels) ## ── Attaching packages ────────────────────────────────────── tidymodels 0.2.0 ── ## ✔ broom 0.","title":"predictioncontest1"},{"content":" Exercise Zwei Modelle, m1 und m2 produzieren jeweils die gleiche Vorhersage (den gleichen Punktschätzer).\nm1:\n## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.196567 -0.069054 0.005416 0.049245 0.261177 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.009946 0.009594 1.037 0.302 ## x 1.006439 0.009749 103.240 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.0959 on 98 degrees of freedom ## Multiple R-squared: 0.9909, Adjusted R-squared: 0.9908 ## F-statistic: 1.066e+04 on 1 and 98 DF, p-value: \u0026lt; 2.2e-16 m2:\n## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.69275 -0.70654 0.01495 0.66760 2.99572 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -0.001719 0.104292 -0.016 0.987 ## x 0.906466 0.109446 8.282 6.31e-13 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 1.041 on 98 degrees of freedom ## Multiple R-squared: 0.4118, Adjusted R-squared: 0.4057 ## F-statistic: 68.6 on 1 and 98 DF, p-value: 6.315e-13 Die Modelle unterscheiden sich aber in ihrer Ungewissheit bezüglich \\(\\beta\\), wie in der Spalte Std. Error ausgedrückt.\nWelches der beiden Modelle ist zu bevorzugen? Begründen Sie.\n         \n Solution Modell m1 hat eine kleinere Ungewissheit im Hinblick auf die Modellkoeffizienten \\(\\beta_0, \\beta_1\\) und ist daher gegenüber m2 zu bevorzugen.\nCategories:\n qm2 qm2-thema01 ws22   ","permalink":"http://example.org/post/punktschaetzer-reicht-nicht/punktschaetzer-reicht-nicht/","summary":"Exercise Zwei Modelle, m1 und m2 produzieren jeweils die gleiche Vorhersage (den gleichen Punktschätzer).\nm1:\n## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.196567 -0.069054 0.005416 0.049245 0.261177 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.009946 0.009594 1.037 0.302 ## x 1.006439 0.009749 103.240 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.","title":"punktschaetzer-reicht-nicht"},{"content":" Exercise In dieser Übung untersuchen wir den Effekt der Stichprobengröße auf die Genauigkeit der Schätzung. Und zwar auf praktische Art und Weise.\nAls praktisches Beispiel soll uns dabei die Körpergröße dienen. Wir erfragen die Körpergröße der Studis und betrachten den Mittelwert einer Stichrpobe in Abhängigkeit der Größe der Stichprobe.\nGeben Sie anonym Ihre Körpergröße hier ein. Sie können die Daten hier beziehen. Berechnen Sie den Mittelwert der Körpergröße für eine zufällige Stichprobe der Größen \\(n=5\\) und \\(n=50\\) Dann berechnen Sie die den “echten” Mittelwert der Studis; damit ist der Mittelwert aller Werte der Tabelle gemeint. Diskutieren Sie die Ergebnisse! Wird die Schätzung genauer bei größerer Stichprobe? Wird die Schätzung “robuster” (weniger schwankend) bei größerer Stichprobe?           \n Solution Individuell\nCategories:\n qm2 qm2-thema01 ws22   ","permalink":"http://example.org/post/stichprobenziehen1/stichprobenziehen1/","summary":"Exercise In dieser Übung untersuchen wir den Effekt der Stichprobengröße auf die Genauigkeit der Schätzung. Und zwar auf praktische Art und Weise.\nAls praktisches Beispiel soll uns dabei die Körpergröße dienen. Wir erfragen die Körpergröße der Studis und betrachten den Mittelwert einer Stichrpobe in Abhängigkeit der Größe der Stichprobe.\nGeben Sie anonym Ihre Körpergröße hier ein. Sie können die Daten hier beziehen. Berechnen Sie den Mittelwert der Körpergröße für eine zufällige Stichprobe der Größen \\(n=5\\) und \\(n=50\\) Dann berechnen Sie die den “echten” Mittelwert der Studis; damit ist der Mittelwert aller Werte der Tabelle gemeint.","title":"Stichprobenziehen1"},{"content":" Exercise Eine statistische Analyse, wie eine Regression, ist mit mehreren Arten an Ungewissheit konfrontiert. Zum einen gibt es die Ungewissheit in den Modellparametern. Für die Regression bedeutet das: “Liegt die Regressionsgerade in”Wahrheit” (in der Population) genauso wie in der Stichprobe, sind Achsenabschnitt und Steigung in der Stichprobe also identisch zur Popuation?“. Zum anderen die Ungewissheit innerhalb des Modells. Auch wenn wir die”wahre” Regressionsgleichung kennen würden, wären (in aller Regel) die Vorhersagen trotzdem nicht perfekt. Auch wenn wir etwa wüssten, wieviel Klausurpunkte “in Wahrheit” pro Stunde Lernen herausspringen (und wenn wir den wahren Achsenabschnitt kennen würden), so würde das Modell trotzdem keine perfekten Vorhersagen zum Klausurerfolg liefern. Vermutlich fehlen dem Modell wichtige Informationen etwa zur Motivation der Studentis.\nVor diesem Hintergrund, betrachten Sie folgendes statistisches Modell, das mit den Methoden der Bayes-Statistik berechnet wurde:\ndata(mtcars) library(rstanarm)  ## Loading required package: Rcpp ## This is rstanarm version 2.21.3 ## - See https://mc-stan.org/rstanarm/articles/priors for changes to default priors! ## - Default priors may change, so it\u0026#39;s safest to specify priors, even if equivalent to the defaults. ## - For execution on a local, multicore CPU with excess RAM we recommend calling ## options(mc.cores = parallel::detectCores()) lm1 \u0026lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0) # um nicht zu viel R-Ausgabe zu erhalten print(lm1) ## stan_glm ## family: gaussian [identity] ## formula: mpg ~ hp ## observations: 32 ## predictors: 2 ## ------ ## Median MAD_SD ## (Intercept) 30.0 1.6 ## hp -0.1 0.0 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 3.9 0.5 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg Für den Prädiktor hp ist das Regressionsgewicht angegeben unter der Spalte median. Dieser Wert entspricht der Punktschätzung in der Population und ist identisch zum Regressiongewicht der Stichprobe.\nDie Spalte MAD_SD gibt den Standardfehler zur Schätzung des Koeffizienten (der entsprechenden Zeile) wieder.\nWelche Zahl kennzeichnet die Ungewissheit des Modells zum Achsenabschnitt? Welche Zahl kennzeichnet die Ungewissheit des Modells zum Regressionsgewicht? Welche Zahl(en) kennzeichnet/kennzeichnen die Ungewissheit des Modells gegeben der Modellparameter (die Ungewissheit innerhalb des Modells)?           \n Solution 1.7 0.0 3.9 und auch dazu 0.5  Categories:\n qm2 qm2-thema01 ws22   ","permalink":"http://example.org/post/ungewiss-arten-regr/ungewiss-arten-regr/","summary":"Exercise Eine statistische Analyse, wie eine Regression, ist mit mehreren Arten an Ungewissheit konfrontiert. Zum einen gibt es die Ungewissheit in den Modellparametern. Für die Regression bedeutet das: “Liegt die Regressionsgerade in”Wahrheit” (in der Population) genauso wie in der Stichprobe, sind Achsenabschnitt und Steigung in der Stichprobe also identisch zur Popuation?“. Zum anderen die Ungewissheit innerhalb des Modells. Auch wenn wir die”wahre” Regressionsgleichung kennen würden, wären (in aller Regel) die Vorhersagen trotzdem nicht perfekt.","title":"ungewiss-arten-regr"},{"content":"Datenwerk ist eine Sammlung von Statistik-Aufgaben.\nAutor: Sebastian Sauer\n","permalink":"http://example.org/about/","summary":"Datenwerk ist eine Sammlung von Statistik-Aufgaben.\nAutor: Sebastian Sauer","title":""}]
[{"content":" Exercise Betrachten Sie folgendes Modell, das den Zusammenhang von PS-Zahl und Spritverbrauch untersucht (Datensatz mtcars).\nAber zuerst zentrieren wir den metrischen Prädiktor hp, um den Achsenabschnitt besser interpretieren zu können.\nmtcars \u0026lt;- mtcars %\u0026gt;% mutate(hp_z = hp - mean(hp)) library(rstanarm) lm1 \u0026lt;- stan_glm(mpg ~ hp_z, data = mtcars, refresh = 0) summary(lm1) Estimates: mean sd 10% 50% 90% (Intercept) 20.1 0.7 19.2 20.1 21.0 hp_z -0.1 0.0 -0.1 -0.1 -0.1 sigma 4.0 0.5 3.4 3.9 4.7  Jetzt können wir aus dem Achsenabschnitt (Intercept) herauslesen, dass ein Auto mit hp_z = 0 - also mit mittlerer PS-Zahl - vielleicht gut 20 Meilen weit mit einer Gallone Sprit kommt.\nZur Verdeutlichung ein Diagramm zum Modell:\nmtcars %\u0026gt;% ggplot() + aes(x = hp_z, y = mpg) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39; Adjustieren Sie im Modell die PS-Zahl um die Art des Schaltgetriebes (am), so dass das neue Modell den statistischen Effekt (nicht notwendig auch kausal) der PS-Zahl bereinigt bzw. unabhängig von der Art des Schaltgetriebes widerspiegelt!\nHinweise:\n am=0 ist ein Auto mit Automatikgetriebe. Wir gehen davon aus, dass der Regressionseffekt gleich stark ist auf allen (beiden) Stufen von am. M.a.W.: Es liegt kein Interaktionseffekt vor.           \n Solution library(rstanarm) lm2 \u0026lt;- stan_glm(mpg ~ hp_z + am, data = mtcars, refresh = 0) summary(lm2) Estimates: mean sd 10% 50% 90% (Intercept) 26.6 1.5 24.7 26.6 28.5 hp -0.1 0.0 -0.1 -0.1 0.0 am 5.3 1.1 3.8 5.3 6.6 sigma 3.0 0.4 2.5 3.0 3.5  Die Spalte mean gibt den mittleren geschätzten Wert für den jeweiligen Koeffizienten an, also den Schätzwert zum Koeffizienten.\nDie Koeffizienten zeigen, dass der Achsenabschnitt für Autos mit Automatikgetriebe um etwa 5 Meilen geringer ist als für Autos mit manueller Schaltung: Ein durchschnittliches Auto mit manueller Schaltung kommt also etwa 5 Meilen weiter als ein Auto mit Automatikschaltung, glaubt unser Modell.\nmtcars %\u0026gt;% mutate(am = factor(am)) %\u0026gt;% ggplot() + aes(x = hp_z, y = mpg, color = am) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39; Man könnte hier noch einen Interaktionseffekt ergänzen.\nCategories:\n qm2 qm2-thema01 ws22   ","permalink":"http://example.org/post/adjustieren1/adjustieren1/","summary":"Exercise Betrachten Sie folgendes Modell, das den Zusammenhang von PS-Zahl und Spritverbrauch untersucht (Datensatz mtcars).\nAber zuerst zentrieren wir den metrischen Prädiktor hp, um den Achsenabschnitt besser interpretieren zu können.\nmtcars \u0026lt;- mtcars %\u0026gt;% mutate(hp_z = hp - mean(hp)) library(rstanarm) lm1 \u0026lt;- stan_glm(mpg ~ hp_z, data = mtcars, refresh = 0) summary(lm1) Estimates: mean sd 10% 50% 90% (Intercept) 20.1 0.7 19.2 20.1 21.0 hp_z -0.1 0.0 -0.1 -0.1 -0.","title":"adjustieren1"},{"content":" Exercise Für Statistiken (Stichprobe) verwendet man meist lateinische Buchstaben; für Parameter (Population) verwendet man meist (die entsprechenden) griechischen Buchstaben.\nVervollständigen Sie folgende Tabelle entsprechend!\ntibble::tribble( ~Kennwert, ~Statistik, ~Parameter, \u0026quot;Mittelwert\u0026quot;, \u0026quot;$\\\\bar{X}$\u0026quot;, NA, \u0026quot;Mittelwertsdifferenz\u0026quot;, \u0026quot;$\\\\bar{X}_1-\\\\bar{X}_2$\u0026quot;, NA, \u0026quot;Streuung\u0026quot;, \u0026quot;sd\u0026quot;, NA, \u0026quot;Anteil\u0026quot;, \u0026quot;p\u0026quot;, NA, \u0026quot;Korrelation\u0026quot;, \u0026quot;r\u0026quot;, NA, \u0026quot;Regressionsgewicht\u0026quot;, \u0026quot;b\u0026quot;, NA ) %\u0026gt;% kable(escape = FALSE)   Kennwert Statistik Parameter    Mittelwert \\(\\bar{X}\\) NA  Mittelwertsdifferenz \\(\\bar{X}_1-\\bar{X}_2\\) NA  Streuung sd NA  Anteil p NA  Korrelation r NA  Regressionsgewicht b NA             \n Solution tibble::tribble( ~Kennwert, ~Statistik, ~Parameter, \u0026quot;Mittelwert\u0026quot;, \u0026quot;$$\\\\bar{X}$$\u0026quot;, \u0026quot;$$\\\\mu$$\u0026quot;, \u0026quot;Mittelwertsdifferenz\u0026quot;, \u0026quot;$$d=\\\\bar{X}_1-\\\\bar{X}_2$$\u0026quot;, \u0026quot;$$\\\\mu_1$$- $$\\\\mu_2$$\u0026quot;, \u0026quot;Streuung\u0026quot;, \u0026quot;sd\u0026quot;, \u0026quot;$$\\\\sigma$$\u0026quot;, \u0026quot;Anteil\u0026quot;, \u0026quot;p\u0026quot;, \u0026quot;$$\\\\pi$$\u0026quot;, \u0026quot;Korrelation\u0026quot;, \u0026quot;r\u0026quot;, \u0026quot;$$\\\\rho$$\u0026quot;, \u0026quot;Regressionsgewicht\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;$$\\\\beta$$\u0026quot; ) %\u0026gt;% kable(escape = FALSE)   Kennwert Statistik Parameter    Mittelwert \\[\\bar{X}\\] \\[\\mu\\]  Mittelwertsdifferenz \\[d=\\bar{X}_1-\\bar{X}_2\\] \\[\\mu_1\\]- \\[\\mu_2\\]  Streuung sd \\[\\sigma\\]  Anteil p \\[\\pi\\]  Korrelation r \\[\\rho\\]  Regressionsgewicht b \\[\\beta\\]    Categories:\n qm2 qm2-thema01   ","permalink":"http://example.org/post/griech-buchstaben/griech-buchstaben-inferenz/","summary":"Exercise Für Statistiken (Stichprobe) verwendet man meist lateinische Buchstaben; für Parameter (Population) verwendet man meist (die entsprechenden) griechischen Buchstaben.\nVervollständigen Sie folgende Tabelle entsprechend!\ntibble::tribble( ~Kennwert, ~Statistik, ~Parameter, \u0026quot;Mittelwert\u0026quot;, \u0026quot;$\\\\bar{X}$\u0026quot;, NA, \u0026quot;Mittelwertsdifferenz\u0026quot;, \u0026quot;$\\\\bar{X}_1-\\\\bar{X}_2$\u0026quot;, NA, \u0026quot;Streuung\u0026quot;, \u0026quot;sd\u0026quot;, NA, \u0026quot;Anteil\u0026quot;, \u0026quot;p\u0026quot;, NA, \u0026quot;Korrelation\u0026quot;, \u0026quot;r\u0026quot;, NA, \u0026quot;Regressionsgewicht\u0026quot;, \u0026quot;b\u0026quot;, NA ) %\u0026gt;% kable(escape = FALSE)   Kennwert Statistik Parameter    Mittelwert \\(\\bar{X}\\) NA  Mittelwertsdifferenz \\(\\bar{X}_1-\\bar{X}_2\\) NA  Streuung sd NA  Anteil p NA  Korrelation r NA  Regressionsgewicht b NA","title":"Griech-Buchstaben-Inferenz"},{"content":" Exercise Erstellen Sie eine Analyse, die einem typischen Vorhersageprojekt entspricht!\nNutzen Sie den Datensatz palmerpenguins!\nSagen Sie die Variable body_mass_g vorher.\nHinweise:\n Halten Sie die Analyse einfach. Teilen Sie Test- vs. Train-Set hälftig auf. Teilen Sie Analysis vs. Assessment-Set 3:1 auf.           \n Solution Pakete laden:\nlibrary(tidymodels) ## ── Attaching packages ────────────────────────────────────── tidymodels 0.2.0 ── ## ✔ broom 0.8.0 ✔ recipes 0.2.0 ## ✔ dials 0.1.1 ✔ rsample 0.1.1 ## ✔ dplyr 1.0.9 ✔ tibble 3.1.7 ## ✔ ggplot2 3.3.6 ✔ tidyr 1.2.0 ## ✔ infer 1.0.2 ✔ tune 0.2.0 ## ✔ modeldata 0.1.1 ✔ workflows 0.2.6 ## ✔ parsnip 0.2.1 ✔ workflowsets 0.2.1 ## ✔ purrr 0.3.4 ✔ yardstick 1.0.0 ## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ── ## ✖ purrr::discard() masks scales::discard() ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ✖ recipes::step() masks stats::step() ## • Search for functions across packages at https://www.tidymodels.org/find/ library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ✔ stringr 1.4.0 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ readr::col_factor() masks scales::col_factor() ## ✖ purrr::discard() masks scales::discard() ## ✖ dplyr::filter() masks stats::filter() ## ✖ stringr::fixed() masks recipes::fixed() ## ✖ dplyr::lag() masks stats::lag() ## ✖ readr::spec() masks yardstick::spec() library(easystats) ## # Attaching packages: easystats 0.5.0 (red = needs update) ## ✖ insight 0.17.1.8 ✔ datawizard 0.4.1.3 ## ✔ bayestestR 0.12.1.1 ✖ performance 0.9.0.6 ## ✔ parameters 0.18.1.2 ✔ effectsize 0.7.0 ## ✔ modelbased 0.8.1.1 ✔ correlation 0.8.1.1 ## ✖ see 0.7.0.2 ✔ report 0.5.1.2 ## ## Restart the R-Session and update packages in red with \u0026#39;easystats::easystats_update()\u0026#39;. data(\u0026quot;penguins\u0026quot;, package = \u0026quot;palmerpenguins\u0026quot;) Zeilen mischen und Train- vs. Testset aufteilen:\npenguins2 \u0026lt;- penguins %\u0026gt;% sample_n(size = nrow(.)) d_train \u0026lt;- penguins2 %\u0026gt;% slice(1:(344/2)) d_test \u0026lt;- penguins2 %\u0026gt;% slice(173:nrow(penguins)) Das Trainset weiter aufteilen:\nd_split \u0026lt;- initial_split(d_train) d_analysis \u0026lt;- training(d_split) d_assessment \u0026lt;- testing(d_split) Rezept definieren:\nrec1 \u0026lt;- recipe(body_mass_g ~ ., data = d_analysis) %\u0026gt;% step_impute_knn(all_predictors()) %\u0026gt;% step_normalize(all_numeric(), -all_outcomes()) Rezept prüfen:\nd_analysis_baked \u0026lt;- rec1 %\u0026gt;% prep() %\u0026gt;% bake(new_data = NULL) describe_distribution(d_analysis_baked) ## Variable | Mean | SD | IQR | Range | Skewness | Kurtosis | n | n_Missing ## ------------------------------------------------------------------------------------------------------------- ## bill_length_mm | -5.23e-16 | 1.00 | 1.79 | [-2.09, 1.65] | -0.13 | -1.22 | 129 | 0 ## bill_depth_mm | 5.14e-16 | 1.00 | 1.61 | [-1.97, 2.09] | -0.14 | -0.95 | 129 | 0 ## flipper_length_mm | 4.38e-16 | 1.00 | 1.66 | [-1.77, 2.13] | 0.41 | -0.94 | 129 | 0 ## year | -1.11e-14 | 1.00 | 2.52 | [-1.21, 1.31] | 0.07 | -1.41 | 129 | 0 ## body_mass_g | 4164.73 | 749.70 | 1137.50 | [2700.00, 5800.00] | 0.37 | -0.68 | 129 | 0 Workflow und CV definieren:\nm1 \u0026lt;- linear_reg() wf1 \u0026lt;- workflow() %\u0026gt;% add_recipe(rec1) %\u0026gt;% add_model(m1) cv_scheme \u0026lt;- vfold_cv(d_analysis, v = 2) Fitten (hier kein Tuning):\nfit1 \u0026lt;- wf1 %\u0026gt;% tune_grid(resamples = cv_scheme) ## Warning: No tuning parameters have been detected, performance will be evaluated ## using the resamples with no tuning. Did you want to [tune()] parameters? Finalisieren:\nshow_best(fit1) ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. ## # A tibble: 1 × 6 ## .metric .estimator mean n std_err .config ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 rmse standard 293. 2 9.97 Preprocessor1_Model1 wf1_final \u0026lt;- wf1 %\u0026gt;% finalize_workflow(show_best(fit1)) ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. wf1_final ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: linear_reg() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 2 Recipe Steps ## ## • step_impute_knn() ## • step_normalize() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Linear Regression Model Specification (regression) ## ## Computational engine: lm Modellgüte:\nfit1_final \u0026lt;- wf1_final %\u0026gt;% last_fit(d_split) collect_metrics(fit1_final) ## # A tibble: 2 × 4 ## .metric .estimator .estimate .config ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 rmse standard 287. Preprocessor1_Model1 ## 2 rsq standard 0.863 Preprocessor1_Model1 fit1_train \u0026lt;- wf1_final %\u0026gt;% fit(d_train) fit1_test \u0026lt;- fit1_train %\u0026gt;% predict(d_test) head(fit1_test) ## # A tibble: 6 × 1 ## .pred ## \u0026lt;dbl\u0026gt; ## 1 4714. ## 2 4060. ## 3 3407. ## 4 3311. ## 5 4238. ## 6 4919. Vgl https://workflows.tidymodels.org/reference/predict-workflow.html\nSubmitten:\nsubm_df \u0026lt;- d_test %\u0026gt;% mutate(id = 173:344) %\u0026gt;% bind_cols(fit1_test) %\u0026gt;% select(id, .pred) %\u0026gt;% rename(pred = .pred) Und als CSV-Datei speichern:\n#write_csv(subm_df, file = \u0026quot;submission_blabla.csv\u0026quot;) Categories:\n R ds1 sose22   ","permalink":"http://example.org/post/predictioncontest1/predictioncontest1/","summary":"Exercise Erstellen Sie eine Analyse, die einem typischen Vorhersageprojekt entspricht!\nNutzen Sie den Datensatz palmerpenguins!\nSagen Sie die Variable body_mass_g vorher.\nHinweise:\n Halten Sie die Analyse einfach. Teilen Sie Test- vs. Train-Set hälftig auf. Teilen Sie Analysis vs. Assessment-Set 3:1 auf.           \n Solution Pakete laden:\nlibrary(tidymodels) ## ── Attaching packages ────────────────────────────────────── tidymodels 0.2.0 ── ## ✔ broom 0.","title":"predictioncontest1"},{"content":" Exercise Zwei Modelle, m1 und m2 produzieren jeweils die gleiche Vorhersage (den gleichen Punktschätzer).\nm1:\n## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.196567 -0.069054 0.005416 0.049245 0.261177 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.009946 0.009594 1.037 0.302 ## x 1.006439 0.009749 103.240 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.0959 on 98 degrees of freedom ## Multiple R-squared: 0.9909, Adjusted R-squared: 0.9908 ## F-statistic: 1.066e+04 on 1 and 98 DF, p-value: \u0026lt; 2.2e-16 m2:\n## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.69275 -0.70654 0.01495 0.66760 2.99572 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -0.001719 0.104292 -0.016 0.987 ## x 0.906466 0.109446 8.282 6.31e-13 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 1.041 on 98 degrees of freedom ## Multiple R-squared: 0.4118, Adjusted R-squared: 0.4057 ## F-statistic: 68.6 on 1 and 98 DF, p-value: 6.315e-13 Die Modelle unterscheiden sich aber in ihrer Ungewissheit bezüglich \\(\\beta\\), wie in der Spalte Std. Error ausgedrückt.\nWelches der beiden Modelle ist zu bevorzugen? Begründen Sie.\n         \n Solution Modell m1 hat eine kleinere Ungewissheit im Hinblick auf die Modellkoeffizienten \\(\\beta_0, \\beta_1\\) und ist daher gegenüber m2 zu bevorzugen.\nCategories:\n qm2 qm2-thema01 ws22   ","permalink":"http://example.org/post/punktschaetzer-reicht-nicht/punktschaetzer-reicht-nicht/","summary":"Exercise Zwei Modelle, m1 und m2 produzieren jeweils die gleiche Vorhersage (den gleichen Punktschätzer).\nm1:\n## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.196567 -0.069054 0.005416 0.049245 0.261177 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.009946 0.009594 1.037 0.302 ## x 1.006439 0.009749 103.240 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.","title":"punktschaetzer-reicht-nicht"},{"content":"Hi There!\nThis is Sebastian Sauer speaking.\n","permalink":"http://example.org/about/","summary":"Hi There!\nThis is Sebastian Sauer speaking.","title":""}]
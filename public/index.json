[{"content":" Exercise Betrachten Sie folgendes Modell, das den Zusammenhang von PS-Zahl und Spritverbrauch untersucht (Datensatz mtcars).\nAber zuerst zentrieren wir den metrischen Prädiktor hp, um den Achsenabschnitt besser interpretieren zu können.\nmtcars \u0026lt;- mtcars %\u0026gt;% mutate(hp_z = hp - mean(hp)) library(rstanarm) lm1 \u0026lt;- stan_glm(mpg ~ hp_z, data = mtcars, refresh = 0) summary(lm1) Estimates: mean sd 10% 50% 90% (Intercept) 20.1 0.7 19.2 20.1 21.0 hp_z -0.1 0.0 -0.1 -0.1 -0.1 sigma 4.0 0.5 3.4 3.9 4.7  Jetzt können wir aus dem Achsenabschnitt (Intercept) herauslesen, dass ein Auto mit hp_z = 0 - also mit mittlerer PS-Zahl - vielleicht gut 20 Meilen weit mit einer Gallone Sprit kommt.\nZur Verdeutlichung ein Diagramm zum Modell:\nmtcars %\u0026gt;% ggplot() + aes(x = hp_z, y = mpg) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39; Adjustieren Sie im Modell die PS-Zahl um die Art des Schaltgetriebes (am), so dass das neue Modell den statistischen Effekt (nicht notwendig auch kausal) der PS-Zahl bereinigt bzw. unabhängig von der Art des Schaltgetriebes widerspiegelt!\nHinweise:\n am=0 ist ein Auto mit Automatikgetriebe. Wir gehen davon aus, dass der Regressionseffekt gleich stark ist auf allen (beiden) Stufen von am. M.a.W.: Es liegt kein Interaktionseffekt vor.           \n Solution library(rstanarm) lm2 \u0026lt;- stan_glm(mpg ~ hp_z + am, data = mtcars, refresh = 0) summary(lm2) Estimates: mean sd 10% 50% 90% (Intercept) 26.6 1.5 24.7 26.6 28.5 hp -0.1 0.0 -0.1 -0.1 0.0 am 5.3 1.1 3.8 5.3 6.6 sigma 3.0 0.4 2.5 3.0 3.5  Die Spalte mean gibt den mittleren geschätzten Wert für den jeweiligen Koeffizienten an, also den Schätzwert zum Koeffizienten.\nDie Koeffizienten zeigen, dass der Achsenabschnitt für Autos mit Automatikgetriebe um etwa 5 Meilen geringer ist als für Autos mit manueller Schaltung: Ein durchschnittliches Auto mit manueller Schaltung kommt also etwa 5 Meilen weiter als ein Auto mit Automatikschaltung, glaubt unser Modell.\nmtcars %\u0026gt;% mutate(am = factor(am)) %\u0026gt;% ggplot() + aes(x = hp_z, y = mpg, color = am) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39; Man könnte hier noch einen Interaktionseffekt ergänzen.\nCategories:\n qm2 qm2-thema01 ws22   ","permalink":"https://datenwerk.netlify.app/post/adjustieren1/adjustieren1/","summary":"Exercise Betrachten Sie folgendes Modell, das den Zusammenhang von PS-Zahl und Spritverbrauch untersucht (Datensatz mtcars).\nAber zuerst zentrieren wir den metrischen Prädiktor hp, um den Achsenabschnitt besser interpretieren zu können.\nmtcars \u0026lt;- mtcars %\u0026gt;% mutate(hp_z = hp - mean(hp)) library(rstanarm) lm1 \u0026lt;- stan_glm(mpg ~ hp_z, data = mtcars, refresh = 0) summary(lm1) Estimates: mean sd 10% 50% 90% (Intercept) 20.1 0.7 19.2 20.1 21.0 hp_z -0.1 0.0 -0.1 -0.1 -0.","title":"adjustieren1"},{"content":" Exercise Für Statistiken (Stichprobe) verwendet man meist lateinische Buchstaben; für Parameter (Population) verwendet man meist (die entsprechenden) griechischen Buchstaben.\nVervollständigen Sie folgende Tabelle entsprechend!\n  Kennwert Statistik Parameter    Mittelwert \\(\\bar{X}\\) NA  Mittelwertsdifferenz \\(\\bar{X}_1-\\bar{X}_2\\) NA  Streuung sd NA  Anteil p NA  Korrelation r NA  Regressionsgewicht b NA             \n Solution   Kennwert Statistik Parameter    Mittelwert \\[\\bar{X}\\] \\[\\mu\\]  Mittelwertsdifferenz \\[d=\\bar{X}_1-\\bar{X}_2\\] \\[\\mu_1\\]- \\[\\mu_2\\]  Streuung sd \\[\\sigma\\]  Anteil p \\[\\pi\\]  Korrelation r \\[\\rho\\]  Regressionsgewicht b \\[\\beta\\]    Categories:\n qm2 qm2-thema01   ","permalink":"https://datenwerk.netlify.app/post/griech-buchstaben-inferenz/griech-buchstaben-inferenz/","summary":"Exercise Für Statistiken (Stichprobe) verwendet man meist lateinische Buchstaben; für Parameter (Population) verwendet man meist (die entsprechenden) griechischen Buchstaben.\nVervollständigen Sie folgende Tabelle entsprechend!\n  Kennwert Statistik Parameter    Mittelwert \\(\\bar{X}\\) NA  Mittelwertsdifferenz \\(\\bar{X}_1-\\bar{X}_2\\) NA  Streuung sd NA  Anteil p NA  Korrelation r NA  Regressionsgewicht b NA             \n Solution   Kennwert Statistik Parameter    Mittelwert \\[\\bar{X}\\] \\[\\mu\\]  Mittelwertsdifferenz \\[d=\\bar{X}_1-\\bar{X}_2\\] \\[\\mu_1\\]- \\[\\mu_2\\]  Streuung sd \\[\\sigma\\]  Anteil p \\[\\pi\\]  Korrelation r \\[\\rho\\]  Regressionsgewicht b \\[\\beta\\]    Categories:","title":"Griech-Buchstaben-Inferenz"},{"content":" options(digits=2) options(width = 80) Exercise Die Korrelation prüft, ob zwei Merkmale linear zusammenhängen.\nWie viele andere Verfahren kann die Korrelation als ein Spezialfall der Regression bzw. des linearen Modells \\(y = \\beta_0 + \\beta_1 + \\ldots \\beta_n + \\epsilon\\) betrachtet werden.\nAls ein spezielles Beispiel betrachten wir die Frage, ob das Gewicht eines Diamanten (carat) mit dem Preis (price) zusammenhängt (Datensatz diamonds).\nDen Datensatz können Sie so laden:\nlibrary(tidyverse) data(diamonds) Geben Sie das Skalenniveau beider Variablen an!\n Betrachten Sie die Ausgabe von R:\n  lm1 \u0026lt;- lm(price ~ carat, data = diamonds) summary(lm1) ## ## Call: ## lm(formula = price ~ carat, data = diamonds) ## ## Residuals: ## Min 1Q Median 3Q Max ## -18585 -805 -19 537 12732 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -2256.4 13.1 -173 \u0026lt;2e-16 *** ## carat 7756.4 14.1 551 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 1550 on 53938 degrees of freedom ## Multiple R-squared: 0.849, Adjusted R-squared: 0.849 ## F-statistic: 3.04e+05 on 1 and 53938 DF, p-value: \u0026lt;2e-16 Wie (bzw. wo) ist aus dieser Ausgabe die Korrelation herauszulesen?\nMacht es einen Unterschied, ob man Preis mit Karat bzw. Karat mit Preis korreliert?\n In der klassischen Inferenzstatistik ist der \\(p\\)-Wert eine zentrale Größe; ist er klein (\\(p\u0026lt;.05\\)) so nennt man die zugehörige Statistik signifikant und verwirft die getestete Hypothese.\n Im Folgenden sehen Sie einen Korrelationstest auf statistische Signifikanz, mit R durchgeführt. Zeigt der Test ein (statistisch) signifikantes Ergebnis? Wie groß ist der “Unsicherheitskorridor”, um den Korrelationswert (zugleich Punktschätzer für den Populationswert)?\n  library(easystats) ## # Attaching packages: easystats 0.5.2 ## ✔ insight 0.18.2 ✔ datawizard 0.5.1 ## ✔ bayestestR 0.12.1.1 ✔ performance 0.9.2 ## ✔ parameters 0.18.2 ✔ effectsize 0.7.0.5 ## ✔ modelbased 0.8.5 ✔ correlation 0.8.2 ## ✔ see 0.7.2 ✔ report 0.5.5 diamonds %\u0026gt;% sample_n(30) %\u0026gt;% select(price, carat) %\u0026gt;% correlation() ## # Correlation Matrix (pearson-method) ## ## Parameter1 | Parameter2 | r | 95% CI | t(28) | p ## ----------------------------------------------------------------- ## price | carat | 0.94 | [0.87, 0.97] | 14.25 | \u0026lt; .001*** ## ## p-value adjustment method: Holm (1979) ## Observations: 30          \n Solution carat ist metrisch (verhältnisskaliert) und price ist metrisch (verhältnisskaliert)\n \\(R^2\\) kann bei einer einfachen (univariaten) Regression als das Quadrat von \\(r\\) berechnet werden. Daher \\(r = \\sqrt{R^2}\\).\n  sqrt(0.8493) ## [1] 0.92 Zum Vergleich\ndiamonds %\u0026gt;% summarise(r = cor(price, carat)) ## # A tibble: 1 × 1 ## r ## \u0026lt;dbl\u0026gt; ## 1 0.922 Man kann den Wert der Korrelation auch noch anderweitig berechnen (\\(\\beta\\) umrechnen in \\(\\rho\\)).\nNein. Die Korrelation ist eine symmetrische Relation.\n Ja; die Zahl “3.81e-14” bezeichnet eine positive Zahl kleiner eins mit 13 Nullern vor der ersten Ziffer, die nicht Null ist (3.81 in diesem Fall). Der “Unsicherheitskorridor” reicht von etwa 0.87 bis 0.97.\n  Categories:\n~\n ","permalink":"https://datenwerk.netlify.app/post/korr-als-regr/korr-als-regr/","summary":"options(digits=2) options(width = 80) Exercise Die Korrelation prüft, ob zwei Merkmale linear zusammenhängen.\nWie viele andere Verfahren kann die Korrelation als ein Spezialfall der Regression bzw. des linearen Modells \\(y = \\beta_0 + \\beta_1 + \\ldots \\beta_n + \\epsilon\\) betrachtet werden.\nAls ein spezielles Beispiel betrachten wir die Frage, ob das Gewicht eines Diamanten (carat) mit dem Preis (price) zusammenhängt (Datensatz diamonds).\nDen Datensatz können Sie so laden:\nlibrary(tidyverse) data(diamonds) Geben Sie das Skalenniveau beider Variablen an!","title":"korr-als-regr"},{"content":" Exercise Der t-Test kann als Spezialfall der Regressionsanalyse gedeutet werden.\nHierbei ist es wichtig, sich das Skalenniveau der Variablen, die ein t-Test verarbeitet, vor Augen zu führen.\nHinweisse:\n Die folgende Abbildung gibt Tipps. Informationen, die zur Lösung einer Aufgabe nicht nötig sind, sollte man ignorieren.  Answerlist  Benennen Sie die Skalenniveaus der UV eines t-Tests! Geben Sie nur ein Wort ein. Verwenden Sie nur Kleinbuchstaben (z.B. regression). Benennen Sie die Skalenniveaus der AV eines t-Tests! Geben Sie nur ein Wort ein. Verwenden Sie nur Kleinbuchstaben (z.B. regression). Nennen Sie eine beispielhafte Forschungsfrage für einen t-Test. Skizzieren Sie ein Diagramm einer Regression, die analytisch identisch (oder sehr ähnlich) zu einem t-Test ist!           \n  Solution Answerlist  UV: binär AV: metrisch Unterscheiden sich die mittleren Einparkzeiten von Frauen und Männern? Aus dem Datensatz mtcars:  data(mtcars) mtcars %\u0026gt;% ggplot() + aes(x = am, y = mpg) + geom_point(alpha = .5) + geom_smooth(method = \u0026quot;lm\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39; Categories:\n~\n  ","permalink":"https://datenwerk.netlify.app/post/ttest-als-regr/ttest-als-regr/","summary":"Exercise Der t-Test kann als Spezialfall der Regressionsanalyse gedeutet werden.\nHierbei ist es wichtig, sich das Skalenniveau der Variablen, die ein t-Test verarbeitet, vor Augen zu führen.\nHinweisse:\n Die folgende Abbildung gibt Tipps. Informationen, die zur Lösung einer Aufgabe nicht nötig sind, sollte man ignorieren.  Answerlist  Benennen Sie die Skalenniveaus der UV eines t-Tests! Geben Sie nur ein Wort ein. Verwenden Sie nur Kleinbuchstaben (z.B. regression). Benennen Sie die Skalenniveaus der AV eines t-Tests!","title":"ttest-als-regr"},{"content":" Exercise Der t-Test ist ein inferenzstatistisches Verfahren des Frequentismus. Welches Skalenniveau passt zu diesem Verfahren?\nHinweisse:\n Die folgende Abbildung gibt Tipps. Informationen, die zur Lösung einer Aufgabe nicht nötig sind, sollte man ignorieren.  Answerlist  UV: nominal (mehrstufig), AV: metrisch UV: metrisch, AV: nominal (zweistufig) UV: nominal (mehrstufig), AV: nominal (mehrstufig) UV: metrisch, AV: nominal (zweistufig) UV: nominal (zweistufig), AV: metrisch           \n  Solution Answerlist  Falsch Falsch Falsch Falsch Wahr  Categories:\n~\n  ","permalink":"https://datenwerk.netlify.app/post/ttest-skalenniveau/ttest-skalenniveau/","summary":"Exercise Der t-Test ist ein inferenzstatistisches Verfahren des Frequentismus. Welches Skalenniveau passt zu diesem Verfahren?\nHinweisse:\n Die folgende Abbildung gibt Tipps. Informationen, die zur Lösung einer Aufgabe nicht nötig sind, sollte man ignorieren.  Answerlist  UV: nominal (mehrstufig), AV: metrisch UV: metrisch, AV: nominal (zweistufig) UV: nominal (mehrstufig), AV: nominal (mehrstufig) UV: metrisch, AV: nominal (zweistufig) UV: nominal (zweistufig), AV: metrisch","title":"ttest-skalenniveau"},{"content":" Exercise Betrachten Sie folgendes Modell, das den Zusammenhang des Preises (price) und dem Gewicht (carat) von Diamanten untersucht (Datensatz diamonds).\nlibrary(tidyverse) data(diamonds) Aber zuerst zentrieren wir den metrischen Prädiktor carat, um den Achsenabschnitt besser interpretieren zu können.\ndiamonds \u0026lt;- diamonds %\u0026gt;% mutate(carat_z = carat - mean(carat, na.rm = TRUE)) Dann berechnen wir ein (bayesianisches) Regressionsmodell, wobei wir auf die Standardwerte der Prior zurückgreifen.\nlibrary(rstanarm) ## Loading required package: Rcpp ## This is rstanarm version 2.21.3 ## - See https://mc-stan.org/rstanarm/articles/priors for changes to default priors! ## - Default priors may change, so it\u0026#39;s safest to specify priors, even if equivalent to the defaults. ## - For execution on a local, multicore CPU with excess RAM we recommend calling ## options(mc.cores = parallel::detectCores()) lm1 \u0026lt;- stan_glm(price ~ carat_z, data = diamonds, refresh = 0) summary(lm1) Estimates: mean sd 10% 50% 90% (Intercept) 3932.5 6.8 3923.7 3932.5 3941.1 carat_z 7756.3 14.2 7737.8 7756.2 7774.7 sigma 1548.6 4.8 1542.5 1548.6 1554.7  Zur Verdeutlichung ein Diagramm zum Modell:\ndiamonds %\u0026gt;% ggplot() + aes(x = carat_z, y = price) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39; Answerlist Was kostet in Diamant mittlerer Größe laut Modell lm1? Runden Sie auf eine Dezimale. Geben Sie nur eine Zahl ein. Geben Sie eine Regressionsformel an, die lm1 ergänzt, so dass die Schliffart (cut) des Diamanten kontrolliert (adjustiert) wird. Anders gesagt: Das Modell soll die mittleren Preise für jede der fünf Schliffarten angeben. Geben Sie nur die Regressionsformel an. Lassen Sie zwischen Termen jeweils ein Leerzeichen Abstand.  Hinweis: Es gibt (laut Datensatz) folgende Schliffarten (und zwar in der folgenden Reihenfolge):\ndiamonds %\u0026gt;% distinct(cut) ## # A tibble: 5 × 1 ## cut ## \u0026lt;ord\u0026gt; ## 1 Ideal ## 2 Premium ## 3 Good ## 4 Very Good ## 5 Fair levels(diamonds$cut) ## [1] \u0026quot;Fair\u0026quot; \u0026quot;Good\u0026quot; \u0026quot;Very Good\u0026quot; \u0026quot;Premium\u0026quot; \u0026quot;Ideal\u0026quot;          \n  Solution Unser Modell lm1 schätzt den Preis eines Diamanten mittlerer Größe auf etwa 3932.5 (was immer auch die Einheiten sind, Dollar vermutlich).\n price ~ carat_z + cut\n  Das Modell könnten wir so berechnen:\nlibrary(rstanarm) lm2 \u0026lt;- stan_glm(price ~ carat_z + cut, data = diamonds, refresh = 0) summary(lm2) Estimates: mean sd 10% 50% 90% (Intercept) 3579.4 9.7 3566.9 3579.5 3591.9 carat_z 7871.5 14.2 7853.1 7871.4 7890.3 cut.L 1239.4 26.3 1205.7 1239.6 1272.6 cut.Q -527.9 23.4 -557.9 -528.3 -497.7 cut.C 367.7 20.4 341.8 367.7 393.5 cut^4 74.9 16.5 53.6 75.0 95.5 sigma 1511.5 4.6 1505.6 1511.5 1517.4  lm(price ~ carat_z + cut, data = diamonds) ## ## Call: ## lm(formula = price ~ carat_z + cut, data = diamonds) ## ## Coefficients: ## (Intercept) carat_z cut.L cut.Q cut.C cut^4 ## 3579.27 7871.08 1239.80 -528.60 367.91 74.59 Man könnte hier noch einen Interaktionseffekt ergänzen.\nCategories:\n qm2 ‘2022’   ","permalink":"https://datenwerk.netlify.app/post/adjustieren2/adjustieren2/","summary":"Exercise Betrachten Sie folgendes Modell, das den Zusammenhang des Preises (price) und dem Gewicht (carat) von Diamanten untersucht (Datensatz diamonds).\nlibrary(tidyverse) data(diamonds) Aber zuerst zentrieren wir den metrischen Prädiktor carat, um den Achsenabschnitt besser interpretieren zu können.\ndiamonds \u0026lt;- diamonds %\u0026gt;% mutate(carat_z = carat - mean(carat, na.rm = TRUE)) Dann berechnen wir ein (bayesianisches) Regressionsmodell, wobei wir auf die Standardwerte der Prior zurückgreifen.\nlibrary(rstanarm) ## Loading required package: Rcpp ## This is rstanarm version 2.","title":"adjustieren2"},{"content":" Exercise Betrachten Sie dieses Modell, das den Zusammenhang von PS-Zahl und Spritverbrauch untersucht (Datensatz mtcars):\ndata(mtcars) library(rstanarm) ## Loading required package: Rcpp ## This is rstanarm version 2.21.3 ## - See https://mc-stan.org/rstanarm/articles/priors for changes to default priors! ## - Default priors may change, so it\u0026#39;s safest to specify priors, even if equivalent to the defaults. ## - For execution on a local, multicore CPU with excess RAM we recommend calling ## options(mc.cores = parallel::detectCores()) lm1 \u0026lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0) summary(lm1) Das Modell liefert folgende Werte für die drei Koeffizienten (Intercept, hp, sigma):\nEstimates: mean sd 10% 50% 90% (Intercept) 30.1 1.7 27.9 30.1 32.3 hp -0.1 0.0 -0.1 -0.1 -0.1 sigma 4.0 0.5 3.3 3.9 4.7  Was bedeuten die drei Koeffizienten! Wie ist der Effekt von \\(\\beta_1\\) zu interpretieren?           \n Solution Intercept (\\(\\beta_0\\)): Der Achsenabschnitt gibt den geschätzten mittleren Y-Wert (Spritverbrauch) an, wenn \\(x=0\\), also für ein Auto mit 0 PS (was nicht wirklich Sinn macht). hp (\\(\\beta_1\\)) ist der Regressionskoeffizient oder Regressionsgewicht und damit die Steigung der Regressionsgeraden. Sigma gibt die Unsicherheit in unserer Vorhersage des Spritverbrauchs an.\n hp (\\(\\beta_1\\)) ist der Regressionskoeffizient oder Regressionsgewicht und gibt den statistischen “Effekt” der PS-Zahl auf den Spritverbrauch an. Vorsicht: Dieser “Effekt” darf nicht vorschnell als kausaler Effekt verstanden werden. Daher muss man vorsichtig sein, wenn man von einem “Effekt” spricht. Vorsichtiger wäre zu sagen: “Ein Auto mit einem PS mehr, kommt im Mittel 0,1 Meilen weniger weit mit einer Gallone Sprit, laut diesem Modell”.\n  Categories:\n qm2 ‘2022’   ","permalink":"https://datenwerk.netlify.app/post/interpret-koeff/interpret-koeff/","summary":"Exercise Betrachten Sie dieses Modell, das den Zusammenhang von PS-Zahl und Spritverbrauch untersucht (Datensatz mtcars):\ndata(mtcars) library(rstanarm) ## Loading required package: Rcpp ## This is rstanarm version 2.21.3 ## - See https://mc-stan.org/rstanarm/articles/priors for changes to default priors! ## - Default priors may change, so it\u0026#39;s safest to specify priors, even if equivalent to the defaults. ## - For execution on a local, multicore CPU with excess RAM we recommend calling ## options(mc.","title":"interpret-koeff"},{"content":" Exercise library(tidyverse) library(easystats) In dieser Aufgabe modellieren wir den (kausalen) Effekt von Schulbildung auf das Einkommen.\nImportieren Sie zunächst den Datensatz und verschaffen Sie sich einen Überblick.\nd_path \u0026lt;- \u0026quot;https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Treatment.csv\u0026quot; d \u0026lt;- data_read(d_path) Dokumentation und Quellenangaben zum Datensatz finden sich hier.\nglimpse(d) ## Rows: 2,675 ## Columns: 11 ## $ V1 \u0026lt;int\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,… ## $ treat \u0026lt;lgl\u0026gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… ## $ age \u0026lt;int\u0026gt; 37, 30, 27, 33, 22, 23, 32, 22, 19, 21, 18, 27, 17, 19, 27, 23… ## $ educ \u0026lt;int\u0026gt; 11, 12, 11, 8, 9, 12, 11, 16, 9, 13, 8, 10, 7, 10, 13, 10, 12,… ## $ ethn \u0026lt;chr\u0026gt; \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;,… ## $ married \u0026lt;lgl\u0026gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, … ## $ re74 \u0026lt;dbl\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ re75 \u0026lt;dbl\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ re78 \u0026lt;dbl\u0026gt; 9930.05, 24909.50, 7506.15, 289.79, 4056.49, 0.00, 8472.16, 21… ## $ u74 \u0026lt;lgl\u0026gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… ## $ u75 \u0026lt;lgl\u0026gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… Modellieren Sie den Effekt der Bildungsdauer auf das Einkommen! Gehen Sie von einem exponenziellen Zusammenhang der beiden Variablen aus. Um welchen Faktor steigt das Einkommen pro Jahr Bildung (laut Modell)?\nHinweise:\n Verwenden Sie lm zur Modellierung. Operationalisieren Sie das Einkommen mit der Variable re74. Fügen Sie keine weiteren Variablen dem Modell hinzu. Gehen Sie von einem kausalen Effekt des Prädiktors aus.           \n Solution d2 \u0026lt;- d %\u0026gt;% filter(re74 \u0026gt; 0) %\u0026gt;% mutate(re74_log = log(re74)) m \u0026lt;- lm(re74_log ~ educ, data = d2) Hier sind die parameters des Modells.\n    Parameter Coefficient SE 95% CI t(2327) p    (Intercept) 8.83 0.06 (8.70, 8.95) 142.91 \u0026lt; .001  educ 0.07 4.94e-03 (0.07, 0.08) 15.16 \u0026lt; .001    Für jedes Jahr Bildung steigt das Einkommen also ca. um den Faktor 1.07.\nEtwas genauer:\n\\(\\hat{\\beta_1} = 0.07\\) bedeutet, dass ein Jahr Bildung zu einen erwarteten Unterschied im Einkommen in Höhe von 0.07 in Log-Einkommen führt. Anders gesagt wird das Einkommen um exp(0.07) erhöht. Dabei gilt \\(e^{0.07} \\approx 1.07\\):\nexp(0.07) ## [1] 1.072508 Die Lösung lautet also: “Pro Jahr Bildung steigt das Einkommen - laut Modell um den Faktor ca. 1.07”.\nMan darf dabei nicht vergessen, dass wir wir uns hier auf die Schnelle ein Modell ausgedacht haben. Ob es in Wirklichkeit so ist, wie unser Modell meint, ist eine andere Sache!\nCategories:\n stats-nutshell qm2   ","permalink":"https://datenwerk.netlify.app/post/log-y-regr1/log-y-regr1/","summary":"Exercise library(tidyverse) library(easystats) In dieser Aufgabe modellieren wir den (kausalen) Effekt von Schulbildung auf das Einkommen.\nImportieren Sie zunächst den Datensatz und verschaffen Sie sich einen Überblick.\nd_path \u0026lt;- \u0026quot;https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Treatment.csv\u0026quot; d \u0026lt;- data_read(d_path) Dokumentation und Quellenangaben zum Datensatz finden sich hier.\nglimpse(d) ## Rows: 2,675 ## Columns: 11 ## $ V1 \u0026lt;int\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,… ## $ treat \u0026lt;lgl\u0026gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… ## $ age \u0026lt;int\u0026gt; 37, 30, 27, 33, 22, 23, 32, 22, 19, 21, 18, 27, 17, 19, 27, 23… ## $ educ \u0026lt;int\u0026gt; 11, 12, 11, 8, 9, 12, 11, 16, 9, 13, 8, 10, 7, 10, 13, 10, 12,… ## $ ethn \u0026lt;chr\u0026gt; \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;,… ## $ married \u0026lt;lgl\u0026gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, … ## $ re74 \u0026lt;dbl\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ re75 \u0026lt;dbl\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ re78 \u0026lt;dbl\u0026gt; 9930.","title":"log-y-regr1"},{"content":" Exercise library(tidyverse) library(easystats) In dieser Aufgabe modellieren wir den (kausalen) Effekt von Schulbildung auf das Einkommen.\nImportieren Sie zunächst den Datensatz und verschaffen Sie sich einen Überblick.\nd_path \u0026lt;- \u0026quot;https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Treatment.csv\u0026quot; d \u0026lt;- data_read(d_path) Dokumentation und Quellenangaben zum Datensatz finden sich hier.\nglimpse(d) ## Rows: 2,675 ## Columns: 11 ## $ V1 \u0026lt;int\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,… ## $ treat \u0026lt;lgl\u0026gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… ## $ age \u0026lt;int\u0026gt; 37, 30, 27, 33, 22, 23, 32, 22, 19, 21, 18, 27, 17, 19, 27, 23… ## $ educ \u0026lt;int\u0026gt; 11, 12, 11, 8, 9, 12, 11, 16, 9, 13, 8, 10, 7, 10, 13, 10, 12,… ## $ ethn \u0026lt;chr\u0026gt; \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;,… ## $ married \u0026lt;lgl\u0026gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, … ## $ re74 \u0026lt;dbl\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ re75 \u0026lt;dbl\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ re78 \u0026lt;dbl\u0026gt; 9930.05, 24909.50, 7506.15, 289.79, 4056.49, 0.00, 8472.16, 21… ## $ u74 \u0026lt;lgl\u0026gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… ## $ u75 \u0026lt;lgl\u0026gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… Modellieren Sie den Effekt der Bildungsdauer auf das Einkommen! Gehen Sie von einem exponenziellen Zusammenhang der beiden Variablen aus. Wie verändert sich die Verteilung der abhängigen Variablen (Y) durch die Logarithmus-Transformation?\nHinweise:\n Verwenden Sie lm zur Modellierung. Operationalisieren Sie das Einkommen mit der Variable re74. Fügen Sie keine weiteren Variablen dem Modell hinzu. Gehen Sie von einem kausalen Effekt des Prädiktors aus.           \n Solution d2 \u0026lt;- d %\u0026gt;% filter(re74 \u0026gt; 0) %\u0026gt;% mutate(re74_log = log(re74)) m \u0026lt;- lm(re74_log ~ educ, data = d2) ggplot(d2) + aes(x = re74) + geom_density() + labs(title = \u0026quot;Income raw\u0026quot;) ggplot(d2) + aes(x = re74_log) + geom_density() + labs(title = \u0026quot;Income log transformed\u0026quot;) Betrachten wir die deskriptiven Statistiken:\nd2 %\u0026gt;% select(re74, re74_log) %\u0026gt;% describe_distribution() ## Variable | Mean | SD | IQR | Range | Skewness | Kurtosis | n | n_Missing ## ------------------------------------------------------------------------------------------------------ ## re74 | 20938.28 | 12631.52 | 15086.30 | [17.63, 1.37e+05] | 1.62 | 6.81 | 2329 | 0 ## re74_log | 9.73 | 0.76 | 0.80 | [2.87, 11.83] | -1.67 | 6.01 | 2329 | 0 Die Log-Transformation hat in diesem Fall nicht wirklich zu einer Normalisierung der Variablen beigetragen. Aber das war auch nicht unser Ziel.\nCategories:\n stats-nutshell qm2   ","permalink":"https://datenwerk.netlify.app/post/log-y-regr2/log-y-regr2/","summary":"Exercise library(tidyverse) library(easystats) In dieser Aufgabe modellieren wir den (kausalen) Effekt von Schulbildung auf das Einkommen.\nImportieren Sie zunächst den Datensatz und verschaffen Sie sich einen Überblick.\nd_path \u0026lt;- \u0026quot;https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Treatment.csv\u0026quot; d \u0026lt;- data_read(d_path) Dokumentation und Quellenangaben zum Datensatz finden sich hier.\nglimpse(d) ## Rows: 2,675 ## Columns: 11 ## $ V1 \u0026lt;int\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,… ## $ treat \u0026lt;lgl\u0026gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… ## $ age \u0026lt;int\u0026gt; 37, 30, 27, 33, 22, 23, 32, 22, 19, 21, 18, 27, 17, 19, 27, 23… ## $ educ \u0026lt;int\u0026gt; 11, 12, 11, 8, 9, 12, 11, 16, 9, 13, 8, 10, 7, 10, 13, 10, 12,… ## $ ethn \u0026lt;chr\u0026gt; \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;,… ## $ married \u0026lt;lgl\u0026gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, … ## $ re74 \u0026lt;dbl\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ re75 \u0026lt;dbl\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ re78 \u0026lt;dbl\u0026gt; 9930.","title":"log-y-regr2"},{"content":" Exercise library(tidyverse) library(easystats) In dieser Aufgabe modellieren wir den (kausalen) Effekt von Schulbildung auf das Einkommen.\nImportieren Sie zunächst den Datensatz und verschaffen Sie sich einen Überblick.\nd_path \u0026lt;- \u0026quot;https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Treatment.csv\u0026quot; d \u0026lt;- data_read(d_path) Dokumentation und Quellenangaben zum Datensatz finden sich hier.\nglimpse(d) ## Rows: 2,675 ## Columns: 11 ## $ V1 \u0026lt;int\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,… ## $ treat \u0026lt;lgl\u0026gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… ## $ age \u0026lt;int\u0026gt; 37, 30, 27, 33, 22, 23, 32, 22, 19, 21, 18, 27, 17, 19, 27, 23… ## $ educ \u0026lt;int\u0026gt; 11, 12, 11, 8, 9, 12, 11, 16, 9, 13, 8, 10, 7, 10, 13, 10, 12,… ## $ ethn \u0026lt;chr\u0026gt; \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;,… ## $ married \u0026lt;lgl\u0026gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, … ## $ re74 \u0026lt;dbl\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ re75 \u0026lt;dbl\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ re78 \u0026lt;dbl\u0026gt; 9930.05, 24909.50, 7506.15, 289.79, 4056.49, 0.00, 8472.16, 21… ## $ u74 \u0026lt;lgl\u0026gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… ## $ u75 \u0026lt;lgl\u0026gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… Welcher der Prädiktoren hat den stärkesten Einfluss auf das Einkommen?\nHinweise:\n Verwenden Sie lm zur Modellierung. Operationalisieren Sie das Einkommen mit der Variable re74. Gehen Sie von einem kausalen Effekt der Prädiktoren aus. Gehen Sie von einem multiplikativen Modell aus (log-y). Lassen Sie die Variablen zur Arbeitslosigkeit außen vor.  Answerlist  treat age educ ethn married           \n  Solution d2 \u0026lt;- d %\u0026gt;% filter(re74 \u0026gt; 0) %\u0026gt;% mutate(re74_log = log(re74)) %\u0026gt;% standardize(select = c(\u0026quot;age\u0026quot;, \u0026quot;educ\u0026quot;)) Prüfen, ob das standardisieren funktioniert hat:\nd2 %\u0026gt;% describe_distribution() %\u0026gt;% display() ## Warning: Can\u0026#39;t describe variables of class \u0026#39;logical\u0026#39;. ## Warning: Can\u0026#39;t describe variables of class \u0026#39;logical\u0026#39;. ## Warning: Can\u0026#39;t describe variables of class \u0026#39;logical\u0026#39;. ## Warning: Can\u0026#39;t describe variables of class \u0026#39;logical\u0026#39;.     Variable Mean SD IQR Range Skewness Kurtosis n n_Missing    V1 1429.07 736.61 1294.00 (95.00, 2675.00) -0.08 -1.15 2329 0  age -2.69e-16 1.00 1.74 (-1.65, 2.03) 0.42 -1.09 2329 0  educ 1.33e-16 1.00 0.99 (-3.99, 1.61) -0.47 0.43 2329 0  re74 20938.28 12631.52 15086.30 (17.63, 1.37e+05) 1.62 6.81 2329 0  re75 20080.38 13123.48 15217.70 (0.00, 1.57e+05) 1.58 7.85 2329 0  re78 22508.65 14917.30 16846.10 (0.00, 1.21e+05) 1.28 4.12 2329 0  re74_log 9.73 0.76 0.80 (2.87, 11.83) -1.67 6.01 2329 0    m \u0026lt;- lm(re74_log ~ educ + treat + age + ethn + married, data = d2) Parameter des Modells:\n    Parameter Coefficient SE 95% CI t(2322) p    (Intercept) 9.29 0.04 (9.20, 9.37) 223.32 \u0026lt; .001  educ 0.23 0.01 (0.20, 0.26) 16.03 \u0026lt; .001  treatTRUE -0.66 0.09 (-0.84, -0.47) -7.06 \u0026lt; .001  age 0.22 0.01 (0.19, 0.25) 15.79 \u0026lt; .001  ethn (hispanic) 0.22 0.08 (0.07, 0.38) 2.90 0.004  ethn (other) 0.22 0.03 (0.16, 0.29) 6.78 \u0026lt; .001  marriedTRUE 0.35 0.04 (0.28, 0.43) 8.93 \u0026lt; .001    Answerlist  TRUE FALSE FALSE FALSE FALSE  Categories:\n stats-nutshell qm2    ","permalink":"https://datenwerk.netlify.app/post/log-y-regr3/log-y-regr3/","summary":"Exercise library(tidyverse) library(easystats) In dieser Aufgabe modellieren wir den (kausalen) Effekt von Schulbildung auf das Einkommen.\nImportieren Sie zunächst den Datensatz und verschaffen Sie sich einen Überblick.\nd_path \u0026lt;- \u0026quot;https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Treatment.csv\u0026quot; d \u0026lt;- data_read(d_path) Dokumentation und Quellenangaben zum Datensatz finden sich hier.\nglimpse(d) ## Rows: 2,675 ## Columns: 11 ## $ V1 \u0026lt;int\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,… ## $ treat \u0026lt;lgl\u0026gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… ## $ age \u0026lt;int\u0026gt; 37, 30, 27, 33, 22, 23, 32, 22, 19, 21, 18, 27, 17, 19, 27, 23… ## $ educ \u0026lt;int\u0026gt; 11, 12, 11, 8, 9, 12, 11, 16, 9, 13, 8, 10, 7, 10, 13, 10, 12,… ## $ ethn \u0026lt;chr\u0026gt; \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;black\u0026quot;,… ## $ married \u0026lt;lgl\u0026gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, … ## $ re74 \u0026lt;dbl\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ re75 \u0026lt;dbl\u0026gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ re78 \u0026lt;dbl\u0026gt; 9930.","title":"log-y-regr3"},{"content":" Exercise Im Folgenden ist der Datensatz mtcars zu analysieren.\nDer Datensatz ist Teil des des R-Pakets datasets und damit beim Start von R automatisch geladen.\nAlternativ ist der Datensatz als CSV-Datei hier abrufbar.\nHilfe zum Datensatz ist via help(\"mtcars\") oder auf dieser Webseite abrufbar.\nBerechnen Sie das folgende generalisierte lineare Modell:\nAV: am.\nUV: qsec, vs, gear.\nIm Folgenden wird ein Prädiktor aus der Menge der UV näher betrachtet. Der gewählte Prädiktor ist: qsec.\nHinweise:\n Verwenden Sie Standardwerte der R-Funktionen, soweit nicht anders angegeben. Runden Sie auf eine Dezimalstelle. Verwenden Sie Methoden der Bayes-Statistik für inferenzstatistische Analysen. Geben Sie keine Prozentzahlen an, sondern Anteile (also nicht “50%”, sondern “0.5” etc.) Findet sich in einer Auswahlliste möglicher Antworten nicht die exakte Lösung, wählen Sie die am besten passende. Beziehen Sie sich im Zweifel auf den Stoff, so wie im Unterricht behandelt.  Answerlist  Der Medianwert des Regressionskoeffizienten aus der Posterior-Verteilung beträgt in Logits: 1.20\n Der Medianwert des Regressionskoeffizienten aus der Posterior-Verteilung beträgt in Logits: -0.80\n Der Medianwert des Regressionskoeffizienten aus der Posterior-Verteilung beträgt in Logits: -4.80\n Der Medianwert des Regressionskoeffizienten aus der Posterior-Verteilung beträgt in Logits: 3.20\n Der Medianwert des Regressionskoeffizienten aus der Posterior-Verteilung beträgt in Logits: -2.80\n Der Absolutwert der Breite eines 90%-PI für den Koeffizienten des Prädiktors beträgt in Logits: 3.80\n Der Absolutwert der Breite eines 90%-PI für den Koeffizienten des Prädiktors beträgt in Logits: 0.63\n Der Absolutwert der Breite eines 90%-PI für den Koeffizienten des Prädiktors beträgt in Logits: 0.95\n Der Absolutwert der Breite eines 90%-PI für den Koeffizienten des Prädiktors beträgt in Logits: 5.70\n Der Absolutwert der Breite eines 90%-PI für den Koeffizienten des Prädiktors beträgt in Logits: 1.90\n Der Wert des Achsenabschnitts (Intercept) in Wahrscheinlichkeit (p) beträgt: 0.42\n Der Wert des Achsenabschnitts (Intercept) in Wahrscheinlichkeit (p) beträgt: 1.00\n Der Wert des Achsenabschnitts (Intercept) in Wahrscheinlichkeit (p) beträgt: 0.00\n Der Wert des Achsenabschnitts (Intercept) in Wahrscheinlichkeit (p) beträgt: 0.33\n Der Wert des Achsenabschnitts (Intercept) in Wahrscheinlichkeit (p) beträgt: 0.50\n Der Punktschätzer für den vorhergesagten Wert, wenn alle Prädiktoren 0 sind, beträgt in Wahrscheinlichkeit: 0.33 Der Punktschätzer für den vorhergesagten Wert, wenn alle Prädiktoren 0 sind, beträgt in Wahrscheinlichkeit: 0.42 Der Punktschätzer für den vorhergesagten Wert, wenn alle Prädiktoren 0 sind, beträgt in Wahrscheinlichkeit: 0.00 Der Punktschätzer für den vorhergesagten Wert, wenn alle Prädiktoren 0 sind, beträgt in Wahrscheinlichkeit: 1.00 Der Punktschätzer für den vorhergesagten Wert, wenn alle Prädiktoren 0 sind, beträgt in Wahrscheinlichkeit: 0.50           \n  Solution Die Prädiktoren (UV) des Modells lauten (hat der Dozent oben im Verborgenen bestimmt):\npreds_chosen ## [1] \u0026quot;qsec\u0026quot; \u0026quot;vs\u0026quot; \u0026quot;gear\u0026quot; Daraus erstellt der Dozent eine “Modellformel” (mod_formula), von der Art y ~ x1 + x2 + x2.\n## am ~ qsec + vs + gear Damit kann man dann das Modell berechnen:\nmod \u0026lt;- stan_glm(mod_formula, data = mtcars, family = binomial(\u0026quot;logit\u0026quot;)) Ausgabe der Ergebnisse:\nprint(mod) ## stan_glm ## family: binomial [logit] ## formula: am ~ qsec + vs + gear ## observations: 32 ## predictors: 4 ## ------ ## Median MAD_SD ## (Intercept) -8.5 11.6 ## qsec -0.8 0.6 ## vs 0.5 2.2 ## gear 5.8 2.0 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg Gefragt war nach diesem Prädiktor:\npreds_chosen[1] # Dieses Objekt hat der Dozent oben im Verborgenen erstellt. ## [1] \u0026quot;qsec\u0026quot; Der Medianwert des Regressionskoeffizienten aus der Posterior-Verteilung beträgt in Logits: …  sol_a \u0026lt;- coef(mod)[preds_chosen[1]] %\u0026gt;% round(1) %\u0026gt;% unname() ## [1] -0.8 Der Absolutwert der Breite eines 90%-PI für den Koeffizienten des Prädiktors beträgt in Logits: …  post_pred_chosen \u0026lt;- posterior_interval(mod, pars = preds_chosen[1], prob = .90) breite \u0026lt;- abs(post_pred_chosen[2] - post_pred_chosen[1]) breite \u0026lt;- round(breite, 1) sol_b \u0026lt;- breite %\u0026gt;% round(1) %\u0026gt;% unname() ## [1] 1.9 Der Wert des Achsenabschnitts (Intercept) in Wahrscheinlichkeit (p) beträgt: …  sol_c \u0026lt;- coef(mod)[1] %\u0026gt;% plogis() %\u0026gt;% unname() ## [1] 0.0002046653 Der Punktschätzer für den vorhergesagten Wert, wenn alle Prädiktoren 0 sind, beträgt in Wahrscheinlichkeit: …  sol_d \u0026lt;- sol_c Answerlist  Falsch. Richtig. Falsch. Falsch. Falsch. Falsch. Falsch. Falsch. Falsch. Richtig. Falsch. Falsch. Richtig. Falsch. Falsch. Falsch. Falsch. Richtig. Falsch. Falsch.  Categories:\n~\n  ","permalink":"https://datenwerk.netlify.app/post/post2-glm/post2-glm/","summary":"Exercise Im Folgenden ist der Datensatz mtcars zu analysieren.\nDer Datensatz ist Teil des des R-Pakets datasets und damit beim Start von R automatisch geladen.\nAlternativ ist der Datensatz als CSV-Datei hier abrufbar.\nHilfe zum Datensatz ist via help(\"mtcars\") oder auf dieser Webseite abrufbar.\nBerechnen Sie das folgende generalisierte lineare Modell:\nAV: am.\nUV: qsec, vs, gear.\nIm Folgenden wird ein Prädiktor aus der Menge der UV näher betrachtet. Der gewählte Prädiktor ist: qsec.","title":"Post2-glm"},{"content":" Exercise We will use the dataset mtcars in this exercise.\nAssume your causal model of your research dictates that fuel economy is a linear function of horse power, cylinder count and displacement of the engine.\nCompute the causal effect of horse power given the above model! Report the point estimate.\nNotes:\n Use can either use frequentist or bayesian modeling. Use R for all computations. There are multiple ways to find a solution.           \n Solution Compute Model:\nlm1_freq \u0026lt;- lm(mpg ~ hp + cyl + disp, data = mtcars) library(rstanarm) lm1_bayes \u0026lt;- stan_glm(mpg ~ hp + cyl + disp, data = mtcars, refresh = 0) Get parameters:\nlibrary(easystats) parameters(lm1_freq) ## Parameter | Coefficient | SE | 95% CI | t(28) | p ## ------------------------------------------------------------------ ## (Intercept) | 34.18 | 2.59 | [28.88, 39.49] | 13.19 | \u0026lt; .001 ## hp | -0.01 | 0.01 | [-0.04, 0.02] | -1.00 | 0.325 ## cyl | -1.23 | 0.80 | [-2.86, 0.41] | -1.54 | 0.135 ## disp | -0.02 | 0.01 | [-0.04, 0.00] | -1.81 | 0.081 parameters(lm1_bayes) ## Parameter | Median | 95% CI | pd | % in ROPE | Rhat | ESS | Prior ## ------------------------------------------------------------------------------------------------------ ## (Intercept) | 34.16 | [28.69, 39.81] | 100% | 0% | 1.001 | 2134.00 | Normal (20.09 +- 15.07) ## hp | -0.01 | [-0.04, 0.01] | 83.78% | 100% | 1.001 | 2644.00 | Normal (0.00 +- 0.22) ## cyl | -1.23 | [-2.94, 0.41] | 93.08% | 3.50% | 1.001 | 1746.00 | Normal (0.00 +- 8.44) ## disp | -0.02 | [-0.04, 0.00] | 95.90% | 100% | 1.000 | 2145.00 | Normal (0.00 +- 0.12) The coefficient is estimated as about -0.01\nCategories:\n qm1 stats-nutshell   ","permalink":"https://datenwerk.netlify.app/post/mtcars-simple1/mtcars-simple1/","summary":"Exercise We will use the dataset mtcars in this exercise.\nAssume your causal model of your research dictates that fuel economy is a linear function of horse power, cylinder count and displacement of the engine.\nCompute the causal effect of horse power given the above model! Report the point estimate.\nNotes:\n Use can either use frequentist or bayesian modeling. Use R for all computations. There are multiple ways to find a solution.","title":"mtcars-simple1"},{"content":" Exercise We will use the dataset mtcars in this exercise.\nAssume your causal model of your research dictates that fuel economy is a linear function of horse power, cylinder count and displacement of the engine.\nCompute the explained variance (point estimate) for the above model!\nNotes:\n Use can either use frequentist or bayesian modeling. Use R for all computations. There are multiple ways to find a solution.           \n Solution Compute Model:\nlm1_freq \u0026lt;- lm(mpg ~ hp + cyl + disp, data = mtcars) library(rstanarm) lm1_bayes \u0026lt;- stan_glm(mpg ~ hp + cyl + disp, data = mtcars, refresh = 0) Get R2:\nlibrary(easystats) r2(lm1_freq) ## # R2 for Linear Regression ## R2: 0.768 ## adj. R2: 0.743 r2(lm1_bayes) ## # Bayesian R2 with Compatibility Interval ## ## Conditional R2: 0.746 (95% CI [0.602, 0.846]) The coefficient is estimated as about 0.77.\nCategories:\n qm1 stats-nutshell   ","permalink":"https://datenwerk.netlify.app/post/mtcars-simple2/mtcars-simple2/","summary":"Exercise We will use the dataset mtcars in this exercise.\nAssume your causal model of your research dictates that fuel economy is a linear function of horse power, cylinder count and displacement of the engine.\nCompute the explained variance (point estimate) for the above model!\nNotes:\n Use can either use frequentist or bayesian modeling. Use R for all computations. There are multiple ways to find a solution.","title":"mtcars-simple2"},{"content":" Exercise We will use the dataset mtcars in this exercise.\nAssume your causal model of your research dictates that fuel economy is a linear function of horse power, cylinder count and displacement of the engine.\nWhich of the predictors in the above model has the weakest causal impact on the output variable?\nNotes:\n Use can either use frequentist or bayesian modeling. Use R for all computations. There are multiple ways to find a solution.  Answerlist  cyl hp disp All are equally strong none of the above           \n  Solution library(rstanarm) library(easystats) library(tidyverse) In order to gauge the relative importance of the predictors, we need to make sure they are on the same scale:\nmtcars2 \u0026lt;- standardise(mtcars) Compute Model:\nlm1_freq \u0026lt;- lm(mpg ~ hp + cyl + disp, data = mtcars2) lm1_bayes \u0026lt;- stan_glm(mpg ~ hp + cyl + disp, data = mtcars2, refresh = 0) Get parameters:\nparameters(lm1_bayes) ## Parameter | Median | 95% CI | pd | % in ROPE | Rhat | ESS | Prior ## ---------------------------------------------------------------------------------------------------------- ## (Intercept) | -1.32e-03 | [-0.19, 0.18] | 50.70% | 77.42% | 1.001 | 2850.00 | Normal (7.11e-17 +- 2.50) ## hp | -0.17 | [-0.50, 0.16] | 85.42% | 30.45% | 1.000 | 2318.00 | Normal (0.00 +- 2.50) ## cyl | -0.36 | [-0.83, 0.11] | 93.55% | 11.39% | 1.002 | 1862.00 | Normal (0.00 +- 2.50) ## disp | -0.39 | [-0.80, 0.03] | 96.65% | 6.42% | 1.002 | 2139.00 | Normal (0.00 +- 2.50) Note that the absolute value of the coefficient’s estimate is what we are after.\nThe predictors with the strongest impact is disp, and cyl. The weakest influence has hp.\nAnswerlist  wrong correct wrong wrong wrong  Categories:\n qm1 stats-nutshell    ","permalink":"https://datenwerk.netlify.app/post/mtcars-simple3/mtcars-simple3/","summary":"Exercise We will use the dataset mtcars in this exercise.\nAssume your causal model of your research dictates that fuel economy is a linear function of horse power, cylinder count and displacement of the engine.\nWhich of the predictors in the above model has the weakest causal impact on the output variable?\nNotes:\n Use can either use frequentist or bayesian modeling. Use R for all computations. There are multiple ways to find a solution.","title":"mtcars-simple3"},{"content":" Exercise Recherchieren Sie den Datensatz “Palmer Penguins” als CSV-Datei im Internet.\nImportieren Sie die Datendatei in R von einer geeigneten Online-Quelle. Laden Sie die Datendatei herunter, speichern Sie Sie in den Ordner Ihres aktuellen RStudio-Projekts. Dann importieren Sie die Datendatei in R von diesem Ort.           \n Solution library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ── ## ✔ ggplot2 3.3.6 ✔ purrr 0.3.4 ## ✔ tibble 3.1.7 ✔ dplyr 1.0.9 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.0 ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() Ad 1)\npenguins_url \u0026lt;- \u0026quot;https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\u0026quot; d \u0026lt;- read_csv(penguins_url) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #yakcxbwkvb .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #yakcxbwkvb .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #yakcxbwkvb .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #yakcxbwkvb .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #yakcxbwkvb .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #yakcxbwkvb .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #yakcxbwkvb .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #yakcxbwkvb .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #yakcxbwkvb .gt_column_spanner_outer:first-child { padding-left: 0; } #yakcxbwkvb .gt_column_spanner_outer:last-child { padding-right: 0; } #yakcxbwkvb .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #yakcxbwkvb .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #yakcxbwkvb .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #yakcxbwkvb .gt_from_md  :first-child { margin-top: 0; } #yakcxbwkvb .gt_from_md  :last-child { margin-bottom: 0; } #yakcxbwkvb .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #yakcxbwkvb .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #yakcxbwkvb .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #yakcxbwkvb .gt_row_group_first td { border-top-width: 2px; } #yakcxbwkvb .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #yakcxbwkvb .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #yakcxbwkvb .gt_first_summary_row.thick { border-top-width: 2px; } #yakcxbwkvb .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #yakcxbwkvb .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #yakcxbwkvb .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #yakcxbwkvb .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #yakcxbwkvb .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #yakcxbwkvb .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #yakcxbwkvb .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #yakcxbwkvb .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #yakcxbwkvb .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #yakcxbwkvb .gt_left { text-align: left; } #yakcxbwkvb .gt_center { text-align: center; } #yakcxbwkvb .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #yakcxbwkvb .gt_font_normal { font-weight: normal; } #yakcxbwkvb .gt_font_bold { font-weight: bold; } #yakcxbwkvb .gt_font_italic { font-style: italic; } #yakcxbwkvb .gt_super { font-size: 65%; } #yakcxbwkvb .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #yakcxbwkvb .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #yakcxbwkvb .gt_asterisk { font-size: 100%; vertical-align: 0; } #yakcxbwkvb .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #yakcxbwkvb .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #yakcxbwkvb .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; }   ...1 species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year   1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 3 Adelie Torgersen 40.3 18.0 195 3250 female 2007 4 Adelie Torgersen NA NA NA NA NA 2007 5 Adelie Torgersen 36.7 19.3 193 3450 female 2007 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007    Alternativ (hier aber nicht verlangt) können Sie den Datensatz penguins auch über ein R-Paket beziehen:\ndata(penguins, package = \u0026quot;palmerpenguins\u0026quot;) head(penguins) ## # A tibble: 6 × 8 ## species island bill_length_mm bill_depth_mm flipper_l…¹ body_…² sex year ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 ## 2 Adelie Torgersen 39.5 17.4 186 3800 fema… 2007 ## 3 Adelie Torgersen 40.3 18 195 3250 fema… 2007 ## 4 Adelie Torgersen NA NA NA NA \u0026lt;NA\u0026gt; 2007 ## 5 Adelie Torgersen 36.7 19.3 193 3450 fema… 2007 ## 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 ## # … with abbreviated variable names ¹​flipper_length_mm, ²​body_mass_g Synonym:\nlibrary(palmerpenguins) data(penguins) head(penguins) ## # A tibble: 6 × 8 ## species island bill_length_mm bill_depth_mm flipper_l…¹ body_…² sex year ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 ## 2 Adelie Torgersen 39.5 17.4 186 3800 fema… 2007 ## 3 Adelie Torgersen 40.3 18 195 3250 fema… 2007 ## 4 Adelie Torgersen NA NA NA NA \u0026lt;NA\u0026gt; 2007 ## 5 Adelie Torgersen 36.7 19.3 193 3450 fema… 2007 ## 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 ## # … with abbreviated variable names ¹​flipper_length_mm, ²​body_mass_g Achtung:\nWenn Sie das Paket palmerpenguins nicht mit library() gestartet haben, dann wird data(penguins) nicht funktionieren.\nAd 2)\nWenn Sie die Datei heruntergeladen haben und in Ihrem (aktuellen) RStudio-Projektordner abgespeichert haben, dann (und nur dann) können Sie sie ohne Angabe eines Pfades in R importieren:\nd \u0026lt;- read_csv(\u0026quot;penguins.csv\u0026quot;) # die Datei muss im aktuellen Verzeichnis liegen Categories:\n qm1 qm2   ","permalink":"https://datenwerk.netlify.app/post/pfad/pfad/","summary":"Exercise Recherchieren Sie den Datensatz “Palmer Penguins” als CSV-Datei im Internet.\nImportieren Sie die Datendatei in R von einer geeigneten Online-Quelle. Laden Sie die Datendatei herunter, speichern Sie Sie in den Ordner Ihres aktuellen RStudio-Projekts. Dann importieren Sie die Datendatei in R von diesem Ort.           \n Solution library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ── ## ✔ ggplot2 3.","title":"Pfad"},{"content":" Exercise Melden Sie sich an für die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?.\nSie benötigen dazu ein Konto; es ist auch möglich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Prädiktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verfügung. Eine klassische “predictive Competition” also :-) Allerdings können immer ein paar Schwierigkeiten auftreten ;-)\nAufgabe\nErstellen Sie ein Random-Forest-Modell mit Tidymodels! Reichen Sie es bei Kaggle ein un berichten Sie den Score!\nHinweise\n Verzichten Sie auf Vorverarbeitung.\n Tunen Sie die typischen Parameter.\n Begrenzen Sie sich auf folgende Prädiktoren.\n  preds_chosen \u0026lt;- c(\u0026quot;id\u0026quot;, \u0026quot;budget\u0026quot;, \u0026quot;popularity\u0026quot;, \u0026quot;runtime\u0026quot;)  Ausnahme: Log-transformieren Sie budget. Tunen Sie die typischen Parameter. Reichen Sie das Modell ein und berichten Sie Ihren Score.  preds_chosen \u0026lt;- c(\u0026quot;id\u0026quot;, \u0026quot;budget\u0026quot;, \u0026quot;popularity\u0026quot;, \u0026quot;runtime\u0026quot;, \u0026quot;status\u0026quot;, \u0026quot;revenue\u0026quot;)          \n Solution Pakete starten library(tidyverse) library(tidymodels) library(tictoc)  Daten importieren d_train_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\u0026quot; d_test_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\u0026quot; d_train \u0026lt;- read_csv(d_train_path) d_test \u0026lt;- read_csv(d_test_path) Werfen wir einen Blick in die Daten:\nglimpse(d_train) ## Rows: 3,000 ## Columns: 23 ## $ id \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1… ## $ belongs_to_collection \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 313576, \u0026#39;name\u0026#39;: \u0026#39;Hot Tub Time Machine C… ## $ budget \u0026lt;dbl\u0026gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00… ## $ genres \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 35, \u0026#39;name\u0026#39;: \u0026#39;Comedy\u0026#39;}]\u0026quot;, \u0026quot;[{\u0026#39;id\u0026#39;: 35, \u0026#39;… ## $ homepage \u0026lt;chr\u0026gt; NA, NA, \u0026quot;http://sonyclassics.com/whiplash/\u0026quot;, \u0026quot;ht… ## $ imdb_id \u0026lt;chr\u0026gt; \u0026quot;tt2637294\u0026quot;, \u0026quot;tt0368933\u0026quot;, \u0026quot;tt2582802\u0026quot;, \u0026quot;tt182148… ## $ original_language \u0026lt;chr\u0026gt; \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;hi\u0026quot;, \u0026quot;ko\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, … ## $ original_title \u0026lt;chr\u0026gt; \u0026quot;Hot Tub Time Machine 2\u0026quot;, \u0026quot;The Princess Diaries … ## $ overview \u0026lt;chr\u0026gt; \u0026quot;When Lou, who has become the \\\u0026quot;father of the In… ## $ popularity \u0026lt;dbl\u0026gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807… ## $ poster_path \u0026lt;chr\u0026gt; \u0026quot;/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\u0026quot;, \u0026quot;/w9Z7A0GHEh… ## $ production_companies \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;name\u0026#39;: \u0026#39;Paramount Pictures\u0026#39;, \u0026#39;id\u0026#39;: 4}, {\u0026#39;nam… ## $ production_countries \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_3166_1\u0026#39;: \u0026#39;US\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;United States of… ## $ release_date \u0026lt;chr\u0026gt; \u0026quot;2/20/15\u0026quot;, \u0026quot;8/6/04\u0026quot;, \u0026quot;10/10/14\u0026quot;, \u0026quot;3/9/12\u0026quot;, \u0026quot;2/5/… ## $ runtime \u0026lt;dbl\u0026gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119… ## $ spoken_languages \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_639_1\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;English\u0026#39;}]\u0026quot;, \u0026quot;[{\u0026#39;… ## $ status \u0026lt;chr\u0026gt; \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, … ## $ tagline \u0026lt;chr\u0026gt; \u0026quot;The Laws of Space and Time are About to be Viol… ## $ title \u0026lt;chr\u0026gt; \u0026quot;Hot Tub Time Machine 2\u0026quot;, \u0026quot;The Princess Diaries … ## $ Keywords \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 4379, \u0026#39;name\u0026#39;: \u0026#39;time travel\u0026#39;}, {\u0026#39;id\u0026#39;: 96… ## $ cast \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;cast_id\u0026#39;: 4, \u0026#39;character\u0026#39;: \u0026#39;Lou\u0026#39;, \u0026#39;credit_id\u0026#39;… ## $ crew \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;credit_id\u0026#39;: \u0026#39;59ac067c92514107af02c8c8\u0026#39;, \u0026#39;dep… ## $ revenue \u0026lt;dbl\u0026gt; 12314651, 95149435, 13092000, 16000000, 3923970,… glimpse(d_test) ## Rows: 4,398 ## Columns: 22 ## $ id \u0026lt;dbl\u0026gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, … ## $ belongs_to_collection \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 34055, \u0026#39;name\u0026#39;: \u0026#39;Pokémon Collection\u0026#39;, \u0026#39;p… ## $ budget \u0026lt;dbl\u0026gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06… ## $ genres \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 12, \u0026#39;name\u0026#39;: \u0026#39;Adventure\u0026#39;}, {\u0026#39;id\u0026#39;: 16, \u0026#39;n… ## $ homepage \u0026lt;chr\u0026gt; \u0026quot;http://www.pokemon.com/us/movies/movie-pokemon-… ## $ imdb_id \u0026lt;chr\u0026gt; \u0026quot;tt1226251\u0026quot;, \u0026quot;tt0051380\u0026quot;, \u0026quot;tt0118556\u0026quot;, \u0026quot;tt125595… ## $ original_language \u0026lt;chr\u0026gt; \u0026quot;ja\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;fr\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;de\u0026quot;, \u0026quot;en\u0026quot;, … ## $ original_title \u0026lt;chr\u0026gt; \u0026quot;ディアルガVSパルキアVSダークライ\u0026quot;, \u0026quot;Attack of t… ## $ overview \u0026lt;chr\u0026gt; \u0026quot;Ash and friends (this time accompanied by newco… ## $ popularity \u0026lt;dbl\u0026gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680… ## $ poster_path \u0026lt;chr\u0026gt; \u0026quot;/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\u0026quot;, \u0026quot;/9MgBNBqlH1… ## $ production_companies \u0026lt;chr\u0026gt; NA, \u0026quot;[{\u0026#39;name\u0026#39;: \u0026#39;Woolner Brothers Pictures Inc.\u0026#39;,… ## $ production_countries \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_3166_1\u0026#39;: \u0026#39;JP\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Japan\u0026#39;}, {\u0026#39;iso_3… ## $ release_date \u0026lt;chr\u0026gt; \u0026quot;7/14/07\u0026quot;, \u0026quot;5/19/58\u0026quot;, \u0026quot;5/23/97\u0026quot;, \u0026quot;9/4/10\u0026quot;, \u0026quot;2/11… ## $ runtime \u0026lt;dbl\u0026gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,… ## $ spoken_languages \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_639_1\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;English\u0026#39;}, {\u0026#39;iso_… ## $ status \u0026lt;chr\u0026gt; \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, … ## $ tagline \u0026lt;chr\u0026gt; \u0026quot;Somewhere Between Time \u0026amp; Space... A Legend Is B… ## $ title \u0026lt;chr\u0026gt; \u0026quot;Pokémon: The Rise of Darkrai\u0026quot;, \u0026quot;Attack of the 5… ## $ Keywords \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 11451, \u0026#39;name\u0026#39;: \u0026#39;pok√©mon\u0026#39;}, {\u0026#39;id\u0026#39;: 1155… ## $ cast \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;cast_id\u0026#39;: 3, \u0026#39;character\u0026#39;: \u0026#39;Tonio\u0026#39;, \u0026#39;credit_i… ## $ crew \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;credit_id\u0026#39;: \u0026#39;52fe44e7c3a368484e03d683\u0026#39;, \u0026#39;dep… preds_chosen sind alle Prädiktoren im Datensatz, oder nicht? Das prüfen wir mal kurz:\npreds_chosen %in% names(d_train) %\u0026gt;% all() ## [1] TRUE Ja, alle Elemente von preds_chosen sind Prädiktoren im (Train-)Datensatz.\nCV Nur um Zeit zu sparen, setzen wir die Anzahl der Folds auf \\(v=2\\). Besser wäre z.B. \\(v=10\\).\ncv_scheme \u0026lt;- vfold_cv(d_train, v = 2)   Rezept 1 rec1 \u0026lt;- recipe(revenue ~ budget + popularity + runtime, data = d_train) %\u0026gt;% step_impute_bag(all_predictors()) %\u0026gt;% step_naomit(all_predictors())  Man beachte, dass noch 21 Prädiktoren angezeigt werden, da das Rezept noch nicht auf den Datensatz angewandt (“gebacken”) wurde.\ntidy(rec1) ## # A tibble: 2 × 6 ## number operation type trained skip id ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 step impute_bag FALSE FALSE impute_bag_bhigA ## 2 2 step naomit FALSE FALSE naomit_rc6Nt Rezept checken:\nprep(rec1) ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 3 ## ## Training data contained 3000 data points and 2 incomplete rows. ## ## Operations: ## ## Bagged tree imputation for budget, popularity, runtime [trained] ## Removing rows with NA values in budget, popularity, runtime [trained] d_train_baked \u0026lt;- rec1 %\u0026gt;% prep() %\u0026gt;% bake(new_data = NULL) glimpse(d_train_baked) ## Rows: 3,000 ## Columns: 4 ## $ budget \u0026lt;dbl\u0026gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00, 8.00e+06,… ## $ popularity \u0026lt;dbl\u0026gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.148070, 0.743274… ## $ runtime \u0026lt;dbl\u0026gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119, 98, 122, … ## $ revenue \u0026lt;dbl\u0026gt; 12314651, 95149435, 13092000, 16000000, 3923970, 3261638, 8… Fehlende Werte noch übrig?\nlibrary(easystats) describe_distribution(d_train_baked) %\u0026gt;% select(Variable, n_Missing) ## Variable | n_Missing ## ---------------------- ## budget | 0 ## popularity | 0 ## runtime | 0 ## revenue | 0  Modell 1: RF model1 \u0026lt;- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %\u0026gt;% set_engine(\u0026#39;ranger\u0026#39;) %\u0026gt;% set_mode(\u0026#39;regression\u0026#39;)  Workflow 1 wf1 \u0026lt;- workflow() %\u0026gt;% add_model(model1) %\u0026gt;% add_recipe(rec1)  Modell fitten (und tunen) doParallel::registerDoParallel(4) tic() rf_fit1 \u0026lt;- wf1 %\u0026gt;% tune_grid(resamples = cv_scheme) toc() ## 13.57 sec elapsed rf_fit1[[\u0026quot;.notes\u0026quot;]][1] ## [[1]] ## # A tibble: 0 × 3 ## # … with 3 variables: location \u0026lt;chr\u0026gt;, type \u0026lt;chr\u0026gt;, note \u0026lt;chr\u0026gt;  Bester Kandidat select_best(rf_fit1) ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. ## # A tibble: 1 × 4 ## mtry trees min_n .config ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 771 2 Preprocessor1_Model10  Workflow finalisieren wf_best \u0026lt;- wf1 %\u0026gt;% finalize_workflow(parameters = select_best(rf_fit1)) ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used.  Final Fit fit1_final \u0026lt;- wf_best %\u0026gt;% fit(d_train) fit1_final ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: rand_forest() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 2 Recipe Steps ## ## • step_impute_bag() ## • step_naomit() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Ranger result ## ## Call: ## ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~1L, x), num.trees = ~771L, min.node.size = min_rows(~2L, x), num.threads = 1, verbose = FALSE, seed = sample.int(10^5, 1)) ## ## Type: Regression ## Number of trees: 771 ## Sample size: 3000 ## Number of independent variables: 3 ## Mtry: 1 ## Target node size: 2 ## Variable importance mode: none ## Splitrule: variance ## OOB prediction error (MSE): 6.639131e+15 ## R squared (OOB): 0.6490044 preds \u0026lt;- fit1_final %\u0026gt;% predict(d_test)  Submission df submission_df \u0026lt;- d_test %\u0026gt;% select(id) %\u0026gt;% bind_cols(preds) %\u0026gt;% rename(revenue = .pred) head(submission_df) ## # A tibble: 6 × 2 ## id revenue ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 3001 5157473. ## 2 3002 4996976. ## 3 3003 12409959. ## 4 3004 33843887. ## 5 3005 4126338. ## 6 3006 21314865. Abspeichern und einreichen:\n#write_csv(submission_df, file = \u0026quot;submission.csv\u0026quot;)  Kaggle Score Diese Submission erzielte einen Score von Score: 2.76961 (RMSLE).\nsol \u0026lt;- 2.76961 Categories:\n ds1 21ss    ","permalink":"https://datenwerk.netlify.app/post/tmdb01/tmdb01/","summary":"Exercise Melden Sie sich an für die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?.\nSie benötigen dazu ein Konto; es ist auch möglich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Prädiktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verfügung. Eine klassische “predictive Competition” also :-) Allerdings können immer ein paar Schwierigkeiten auftreten ;-)","title":"tmdb01"},{"content":" Exercise Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall für Filme.\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\nd_train_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\u0026quot; d_test_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\u0026quot; Aufgabe Reichen Sie bei Kaggle eine Submission für die Fallstudie ein! Berichten Sie den Kaggle-Score\nHinweise:\n Sie müssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym möglich); alternativ können Sie sich mit einem Google-Konto anmelden. Berechnen Sie einen Entscheidungsbaum und einen Random-Forest. Tunen Sie nach Bedarf; verwenden Sie aber Default-Werte. Verwenden Sie Tidymodels.           \n  Solution Vorbereitung library(tidyverse) library(tidymodels) library(tictoc) d_train \u0026lt;- read_csv(d_train_path) d_test \u0026lt;- read_csv(d_test_path) glimpse(d_train) ## Rows: 3,000 ## Columns: 23 ## $ id \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1… ## $ belongs_to_collection \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 313576, \u0026#39;name\u0026#39;: \u0026#39;Hot Tub Time Machine C… ## $ budget \u0026lt;dbl\u0026gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00… ## $ genres \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 35, \u0026#39;name\u0026#39;: \u0026#39;Comedy\u0026#39;}]\u0026quot;, \u0026quot;[{\u0026#39;id\u0026#39;: 35, \u0026#39;… ## $ homepage \u0026lt;chr\u0026gt; NA, NA, \u0026quot;http://sonyclassics.com/whiplash/\u0026quot;, \u0026quot;ht… ## $ imdb_id \u0026lt;chr\u0026gt; \u0026quot;tt2637294\u0026quot;, \u0026quot;tt0368933\u0026quot;, \u0026quot;tt2582802\u0026quot;, \u0026quot;tt182148… ## $ original_language \u0026lt;chr\u0026gt; \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;hi\u0026quot;, \u0026quot;ko\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, … ## $ original_title \u0026lt;chr\u0026gt; \u0026quot;Hot Tub Time Machine 2\u0026quot;, \u0026quot;The Princess Diaries … ## $ overview \u0026lt;chr\u0026gt; \u0026quot;When Lou, who has become the \\\u0026quot;father of the In… ## $ popularity \u0026lt;dbl\u0026gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807… ## $ poster_path \u0026lt;chr\u0026gt; \u0026quot;/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\u0026quot;, \u0026quot;/w9Z7A0GHEh… ## $ production_companies \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;name\u0026#39;: \u0026#39;Paramount Pictures\u0026#39;, \u0026#39;id\u0026#39;: 4}, {\u0026#39;nam… ## $ production_countries \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_3166_1\u0026#39;: \u0026#39;US\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;United States of… ## $ release_date \u0026lt;chr\u0026gt; \u0026quot;2/20/15\u0026quot;, \u0026quot;8/6/04\u0026quot;, \u0026quot;10/10/14\u0026quot;, \u0026quot;3/9/12\u0026quot;, \u0026quot;2/5/… ## $ runtime \u0026lt;dbl\u0026gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119… ## $ spoken_languages \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_639_1\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;English\u0026#39;}]\u0026quot;, \u0026quot;[{\u0026#39;… ## $ status \u0026lt;chr\u0026gt; \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, … ## $ tagline \u0026lt;chr\u0026gt; \u0026quot;The Laws of Space and Time are About to be Viol… ## $ title \u0026lt;chr\u0026gt; \u0026quot;Hot Tub Time Machine 2\u0026quot;, \u0026quot;The Princess Diaries … ## $ Keywords \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 4379, \u0026#39;name\u0026#39;: \u0026#39;time travel\u0026#39;}, {\u0026#39;id\u0026#39;: 96… ## $ cast \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;cast_id\u0026#39;: 4, \u0026#39;character\u0026#39;: \u0026#39;Lou\u0026#39;, \u0026#39;credit_id\u0026#39;… ## $ crew \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;credit_id\u0026#39;: \u0026#39;59ac067c92514107af02c8c8\u0026#39;, \u0026#39;dep… ## $ revenue \u0026lt;dbl\u0026gt; 12314651, 95149435, 13092000, 16000000, 3923970,… glimpse(d_test) ## Rows: 4,398 ## Columns: 22 ## $ id \u0026lt;dbl\u0026gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, … ## $ belongs_to_collection \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 34055, \u0026#39;name\u0026#39;: \u0026#39;Pokémon Collection\u0026#39;, \u0026#39;p… ## $ budget \u0026lt;dbl\u0026gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06… ## $ genres \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 12, \u0026#39;name\u0026#39;: \u0026#39;Adventure\u0026#39;}, {\u0026#39;id\u0026#39;: 16, \u0026#39;n… ## $ homepage \u0026lt;chr\u0026gt; \u0026quot;http://www.pokemon.com/us/movies/movie-pokemon-… ## $ imdb_id \u0026lt;chr\u0026gt; \u0026quot;tt1226251\u0026quot;, \u0026quot;tt0051380\u0026quot;, \u0026quot;tt0118556\u0026quot;, \u0026quot;tt125595… ## $ original_language \u0026lt;chr\u0026gt; \u0026quot;ja\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;fr\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;de\u0026quot;, \u0026quot;en\u0026quot;, … ## $ original_title \u0026lt;chr\u0026gt; \u0026quot;ディアルガVSパルキアVSダークライ\u0026quot;, \u0026quot;Attack of t… ## $ overview \u0026lt;chr\u0026gt; \u0026quot;Ash and friends (this time accompanied by newco… ## $ popularity \u0026lt;dbl\u0026gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680… ## $ poster_path \u0026lt;chr\u0026gt; \u0026quot;/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\u0026quot;, \u0026quot;/9MgBNBqlH1… ## $ production_companies \u0026lt;chr\u0026gt; NA, \u0026quot;[{\u0026#39;name\u0026#39;: \u0026#39;Woolner Brothers Pictures Inc.\u0026#39;,… ## $ production_countries \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_3166_1\u0026#39;: \u0026#39;JP\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Japan\u0026#39;}, {\u0026#39;iso_3… ## $ release_date \u0026lt;chr\u0026gt; \u0026quot;7/14/07\u0026quot;, \u0026quot;5/19/58\u0026quot;, \u0026quot;5/23/97\u0026quot;, \u0026quot;9/4/10\u0026quot;, \u0026quot;2/11… ## $ runtime \u0026lt;dbl\u0026gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,… ## $ spoken_languages \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_639_1\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;English\u0026#39;}, {\u0026#39;iso_… ## $ status \u0026lt;chr\u0026gt; \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, … ## $ tagline \u0026lt;chr\u0026gt; \u0026quot;Somewhere Between Time \u0026amp; Space... A Legend Is B… ## $ title \u0026lt;chr\u0026gt; \u0026quot;Pokémon: The Rise of Darkrai\u0026quot;, \u0026quot;Attack of the 5… ## $ Keywords \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 11451, \u0026#39;name\u0026#39;: \u0026#39;pok√©mon\u0026#39;}, {\u0026#39;id\u0026#39;: 1155… ## $ cast \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;cast_id\u0026#39;: 3, \u0026#39;character\u0026#39;: \u0026#39;Tonio\u0026#39;, \u0026#39;credit_i… ## $ crew \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;credit_id\u0026#39;: \u0026#39;52fe44e7c3a368484e03d683\u0026#39;, \u0026#39;dep…  Rezept Rezept definieren rec1 \u0026lt;- recipe(revenue ~ ., data = d_train) %\u0026gt;% update_role(all_predictors(), new_role = \u0026quot;id\u0026quot;) %\u0026gt;% update_role(popularity, runtime, revenue, budget) %\u0026gt;% update_role(revenue, new_role = \u0026quot;outcome\u0026quot;) %\u0026gt;% step_mutate(budget = ifelse(budget \u0026lt; 10, 10, budget)) %\u0026gt;% step_log(budget) %\u0026gt;% step_impute_knn(all_predictors()) rec1 ## Recipe ## ## Inputs: ## ## role #variables ## id 19 ## outcome 1 ## predictor 3 ## ## Operations: ## ## Variable mutation for ifelse(budget \u0026lt; 10, 10, budget) ## Log transformation on budget ## K-nearest neighbor imputation for all_predictors()  Check das Rezept rec1_prepped \u0026lt;- prep(rec1, verbose = TRUE) ## oper 1 step mutate [training] ## oper 2 step log [training] ## oper 3 step impute knn [training] ## The retained training set is ~ 28.71 Mb in memory. rec1_prepped ## Recipe ## ## Inputs: ## ## role #variables ## id 19 ## outcome 1 ## predictor 3 ## ## Training data contained 3000 data points and 2793 incomplete rows. ## ## Operations: ## ## Variable mutation for ~ifelse(budget \u0026lt; 10, 10, budget) [trained] ## Log transformation on budget [trained] ## K-nearest neighbor imputation for budget, popularity, runtime [trained] d_train_baked \u0026lt;- rec1_prepped %\u0026gt;% bake(new_data = NULL) head(d_train_baked) ## # A tibble: 6 × 23 ## id belongs_…¹ budget genres homep…² imdb_id origi…³ origi…⁴ overv…⁵ popul…⁶ ## \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 [{\u0026#39;id\u0026#39;: 3… 16.5 [{\u0026#39;id… \u0026lt;NA\u0026gt; tt2637… en Hot Tu… \u0026quot;When … 6.58 ## 2 2 [{\u0026#39;id\u0026#39;: 1… 17.5 [{\u0026#39;id… \u0026lt;NA\u0026gt; tt0368… en The Pr… \u0026quot;Mia T… 8.25 ## 3 3 \u0026lt;NA\u0026gt; 15.0 [{\u0026#39;id… http:/… tt2582… en Whipla… \u0026quot;Under… 64.3 ## 4 4 \u0026lt;NA\u0026gt; 14.0 [{\u0026#39;id… http:/… tt1821… hi Kahaani \u0026quot;Vidya… 3.17 ## 5 5 \u0026lt;NA\u0026gt; 2.30 [{\u0026#39;id… \u0026lt;NA\u0026gt; tt1380… ko 마린보… \u0026quot;Marin… 1.15 ## 6 6 \u0026lt;NA\u0026gt; 15.9 [{\u0026#39;id… \u0026lt;NA\u0026gt; tt0093… en Pinocc… \u0026quot;Pinoc… 0.743 ## # … with 13 more variables: poster_path \u0026lt;fct\u0026gt;, production_companies \u0026lt;fct\u0026gt;, ## # production_countries \u0026lt;fct\u0026gt;, release_date \u0026lt;fct\u0026gt;, runtime \u0026lt;dbl\u0026gt;, ## # spoken_languages \u0026lt;fct\u0026gt;, status \u0026lt;fct\u0026gt;, tagline \u0026lt;fct\u0026gt;, title \u0026lt;fct\u0026gt;, ## # Keywords \u0026lt;fct\u0026gt;, cast \u0026lt;fct\u0026gt;, crew \u0026lt;fct\u0026gt;, revenue \u0026lt;dbl\u0026gt;, and abbreviated ## # variable names ¹​belongs_to_collection, ²​homepage, ³​original_language, ## # ⁴​original_title, ⁵​overview, ⁶​popularity ## # ℹ Use `colnames()` to see all variable names Die AV-Spalte sollte leer sein:\nbake(rec1_prepped, new_data = head(d_test), all_outcomes()) ## # A tibble: 6 × 0 d_train_baked %\u0026gt;% map_df(~ sum(is.na(.))) ## # A tibble: 1 × 23 ## id belongs_…¹ budget genres homep…² imdb_id origi…³ origi…⁴ overv…⁵ popul…⁶ ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 0 2396 0 7 2054 0 0 0 8 0 ## # … with 13 more variables: poster_path \u0026lt;int\u0026gt;, production_companies \u0026lt;int\u0026gt;, ## # production_countries \u0026lt;int\u0026gt;, release_date \u0026lt;int\u0026gt;, runtime \u0026lt;int\u0026gt;, ## # spoken_languages \u0026lt;int\u0026gt;, status \u0026lt;int\u0026gt;, tagline \u0026lt;int\u0026gt;, title \u0026lt;int\u0026gt;, ## # Keywords \u0026lt;int\u0026gt;, cast \u0026lt;int\u0026gt;, crew \u0026lt;int\u0026gt;, revenue \u0026lt;int\u0026gt;, and abbreviated ## # variable names ¹​belongs_to_collection, ²​homepage, ³​original_language, ## # ⁴​original_title, ⁵​overview, ⁶​popularity ## # ℹ Use `colnames()` to see all variable names Keine fehlenden Werte mehr in den Prädiktoren.\nNach fehlenden Werten könnte man z.B. auch so suchen:\ndatawizard::describe_distribution(d_train_baked) ## Variable | Mean | SD | IQR | Range | Skewness | Kurtosis | n | n_Missing ## --------------------------------------------------------------------------------------------------------- ## id | 1500.50 | 866.17 | 1500.50 | [1.00, 3000.00] | 0.00 | -1.20 | 3000 | 0 ## budget | 12.51 | 6.44 | 14.88 | [2.30, 19.76] | -0.87 | -1.09 | 3000 | 0 ## popularity | 8.46 | 12.10 | 6.88 | [1.00e-06, 294.34] | 14.38 | 280.10 | 3000 | 0 ## runtime | 107.85 | 22.08 | 24.00 | [0.00, 338.00] | 1.02 | 8.20 | 3000 | 0 ## revenue | 6.67e+07 | 1.38e+08 | 6.66e+07 | [1.00, 1.52e+09] | 4.54 | 27.78 | 3000 | 0 So bekommt man gleich noch ein paar Infos über die Verteilung der Variablen. Praktische Sache.\nDas Test-Sample backen wir auch mal:\nd_test_baked \u0026lt;- bake(rec1_prepped, new_data = d_test) d_test_baked %\u0026gt;% head() ## # A tibble: 6 × 22 ## id belongs_…¹ budget genres homep…² imdb_id origi…³ origi…⁴ overv…⁵ popul…⁶ ## \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; ## 1 3001 [{\u0026#39;id\u0026#39;: 3… 2.30 [{\u0026#39;id… \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ja \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 3.85 ## 2 3002 \u0026lt;NA\u0026gt; 11.4 [{\u0026#39;id… \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; en \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 3.56 ## 3 3003 \u0026lt;NA\u0026gt; 2.30 [{\u0026#39;id… \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; en \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 8.09 ## 4 3004 \u0026lt;NA\u0026gt; 15.7 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; fr \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 8.60 ## 5 3005 \u0026lt;NA\u0026gt; 14.5 [{\u0026#39;id… \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; en \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 3.22 ## 6 3006 \u0026lt;NA\u0026gt; 2.30 [{\u0026#39;id… \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; en \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 8.68 ## # … with 12 more variables: poster_path \u0026lt;fct\u0026gt;, production_companies \u0026lt;fct\u0026gt;, ## # production_countries \u0026lt;fct\u0026gt;, release_date \u0026lt;fct\u0026gt;, runtime \u0026lt;dbl\u0026gt;, ## # spoken_languages \u0026lt;fct\u0026gt;, status \u0026lt;fct\u0026gt;, tagline \u0026lt;fct\u0026gt;, title \u0026lt;fct\u0026gt;, ## # Keywords \u0026lt;fct\u0026gt;, cast \u0026lt;fct\u0026gt;, crew \u0026lt;fct\u0026gt;, and abbreviated variable names ## # ¹​belongs_to_collection, ²​homepage, ³​original_language, ⁴​original_title, ## # ⁵​overview, ⁶​popularity ## # ℹ Use `colnames()` to see all variable names   Kreuzvalidierung cv_scheme \u0026lt;- vfold_cv(d_train, v = 5, repeats = 1)  Modelle Baum mod_tree \u0026lt;- decision_tree(cost_complexity = tune(), tree_depth = tune(), mode = \u0026quot;regression\u0026quot;)  Random Forest doParallel::registerDoParallel() mod_rf \u0026lt;- rand_forest(mtry = tune(), min_n = tune(), trees = 1000, mode = \u0026quot;regression\u0026quot;) %\u0026gt;% set_engine(\u0026quot;ranger\u0026quot;, num.threads = 4)   Workflows wf_tree \u0026lt;- workflow() %\u0026gt;% add_model(mod_tree) %\u0026gt;% add_recipe(rec1) wf_rf \u0026lt;- workflow() %\u0026gt;% add_model(mod_rf) %\u0026gt;% add_recipe(rec1)  Fitten und tunen Um Rechenzeit zu sparen, kann man den Parameter grid bei tune_grid() auf einen kleinen Wert setzen. Der Default ist 10. Um gute Vorhersagen zu erzielen, sollte man den Wert tendenziell noch über 10 erhöhen.\nTree tic() tree_fit \u0026lt;- wf_tree %\u0026gt;% tune_grid( resamples = cv_scheme, grid = 2 ) toc() ## 3.374 sec elapsed Hilfe zu tune_grid() bekommt man hier.\ntree_fit ## # Tuning results ## # 5-fold cross-validation ## # A tibble: 5 × 4 ## splits id .metrics .notes ## \u0026lt;list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; ## 1 \u0026lt;split [2400/600]\u0026gt; Fold1 \u0026lt;tibble [4 × 6]\u0026gt; \u0026lt;tibble [0 × 3]\u0026gt; ## 2 \u0026lt;split [2400/600]\u0026gt; Fold2 \u0026lt;tibble [4 × 6]\u0026gt; \u0026lt;tibble [0 × 3]\u0026gt; ## 3 \u0026lt;split [2400/600]\u0026gt; Fold3 \u0026lt;tibble [4 × 6]\u0026gt; \u0026lt;tibble [0 × 3]\u0026gt; ## 4 \u0026lt;split [2400/600]\u0026gt; Fold4 \u0026lt;tibble [4 × 6]\u0026gt; \u0026lt;tibble [0 × 3]\u0026gt; ## 5 \u0026lt;split [2400/600]\u0026gt; Fold5 \u0026lt;tibble [4 × 6]\u0026gt; \u0026lt;tibble [0 × 3]\u0026gt; Steht was in den .notes?\ntree_fit[[\u0026quot;.notes\u0026quot;]][[2]] ## # A tibble: 0 × 3 ## # … with 3 variables: location \u0026lt;chr\u0026gt;, type \u0026lt;chr\u0026gt;, note \u0026lt;chr\u0026gt; ## # ℹ Use `colnames()` to see all variable names Nein.\ncollect_metrics(tree_fit) ## # A tibble: 4 × 8 ## cost_complexity tree_depth .metric .estimator mean n std_err .config ## \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 0.00000000100 5 rmse standard 8.59e+7 5 4.68e+6 Prepro… ## 2 0.00000000100 5 rsq standard 6.12e-1 5 2.76e-2 Prepro… ## 3 0.00000781 9 rmse standard 8.76e+7 5 3.86e+6 Prepro… ## 4 0.00000781 9 rsq standard 5.99e-1 5 2.49e-2 Prepro… show_best(tree_fit) ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. ## # A tibble: 2 × 8 ## cost_complexity tree_depth .metric .estimator mean n std_err .config ## \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 0.00000000100 5 rmse standard 85864841. 5 4676421. Prepro… ## 2 0.00000781 9 rmse standard 87647236. 5 3862933. Prepro…   Finalisieren best_tree_wf \u0026lt;- wf_tree %\u0026gt;% finalize_workflow(select_best(tree_fit)) ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. best_tree_wf ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: decision_tree() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 3 Recipe Steps ## ## • step_mutate() ## • step_log() ## • step_impute_knn() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Decision Tree Model Specification (regression) ## ## Main Arguments: ## cost_complexity = 1.00205814434566e-09 ## tree_depth = 5 ## ## Computational engine: rpart tree_last_fit \u0026lt;- fit(best_tree_wf, data = d_train) tree_last_fit ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: decision_tree() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 3 Recipe Steps ## ## • step_mutate() ## • step_log() ## • step_impute_knn() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## n= 3000 ## ## node), split, n, deviance, yval ## * denotes terminal node ## ## 1) root 3000 5.672651e+19 66725850 ## 2) budget\u0026lt; 18.32631 2845 1.958584e+19 46935270 ## 4) budget\u0026lt; 17.19976 2252 5.443953e+18 25901120 ## 8) popularity\u0026lt; 9.734966 1745 1.665118e+18 17076460 ## 16) popularity\u0026lt; 5.761331 1019 3.184962e+17 8793730 ## 32) budget\u0026lt; 15.44456 782 1.408243e+17 6074563 * ## 33) budget\u0026gt;=15.44456 237 1.528117e+17 17765830 * ## 17) popularity\u0026gt;=5.761331 726 1.178595e+18 28701940 ## 34) budget\u0026lt; 16.15249 484 6.504138e+17 21093220 * ## 35) budget\u0026gt;=16.15249 242 4.441208e+17 43919380 * ## 9) popularity\u0026gt;=9.734966 507 3.175231e+18 56273980 ## 18) budget\u0026lt; 15.36217 186 3.092335e+17 24880850 ## 36) popularity\u0026lt; 14.04031 151 1.743659e+17 20728170 * ## 37) popularity\u0026gt;=14.04031 35 1.210294e+17 42796710 * ## 19) budget\u0026gt;=15.36217 321 2.576473e+18 74464390 ## 38) popularity\u0026lt; 19.64394 300 2.025184e+18 68010500 * ## 39) popularity\u0026gt;=19.64394 21 3.602808e+17 166662900 * ## 5) budget\u0026gt;=17.19976 593 9.361685e+18 126815400 ## 10) popularity\u0026lt; 19.63372 570 6.590372e+18 117422100 ## 20) budget\u0026lt; 17.86726 374 2.692151e+18 94469490 ## 40) popularity\u0026lt; 8.444193 149 6.363495e+17 68256660 * ## 41) popularity\u0026gt;=8.444193 225 1.885623e+18 111828200 * ## 21) budget\u0026gt;=17.86726 196 3.325222e+18 161219400 ## 42) popularity\u0026lt; 11.60513 126 1.693483e+18 136587100 * ## 43) popularity\u0026gt;=11.60513 70 1.417677e+18 205557600 * ## 11) popularity\u0026gt;=19.63372 23 1.474624e+18 359605200 ## 22) runtime\u0026gt;=109.5 16 9.882757e+17 299077200 * ## 23) runtime\u0026lt; 109.5 7 2.937458e+17 497955000 * ## 3) budget\u0026gt;=18.32631 155 1.557371e+19 429978800 ## 6) popularity\u0026lt; 17.26579 101 4.711450e+18 299997300 ## 12) budget\u0026lt; 18.73897 67 1.671489e+18 230290900 ## 24) popularity\u0026lt; 12.66146 40 5.426991e+17 174328700 ## 48) budget\u0026lt; 18.44536 18 1.099070e+17 134734600 * ## 49) budget\u0026gt;=18.44536 22 3.814856e+17 206724000 * ## 25) popularity\u0026gt;=12.66146 27 8.179336e+17 313197700 ## 50) budget\u0026lt; 18.52944 13 1.273606e+17 234797100 * ## 51) budget\u0026gt;=18.52944 14 5.364675e+17 385998300 * ## 13) budget\u0026gt;=18.73897 34 2.072879e+18 437360100 ## 26) runtime\u0026lt; 132.5 26 1.123840e+18 391271100 ## 52) popularity\u0026lt; 11.34182 9 9.729505e+16 248614500 * ## 53) popularity\u0026gt;=11.34182 17 7.464210e+17 466795200 * ## 27) runtime\u0026gt;=132.5 8 7.143147e+17 587149400 * ## 7) popularity\u0026gt;=17.26579 54 5.964228e+18 673092200 ## 14) budget\u0026lt; 18.99438 33 2.082469e+18 534404700 ## 28) popularity\u0026lt; 25.35778 19 5.425201e+17 416871200 * ## ## ... ## and 4 more lines.  Vorhersage Test-Sample predict(tree_last_fit, new_data = d_test) ## # A tibble: 4,398 × 1 ## .pred ## \u0026lt;dbl\u0026gt; ## 1 6074563. ## 2 6074563. ## 3 21093221. ## 4 21093221. ## 5 6074563. ## 6 21093221. ## 7 6074563. ## 8 68256659. ## 9 43919378. ## 10 205557624. ## # … with 4,388 more rows ## # ℹ Use `print(n = ...)` to see more rows RF   Fitten und Tunen Um Rechenzeit zu sparen, kann man das Objekt, wenn einmal berechnet, abspeichern unter result_obj_path auf der Festplatte und beim nächsten Mal importieren, das geht schneller als neu berechnen.\nDas könnte dann z.B. so aussehen:\nif (file.exists(result_obj_path)) { rf_fit \u0026lt;- read_rds(result_obj_path) } else { tic() rf_fit \u0026lt;- wf_rf %\u0026gt;% tune_grid( resamples = cv_scheme) toc() } Achtung Ein Ergebnisobjekt von der Festplatte zu laden ist gefährlich. Wenn Sie Ihr Modell verändern, aber vergessen, das Objekt auf der Festplatte zu aktualisieren, werden Ihre Ergebnisse falsch sein (da auf dem veralteten Objekt beruhend), ohne dass Sie durch eine Fehlermeldung von R gewarnt würden!\nSo kann man das Ergebnisobjekt auf die Festplatte schreiben:\n#write_rds(rf_fit, file = \u0026quot;objects/tmbd_rf_fit1.rds\u0026quot;) Aber wir berechnen lieber neu:\ntic() rf_fit \u0026lt;- wf_rf %\u0026gt;% tune_grid( resamples = cv_scheme, grid = 2) toc() ## 8.623 sec elapsed collect_metrics(rf_fit) ## # A tibble: 4 × 8 ## mtry min_n .metric .estimator mean n std_err .config ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 2 11 rmse standard 82295157. 5 5357246. Preprocessor1_… ## 2 2 11 rsq standard 0.640 5 0.0232 Preprocessor1_… ## 3 3 30 rmse standard 82406352. 5 5356881. Preprocessor1_… ## 4 3 30 rsq standard 0.640 5 0.0249 Preprocessor1_… select_best(rf_fit) ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. ## # A tibble: 1 × 3 ## mtry min_n .config ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; ## 1 2 11 Preprocessor1_Model1  Finalisieren final_wf \u0026lt;- wf_rf %\u0026gt;% finalize_workflow(select_best(rf_fit)) ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. final_fit \u0026lt;- fit(final_wf, data = d_train) final_preds \u0026lt;- final_fit %\u0026gt;% predict(new_data = d_test) %\u0026gt;% bind_cols(d_test) submission \u0026lt;- final_preds %\u0026gt;% select(id, revenue = .pred) Abspeichern und einreichen:\nwrite_csv(submission, file = \u0026quot;submission.csv\u0026quot;)  Kaggle Score Diese Submission erzielte einen Score von 2.7664 (RMSLE).\nsol \u0026lt;- 2.7664 Categories:\n ds1 21ss    ","permalink":"https://datenwerk.netlify.app/post/tmdb02/tmdb02/","summary":"Exercise Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall für Filme.\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\nd_train_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\u0026quot; d_test_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\u0026quot; Aufgabe Reichen Sie bei Kaggle eine Submission für die Fallstudie ein! Berichten Sie den Kaggle-Score\nHinweise:\n Sie müssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym möglich); alternativ können Sie sich mit einem Google-Konto anmelden.","title":"tmdb02"},{"content":" result_obj_file \u0026lt;- \u0026quot;tmdb_model_set.rds\u0026quot; result_obj_path \u0026lt;- \u0026quot;/Users/sebastiansaueruser/github-repos/rexams-exercises/objects/tmdb_model_set.rds\u0026quot; #exams::include_supplement(file = result_obj_file, # recursive = TRUE) # tmdb_model_set \u0026lt;- readr::read_rds(\u0026quot;tmdb_model_set.rds\u0026quot;) #tmdb_model_set \u0026lt;- readr::read_rds(result_obj_path) Exercise Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall für Filme.\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\nd_train_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\u0026quot; d_test_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\u0026quot;  Aufgabe Reichen Sie bei Kaggle eine Submission für die Fallstudie ein! Berichten Sie den Score!\nHinweise:\n Sie müssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym möglich); alternativ können Sie sich mit einem Google-Konto anmelden. Verwenden Sie mehrere, und zwar folgende Algorithmen: Random Forest, Boosting, lineare Regression. Tipp: Ein Workflow-Set ist hilfreich. Logarithmieren Sie budget. Betreiben Sie Feature Engineering, zumindest etwas. Insbesondere sollten Sie den Monat und das Jahr aus dem Datum extrahieren und als Features (Prädiktoren) nutzen. Verwenden Sie tidymodels. Die Zielgröße ist revenue in Dollars; nicht in “Log-Dollars”. Sie müssen also rücktransformieren, falls Sie revenue logarithmiert haben.           \n Solution Vorbereitung\nlibrary(tidyverse) library(tidymodels) library(tictoc) # Rechenzeit messen #library(Metrics) library(lubridate) # Datumsangaben library(VIM) # fehlende Werte library(visdat) # Datensatz visualisieren d_train_raw \u0026lt;- read_csv(d_train_path) d_test \u0026lt;- read_csv(d_test_path) Mal einen Blick werfen:\nglimpse(d_train_raw) ## Rows: 3,000 ## Columns: 23 ## $ id \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1… ## $ belongs_to_collection \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 313576, \u0026#39;name\u0026#39;: \u0026#39;Hot Tub Time Machine C… ## $ budget \u0026lt;dbl\u0026gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00… ## $ genres \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 35, \u0026#39;name\u0026#39;: \u0026#39;Comedy\u0026#39;}]\u0026quot;, \u0026quot;[{\u0026#39;id\u0026#39;: 35, \u0026#39;… ## $ homepage \u0026lt;chr\u0026gt; NA, NA, \u0026quot;http://sonyclassics.com/whiplash/\u0026quot;, \u0026quot;ht… ## $ imdb_id \u0026lt;chr\u0026gt; \u0026quot;tt2637294\u0026quot;, \u0026quot;tt0368933\u0026quot;, \u0026quot;tt2582802\u0026quot;, \u0026quot;tt182148… ## $ original_language \u0026lt;chr\u0026gt; \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;hi\u0026quot;, \u0026quot;ko\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, … ## $ original_title \u0026lt;chr\u0026gt; \u0026quot;Hot Tub Time Machine 2\u0026quot;, \u0026quot;The Princess Diaries … ## $ overview \u0026lt;chr\u0026gt; \u0026quot;When Lou, who has become the \\\u0026quot;father of the In… ## $ popularity \u0026lt;dbl\u0026gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807… ## $ poster_path \u0026lt;chr\u0026gt; \u0026quot;/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\u0026quot;, \u0026quot;/w9Z7A0GHEh… ## $ production_companies \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;name\u0026#39;: \u0026#39;Paramount Pictures\u0026#39;, \u0026#39;id\u0026#39;: 4}, {\u0026#39;nam… ## $ production_countries \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_3166_1\u0026#39;: \u0026#39;US\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;United States of… ## $ release_date \u0026lt;chr\u0026gt; \u0026quot;2/20/15\u0026quot;, \u0026quot;8/6/04\u0026quot;, \u0026quot;10/10/14\u0026quot;, \u0026quot;3/9/12\u0026quot;, \u0026quot;2/5/… ## $ runtime \u0026lt;dbl\u0026gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119… ## $ spoken_languages \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_639_1\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;English\u0026#39;}]\u0026quot;, \u0026quot;[{\u0026#39;… ## $ status \u0026lt;chr\u0026gt; \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, … ## $ tagline \u0026lt;chr\u0026gt; \u0026quot;The Laws of Space and Time are About to be Viol… ## $ title \u0026lt;chr\u0026gt; \u0026quot;Hot Tub Time Machine 2\u0026quot;, \u0026quot;The Princess Diaries … ## $ Keywords \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 4379, \u0026#39;name\u0026#39;: \u0026#39;time travel\u0026#39;}, {\u0026#39;id\u0026#39;: 96… ## $ cast \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;cast_id\u0026#39;: 4, \u0026#39;character\u0026#39;: \u0026#39;Lou\u0026#39;, \u0026#39;credit_id\u0026#39;… ## $ crew \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;credit_id\u0026#39;: \u0026#39;59ac067c92514107af02c8c8\u0026#39;, \u0026#39;dep… ## $ revenue \u0026lt;dbl\u0026gt; 12314651, 95149435, 13092000, 16000000, 3923970,… glimpse(d_test) ## Rows: 4,398 ## Columns: 22 ## $ id \u0026lt;dbl\u0026gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, … ## $ belongs_to_collection \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 34055, \u0026#39;name\u0026#39;: \u0026#39;Pokémon Collection\u0026#39;, \u0026#39;p… ## $ budget \u0026lt;dbl\u0026gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06… ## $ genres \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 12, \u0026#39;name\u0026#39;: \u0026#39;Adventure\u0026#39;}, {\u0026#39;id\u0026#39;: 16, \u0026#39;n… ## $ homepage \u0026lt;chr\u0026gt; \u0026quot;http://www.pokemon.com/us/movies/movie-pokemon-… ## $ imdb_id \u0026lt;chr\u0026gt; \u0026quot;tt1226251\u0026quot;, \u0026quot;tt0051380\u0026quot;, \u0026quot;tt0118556\u0026quot;, \u0026quot;tt125595… ## $ original_language \u0026lt;chr\u0026gt; \u0026quot;ja\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;fr\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;de\u0026quot;, \u0026quot;en\u0026quot;, … ## $ original_title \u0026lt;chr\u0026gt; \u0026quot;ディアルガVSパルキアVSダークライ\u0026quot;, \u0026quot;Attack of t… ## $ overview \u0026lt;chr\u0026gt; \u0026quot;Ash and friends (this time accompanied by newco… ## $ popularity \u0026lt;dbl\u0026gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680… ## $ poster_path \u0026lt;chr\u0026gt; \u0026quot;/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\u0026quot;, \u0026quot;/9MgBNBqlH1… ## $ production_companies \u0026lt;chr\u0026gt; NA, \u0026quot;[{\u0026#39;name\u0026#39;: \u0026#39;Woolner Brothers Pictures Inc.\u0026#39;,… ## $ production_countries \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_3166_1\u0026#39;: \u0026#39;JP\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Japan\u0026#39;}, {\u0026#39;iso_3… ## $ release_date \u0026lt;chr\u0026gt; \u0026quot;7/14/07\u0026quot;, \u0026quot;5/19/58\u0026quot;, \u0026quot;5/23/97\u0026quot;, \u0026quot;9/4/10\u0026quot;, \u0026quot;2/11… ## $ runtime \u0026lt;dbl\u0026gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,… ## $ spoken_languages \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_639_1\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;English\u0026#39;}, {\u0026#39;iso_… ## $ status \u0026lt;chr\u0026gt; \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, … ## $ tagline \u0026lt;chr\u0026gt; \u0026quot;Somewhere Between Time \u0026amp; Space... A Legend Is B… ## $ title \u0026lt;chr\u0026gt; \u0026quot;Pokémon: The Rise of Darkrai\u0026quot;, \u0026quot;Attack of the 5… ## $ Keywords \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 11451, \u0026#39;name\u0026#39;: \u0026#39;pok√©mon\u0026#39;}, {\u0026#39;id\u0026#39;: 1155… ## $ cast \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;cast_id\u0026#39;: 3, \u0026#39;character\u0026#39;: \u0026#39;Tonio\u0026#39;, \u0026#39;credit_i… ## $ crew \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;credit_id\u0026#39;: \u0026#39;52fe44e7c3a368484e03d683\u0026#39;, \u0026#39;dep… Train-Set verschlanken\nd_train \u0026lt;- d_train_raw %\u0026gt;% select(popularity, runtime, revenue, budget, release_date)  Datensatz kennenlernen\nlibrary(visdat) vis_dat(d_train) ## Warning: `gather_()` was deprecated in tidyr 1.2.0. ## Please use `gather()` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. Fehlende Werte prüfen\nWelche Spalten haben viele fehlende Werte?\nvis_miss(d_train) Mit {VIM} kann man einen Datensatz gut auf fehlende Werte hin untersuchen:\naggr(d_train) Rezept definieren\nrec1 \u0026lt;- recipe(revenue ~ ., data = d_train) %\u0026gt;% #update_role(all_predictors(), new_role = \u0026quot;id\u0026quot;) %\u0026gt;% #update_role(popularity, runtime, revenue, budget, original_language) %\u0026gt;% #update_role(revenue, new_role = \u0026quot;outcome\u0026quot;) %\u0026gt;% step_mutate(budget = if_else(budget \u0026lt; 10, 10, budget)) %\u0026gt;% step_log(budget) %\u0026gt;% step_mutate(release_date = mdy(release_date)) %\u0026gt;% step_date(release_date, features = c(\u0026quot;year\u0026quot;, \u0026quot;month\u0026quot;), keep_original_cols = FALSE) %\u0026gt;% step_impute_knn(all_predictors()) %\u0026gt;% step_dummy(all_nominal()) rec1 ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 4 ## ## Operations: ## ## Variable mutation for if_else(budget \u0026lt; 10, 10, budget) ## Log transformation on budget ## Variable mutation for mdy(release_date) ## Date features from release_date ## K-nearest neighbor imputation for all_predictors() ## Dummy variables from all_nominal() tidy(rec1) ## # A tibble: 6 × 6 ## number operation type trained skip id ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 step mutate FALSE FALSE mutate_AXiBI ## 2 2 step log FALSE FALSE log_mpbrN ## 3 3 step mutate FALSE FALSE mutate_uLpTz ## 4 4 step date FALSE FALSE date_rthRQ ## 5 5 step impute_knn FALSE FALSE impute_knn_e9pAc ## 6 6 step dummy FALSE FALSE dummy_qnnVe Check das Rezept \nprep(rec1, verbose = TRUE) ## oper 1 step mutate [training] ## oper 2 step log [training] ## oper 3 step mutate [training] ## oper 4 step date [training] ## oper 5 step impute knn [training] ## oper 6 step dummy [training] ## The retained training set is ~ 0.38 Mb in memory. ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 4 ## ## Training data contained 3000 data points and 2 incomplete rows. ## ## Operations: ## ## Variable mutation for ~if_else(budget \u0026lt; 10, 10, budget) [trained] ## Log transformation on budget [trained] ## Variable mutation for ~mdy(release_date) [trained] ## Date features from release_date [trained] ## K-nearest neighbor imputation for runtime, budget, release_date_year, release_da... [trained] ## Dummy variables from release_date_month [trained] d_train_baked \u0026lt;- prep(rec1) %\u0026gt;% bake(new_data = NULL) d_train_baked ## # A tibble: 3,000 × 16 ## popularity runtime budget revenue release_date_year release_date_month_Feb ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 6.58 93 16.5 12314651 2015 1 ## 2 8.25 113 17.5 95149435 2004 0 ## 3 64.3 105 15.0 13092000 2014 0 ## 4 3.17 122 14.0 16000000 2012 0 ## 5 1.15 118 2.30 3923970 2009 1 ## 6 0.743 83 15.9 3261638 1987 0 ## 7 7.29 92 16.5 85446075 2012 0 ## 8 1.95 84 2.30 2586511 2004 0 ## 9 6.90 100 2.30 34327391 1996 1 ## 10 4.67 91 15.6 18750246 2003 0 ## # … with 2,990 more rows, and 10 more variables: release_date_month_Mar \u0026lt;dbl\u0026gt;, ## # release_date_month_Apr \u0026lt;dbl\u0026gt;, release_date_month_May \u0026lt;dbl\u0026gt;, ## # release_date_month_Jun \u0026lt;dbl\u0026gt;, release_date_month_Jul \u0026lt;dbl\u0026gt;, ## # release_date_month_Aug \u0026lt;dbl\u0026gt;, release_date_month_Sep \u0026lt;dbl\u0026gt;, ## # release_date_month_Oct \u0026lt;dbl\u0026gt;, release_date_month_Nov \u0026lt;dbl\u0026gt;, ## # release_date_month_Dec \u0026lt;dbl\u0026gt; d_train_baked %\u0026gt;% map_df(~ sum(is.na(.))) ## # A tibble: 1 × 16 ## popularity runtime budget revenue release_date_year release_date_month_Feb ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 0 0 0 0 0 0 ## # … with 10 more variables: release_date_month_Mar \u0026lt;int\u0026gt;, ## # release_date_month_Apr \u0026lt;int\u0026gt;, release_date_month_May \u0026lt;int\u0026gt;, ## # release_date_month_Jun \u0026lt;int\u0026gt;, release_date_month_Jul \u0026lt;int\u0026gt;, ## # release_date_month_Aug \u0026lt;int\u0026gt;, release_date_month_Sep \u0026lt;int\u0026gt;, ## # release_date_month_Oct \u0026lt;int\u0026gt;, release_date_month_Nov \u0026lt;int\u0026gt;, ## # release_date_month_Dec \u0026lt;int\u0026gt; Keine fehlenden Werte mehr in den Prädiktoren.\nNach fehlenden Werten könnte man z.B. auch so suchen:\ndatawizard::describe_distribution(d_train_baked) ## Variable | Mean | SD | IQR | Range | Skewness | Kurtosis | n | n_Missing ## --------------------------------------------------------------------------------------------------------------------- ## popularity | 8.46 | 12.10 | 6.88 | [1.00e-06, 294.34] | 14.38 | 280.10 | 3000 | 0 ## runtime | 107.84 | 22.09 | 24.00 | [0.00, 338.00] | 1.02 | 8.19 | 3000 | 0 ## budget | 12.51 | 6.44 | 14.88 | [2.30, 19.76] | -0.87 | -1.09 | 3000 | 0 ## revenue | 6.67e+07 | 1.38e+08 | 6.66e+07 | [1.00, 1.52e+09] | 4.54 | 27.78 | 3000 | 0 ## release_date_year | 2004.58 | 15.48 | 17.00 | [1969.00, 2068.00] | 1.22 | 3.94 | 3000 | 0 ## release_date_month_Feb | 0.08 | 0.26 | 0.00 | [0.00, 1.00] | 3.22 | 8.37 | 3000 | 0 ## release_date_month_Mar | 0.08 | 0.27 | 0.00 | [0.00, 1.00] | 3.11 | 7.71 | 3000 | 0 ## release_date_month_Apr | 0.08 | 0.27 | 0.00 | [0.00, 1.00] | 3.06 | 7.35 | 3000 | 0 ## release_date_month_May | 0.07 | 0.26 | 0.00 | [0.00, 1.00] | 3.24 | 8.49 | 3000 | 0 ## release_date_month_Jun | 0.08 | 0.27 | 0.00 | [0.00, 1.00] | 3.12 | 7.76 | 3000 | 0 ## release_date_month_Jul | 0.07 | 0.25 | 0.00 | [0.00, 1.00] | 3.38 | 9.45 | 3000 | 0 ## release_date_month_Aug | 0.09 | 0.28 | 0.00 | [0.00, 1.00] | 2.97 | 6.83 | 3000 | 0 ## release_date_month_Sep | 0.12 | 0.33 | 0.00 | [0.00, 1.00] | 2.33 | 3.43 | 3000 | 0 ## release_date_month_Oct | 0.10 | 0.30 | 0.00 | [0.00, 1.00] | 2.63 | 4.90 | 3000 | 0 ## release_date_month_Nov | 0.07 | 0.26 | 0.00 | [0.00, 1.00] | 3.27 | 8.67 | 3000 | 0 ## release_date_month_Dec | 0.09 | 0.28 | 0.00 | [0.00, 1.00] | 2.92 | 6.52 | 3000 | 0 So bekommt man gleich noch ein paar Infos über die Verteilung der Variablen. Praktische Sache.\nCheck Test-Sample\nDas Test-Sample backen wir auch mal. Das hat nur den Zwecke, zu prüfen, ob unser Rezept auch richtig funktioniert. Das Preppen und Backen des Test-Samples wir automatisch von predict() bzw. last_fit() erledigt.\nWichtig: Wir preppen den Datensatz mit dem Train-Sample, auch wenn wir das Test-Sample backen wollen.\nrec1_prepped \u0026lt;- prep(rec1) d_test_baked \u0026lt;- bake(rec1_prepped, new_data = d_test) d_test_baked %\u0026gt;% head() ## # A tibble: 6 × 15 ## popularity runtime budget release_date_year release_date_mon… release_date_mo… ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 3.85 90 2.30 2007 0 0 ## 2 3.56 65 11.4 2058 0 0 ## 3 8.09 100 2.30 1997 0 0 ## 4 8.60 130 15.7 2010 0 0 ## 5 3.22 92 14.5 2005 1 0 ## 6 8.68 121 2.30 1996 1 0 ## # … with 9 more variables: release_date_month_Apr \u0026lt;dbl\u0026gt;, ## # release_date_month_May \u0026lt;dbl\u0026gt;, release_date_month_Jun \u0026lt;dbl\u0026gt;, ## # release_date_month_Jul \u0026lt;dbl\u0026gt;, release_date_month_Aug \u0026lt;dbl\u0026gt;, ## # release_date_month_Sep \u0026lt;dbl\u0026gt;, release_date_month_Oct \u0026lt;dbl\u0026gt;, ## # release_date_month_Nov \u0026lt;dbl\u0026gt;, release_date_month_Dec \u0026lt;dbl\u0026gt;  Kreuzvalidierung Nur aus Zeitgründen ist hier \\(v=2\\) eingestellt; besser wäre z.B. \\(v=10\\) und \\(r=3\\).\ncv_scheme \u0026lt;- vfold_cv(d_train, v = 2, repeats = 1)  Modelle Baum\nmod_tree \u0026lt;- decision_tree(cost_complexity = tune(), tree_depth = tune(), mode = \u0026quot;regression\u0026quot;) Random Forest\ndoParallel::registerDoParallel() mod_rf \u0026lt;- rand_forest(mtry = tune(), min_n = tune(), trees = 1000, mode = \u0026quot;regression\u0026quot;) %\u0026gt;% set_engine(\u0026quot;ranger\u0026quot;, num.threads = 4) XGBoost\nmod_boost \u0026lt;- boost_tree(mtry = tune(), min_n = tune(), trees = tune()) %\u0026gt;% set_engine(\u0026quot;xgboost\u0026quot;, nthreads = parallel::detectCores()) %\u0026gt;% set_mode(\u0026quot;regression\u0026quot;) LM\nmod_lm \u0026lt;- linear_reg() Workflow-Set\npreproc \u0026lt;- list(rec1 = rec1) models \u0026lt;- list(tree1 = mod_tree, rf1 = mod_rf, boost1 = mod_boost, lm1 = mod_lm) all_workflows \u0026lt;- workflow_set(preproc, models) Fitten und tunen\nWenn man das Ergebnis-Objekt abgespeichert hat, dann kann man es einfach laden, spart Rechenzeit (der Tag ist kurz):\nresult_obj_file \u0026lt;- \u0026quot;tmdb_model_set.rds\u0026quot; (Davon ausgehend, dass die Datei im Arbeitsverzeichnis liegt.)\nDann könnte man Folgendes machen:\nif (file.exists(result_obj_file)) { tmdb_model_set \u0026lt;- read_rds(result_obj_file) } else { tic() tmdb_model_set \u0026lt;- all_workflows %\u0026gt;% workflow_map( resamples = cv_scheme, grid = 10, # metrics = metric_set(rmse), seed = 42, # reproducibility verbose = TRUE) toc() } Achtung Gefährlich! Zwischenspeichern auf der Festplatte birgt die Gefahr, dass man vergisst, das Objekt auf der Festplatte zu aktualisieren und Sie noch in einem Jahr und nach 100 Updates Ihres Rezepts immer noch das uralte Objekt von der Festplatte laden …\nUm Rechenzeit zu sparen, kann man das Ergebnisobjekt abspeichern, dann muss man beim nächsten Mal nicht wieder von Neuem berechnen:\n#write_rds(tmdb_model_set, \u0026quot;objects/tmdb_model_set.rds\u0026quot;) Hier berechnen wir aber lieber das Modell neu:\ntic() tmdb_model_set \u0026lt;- all_workflows %\u0026gt;% workflow_map( resamples = cv_scheme, grid = 10, # metrics = metric_set(rmse), seed = 42, # reproducibility verbose = TRUE) toc() ## 30.054 sec elapsed Finalisieren\nWelcher Algorithmus schneidet am besten ab?\nGenauer geagt, welches Modell, denn es ist ja nicht nur ein Algorithmus, sondern ein Algorithmus plus ein Rezept plus die Parameterinstatiierung plus ein spezifischer Datensatz.\ntune::autoplot(tmdb_model_set) + theme(legend.position = \u0026quot;bottom\u0026quot;) R-Quadrat ist nicht entscheidend; rmse ist wichtiger.\nDie Ergebnislage ist nicht ganz klar, aber einiges spricht für das Boosting-Modell, rec1_boost1.\ntmdb_model_set %\u0026gt;% collect_metrics() %\u0026gt;% arrange(-mean) %\u0026gt;% head(10) ## # A tibble: 10 × 9 ## wflow_id .config preproc model .metric .estimator mean n std_err ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 rec1_lm1 Preprocess… recipe line… rmse standard 1.16e8 2 2.42e6 ## 2 rec1_rf1 Preprocess… recipe rand… rmse standard 1.11e8 2 2.85e6 ## 3 rec1_tree1 Preprocess… recipe deci… rmse standard 1.10e8 2 1.61e6 ## 4 rec1_tree1 Preprocess… recipe deci… rmse standard 9.75e7 2 3.43e6 ## 5 rec1_boost1 Preprocess… recipe boos… rmse standard 9.73e7 2 2.51e6 ## 6 rec1_tree1 Preprocess… recipe deci… rmse standard 9.66e7 2 3.36e6 ## 7 rec1_boost1 Preprocess… recipe boos… rmse standard 9.50e7 2 1.05e5 ## 8 rec1_boost1 Preprocess… recipe boos… rmse standard 9.45e7 2 2.71e6 ## 9 rec1_tree1 Preprocess… recipe deci… rmse standard 9.40e7 2 1.32e6 ## 10 rec1_tree1 Preprocess… recipe deci… rmse standard 9.40e7 2 1.32e6 best_model_params \u0026lt;- extract_workflow_set_result(tmdb_model_set, \u0026quot;rec1_boost1\u0026quot;) %\u0026gt;% select_best() ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. best_model_params ## # A tibble: 1 × 4 ## mtry trees min_n .config ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 928 17 Preprocessor1_Model01 Finalisieren\nbest_wf \u0026lt;- all_workflows %\u0026gt;% extract_workflow(\u0026quot;rec1_boost1\u0026quot;) best_wf ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: boost_tree() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 6 Recipe Steps ## ## • step_mutate() ## • step_log() ## • step_mutate() ## • step_date() ## • step_impute_knn() ## • step_dummy() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Boosted Tree Model Specification (regression) ## ## Main Arguments: ## mtry = tune() ## trees = tune() ## min_n = tune() ## ## Engine-Specific Arguments: ## nthreads = parallel::detectCores() ## ## Computational engine: xgboost best_wf_finalized \u0026lt;- best_wf %\u0026gt;% finalize_workflow(best_model_params) best_wf_finalized ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: boost_tree() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 6 Recipe Steps ## ## • step_mutate() ## • step_log() ## • step_mutate() ## • step_date() ## • step_impute_knn() ## • step_dummy() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Boosted Tree Model Specification (regression) ## ## Main Arguments: ## mtry = 1 ## trees = 928 ## min_n = 17 ## ## Engine-Specific Arguments: ## nthreads = parallel::detectCores() ## ## Computational engine: xgboost Final Fit\nfit_final \u0026lt;- best_wf_finalized %\u0026gt;% fit(d_train) ## [10:24:41] WARNING: amalgamation/../src/learner.cc:627: ## Parameters: { \u0026quot;nthreads\u0026quot; } might not be used. ## ## This could be a false alarm, with some parameters getting used by language bindings but ## then being mistakenly passed down to XGBoost core, or some parameter actually being used ## but getting flagged wrongly here. Please open an issue if you find any such cases. fit_final ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: boost_tree() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 6 Recipe Steps ## ## • step_mutate() ## • step_log() ## • step_mutate() ## • step_date() ## • step_impute_knn() ## • step_dummy() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## ##### xgb.Booster ## raw: 1 Mb ## call: ## xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, ## colsample_bytree = 1, colsample_bynode = 0.0666666666666667, ## min_child_weight = 17L, subsample = 1, objective = \u0026quot;reg:squarederror\u0026quot;), ## data = x$data, nrounds = 928L, watchlist = x$watchlist, verbose = 0, ## nthreads = 8L, nthread = 1) ## params (as set within xgb.train): ## eta = \u0026quot;0.3\u0026quot;, max_depth = \u0026quot;6\u0026quot;, gamma = \u0026quot;0\u0026quot;, colsample_bytree = \u0026quot;1\u0026quot;, colsample_bynode = \u0026quot;0.0666666666666667\u0026quot;, min_child_weight = \u0026quot;17\u0026quot;, subsample = \u0026quot;1\u0026quot;, objective = \u0026quot;reg:squarederror\u0026quot;, nthreads = \u0026quot;8\u0026quot;, nthread = \u0026quot;1\u0026quot;, validate_parameters = \u0026quot;TRUE\u0026quot; ## xgb.attributes: ## niter ## callbacks: ## cb.evaluation.log() ## # of features: 15 ## niter: 928 ## nfeatures : 15 ## evaluation_log: ## iter training_rmse ## 1 130631526 ## 2 125426215 ## --- ## 927 44181662 ## 928 44158939 d_test$revenue \u0026lt;- NA final_preds \u0026lt;- fit_final %\u0026gt;% predict(new_data = d_test) %\u0026gt;% bind_cols(d_test) Submission\nsubmission_df \u0026lt;- final_preds %\u0026gt;% select(id, revenue = .pred) Abspeichern und einreichen:\n#write_csv(submission_df, file = \u0026quot;submission.csv\u0026quot;) Kaggle Score\nDiese Submission erzielte einen Score von 4.79227 (RMSLE).\nsol \u0026lt;- 4.79227 Categories:\n ds1 21ss   ","permalink":"https://datenwerk.netlify.app/post/tmdb03/tmdb03/","summary":"result_obj_file \u0026lt;- \u0026quot;tmdb_model_set.rds\u0026quot; result_obj_path \u0026lt;- \u0026quot;/Users/sebastiansaueruser/github-repos/rexams-exercises/objects/tmdb_model_set.rds\u0026quot; #exams::include_supplement(file = result_obj_file, # recursive = TRUE) # tmdb_model_set \u0026lt;- readr::read_rds(\u0026quot;tmdb_model_set.rds\u0026quot;) #tmdb_model_set \u0026lt;- readr::read_rds(result_obj_path) Exercise Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall für Filme.\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\nd_train_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\u0026quot; d_test_path \u0026lt;- \u0026quot;https://raw.","title":"tmdb03"},{"content":" Exercise Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall für Filme.\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\nd_train_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\u0026quot; d_test_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\u0026quot;  Aufgabe Reichen Sie bei Kaggle eine Submission für die Fallstudie ein! Berichten Sie den Score!\nHinweise:\n Sie müssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym möglich); alternativ können Sie sich mit einem Google-Konto anmelden. Halten Sie das Modell so einfach wie möglich. Verwenden Sie als Algorithmus die lineare Regression ohne weitere Schnörkel. Logarithmieren Sie budget und revenue. Minimieren Sie die Vorverarbeitung (steps) so weit als möglich. Verwenden Sie tidymodels. Die Zielgröße ist revenue in Dollars; nicht in “Log-Dollars”. Sie müssen also rücktransformieren, wenn Sie revenue logarithmiert haben, bevor Sie Ihre Prognose einreichen.           \n Solution  Vorbereitung library(tidyverse) library(tidymodels) d_train_raw \u0026lt;- read_csv(d_train_path) d_test_raw \u0026lt;- read_csv(d_test_path) Sicher ist sicher:\nd_train_backup \u0026lt;- d_train_raw Mal einen Blick werfen:\nglimpse(d_train_raw) ## Rows: 3,000 ## Columns: 23 ## $ id \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1… ## $ belongs_to_collection \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 313576, \u0026#39;name\u0026#39;: \u0026#39;Hot Tub Time Machine C… ## $ budget \u0026lt;dbl\u0026gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00… ## $ genres \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 35, \u0026#39;name\u0026#39;: \u0026#39;Comedy\u0026#39;}]\u0026quot;, \u0026quot;[{\u0026#39;id\u0026#39;: 35, \u0026#39;… ## $ homepage \u0026lt;chr\u0026gt; NA, NA, \u0026quot;http://sonyclassics.com/whiplash/\u0026quot;, \u0026quot;ht… ## $ imdb_id \u0026lt;chr\u0026gt; \u0026quot;tt2637294\u0026quot;, \u0026quot;tt0368933\u0026quot;, \u0026quot;tt2582802\u0026quot;, \u0026quot;tt182148… ## $ original_language \u0026lt;chr\u0026gt; \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;hi\u0026quot;, \u0026quot;ko\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, … ## $ original_title \u0026lt;chr\u0026gt; \u0026quot;Hot Tub Time Machine 2\u0026quot;, \u0026quot;The Princess Diaries … ## $ overview \u0026lt;chr\u0026gt; \u0026quot;When Lou, who has become the \\\u0026quot;father of the In… ## $ popularity \u0026lt;dbl\u0026gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807… ## $ poster_path \u0026lt;chr\u0026gt; \u0026quot;/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\u0026quot;, \u0026quot;/w9Z7A0GHEh… ## $ production_companies \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;name\u0026#39;: \u0026#39;Paramount Pictures\u0026#39;, \u0026#39;id\u0026#39;: 4}, {\u0026#39;nam… ## $ production_countries \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_3166_1\u0026#39;: \u0026#39;US\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;United States of… ## $ release_date \u0026lt;chr\u0026gt; \u0026quot;2/20/15\u0026quot;, \u0026quot;8/6/04\u0026quot;, \u0026quot;10/10/14\u0026quot;, \u0026quot;3/9/12\u0026quot;, \u0026quot;2/5/… ## $ runtime \u0026lt;dbl\u0026gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119… ## $ spoken_languages \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_639_1\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;English\u0026#39;}]\u0026quot;, \u0026quot;[{\u0026#39;… ## $ status \u0026lt;chr\u0026gt; \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, … ## $ tagline \u0026lt;chr\u0026gt; \u0026quot;The Laws of Space and Time are About to be Viol… ## $ title \u0026lt;chr\u0026gt; \u0026quot;Hot Tub Time Machine 2\u0026quot;, \u0026quot;The Princess Diaries … ## $ Keywords \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 4379, \u0026#39;name\u0026#39;: \u0026#39;time travel\u0026#39;}, {\u0026#39;id\u0026#39;: 96… ## $ cast \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;cast_id\u0026#39;: 4, \u0026#39;character\u0026#39;: \u0026#39;Lou\u0026#39;, \u0026#39;credit_id\u0026#39;… ## $ crew \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;credit_id\u0026#39;: \u0026#39;59ac067c92514107af02c8c8\u0026#39;, \u0026#39;dep… ## $ revenue \u0026lt;dbl\u0026gt; 12314651, 95149435, 13092000, 16000000, 3923970,… Train-Set verschlanken d_train_raw_reduced \u0026lt;- d_train_raw %\u0026gt;% select(id, popularity, runtime, revenue, budget)   Test-Set verschlanken d_test \u0026lt;- d_test_raw %\u0026gt;% select(id,popularity, runtime, budget)   Outcome logarithmieren Der Outcome sollte nicht im Rezept transformiert werden (vgl. Part 3, S. 30, in dieser Unterlage).\nd_train \u0026lt;- d_train_raw_reduced %\u0026gt;% mutate(revenue = if_else(revenue \u0026lt; 10, 10, revenue)) %\u0026gt;% mutate(revenue = log(revenue))  Prüfen, ob das funktioniert hat:\nd_train$revenue %\u0026gt;% is.infinite() %\u0026gt;% any() ## [1] FALSE Keine unendlichen Werte mehr, auf dieser Basis können wir weitermachen.\n  Fehlende Werte prüfen Welche Spalten haben viele fehlende Werte?\nlibrary(easystats) describe_distribution(d_train) ## Variable | Mean | SD | IQR | Range | Skewness | Kurtosis | n | n_Missing ## --------------------------------------------------------------------------------------------------------- ## id | 1500.50 | 866.17 | 1500.50 | [1.00, 3000.00] | 0.00 | -1.20 | 3000 | 0 ## popularity | 8.46 | 12.10 | 6.88 | [1.00e-06, 294.34] | 14.38 | 280.10 | 3000 | 0 ## runtime | 107.86 | 22.09 | 24.00 | [0.00, 338.00] | 1.02 | 8.19 | 2998 | 2 ## revenue | 15.97 | 3.04 | 3.37 | [2.30, 21.14] | -1.60 | 3.82 | 3000 | 0 ## budget | 2.25e+07 | 3.70e+07 | 2.90e+07 | [0.00, 3.80e+08] | 3.10 | 13.23 | 3000 | 0 sum_isna \u0026lt;- function(x) {sum(is.na(x))} d_train %\u0026gt;% summarise(across(everything(), sum_isna)) ## # A tibble: 1 × 5 ## id popularity runtime revenue budget ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 0 0 2 0 0  Rezept Rezept definieren rec2 \u0026lt;- recipe(revenue ~ ., data = d_train) %\u0026gt;% step_mutate(budget = ifelse(budget == 0, NA, budget)) %\u0026gt;% # log mag keine 0 step_log(budget) %\u0026gt;% step_impute_knn(all_predictors()) %\u0026gt;% step_dummy(all_nominal_predictors()) %\u0026gt;% update_role(id, new_role = \u0026quot;id\u0026quot;) rec2 ## Recipe ## ## Inputs: ## ## role #variables ## id 1 ## outcome 1 ## predictor 3 ## ## Operations: ## ## Variable mutation for ifelse(budget == 0, NA, budget) ## Log transformation on budget ## K-nearest neighbor imputation for all_predictors() ## Dummy variables from all_nominal_predictors() Schauen Sie mal, der Log mag keine Nullen:\nx \u0026lt;- c(1,2, NA, 0) log(x) ## [1] 0.0000000 0.6931472 NA -Inf Da \\(log(0) = -\\infty\\). Aus dem Grund wandeln wir 0 lieber in NA um.\ntidy(rec2) ## # A tibble: 4 × 6 ## number operation type trained skip id ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 step mutate FALSE FALSE mutate_6KDmy ## 2 2 step log FALSE FALSE log_WYoMT ## 3 3 step impute_knn FALSE FALSE impute_knn_hL3ll ## 4 4 step dummy FALSE FALSE dummy_EIv53  Check das Rezept Wir berechnen das Rezept:\nrec2_prepped \u0026lt;- prep(rec2, verbose = TRUE) ## oper 1 step mutate [training] ## oper 2 step log [training] ## oper 3 step impute knn [training] ## oper 4 step dummy [training] ## The retained training set is ~ 0.12 Mb in memory. rec2_prepped ## Recipe ## ## Inputs: ## ## role #variables ## id 1 ## outcome 1 ## predictor 3 ## ## Training data contained 3000 data points and 2 incomplete rows. ## ## Operations: ## ## Variable mutation for ~ifelse(budget == 0, NA, budget) [trained] ## Log transformation on budget [trained] ## K-nearest neighbor imputation for runtime, budget, popularity [trained] ## Dummy variables from \u0026lt;none\u0026gt; [trained] Das ist noch nicht auf einen Datensatz angewendet! Lediglich die steps wurden vorbereitet, “präpariert”: z.B. “Diese Dummy-Variablen impliziert das Rezept”.\nSo sieht das dann aus, wenn man das präparierte Rezept auf das Train-Sample anwendet:\nd_train_baked2 \u0026lt;- rec2_prepped %\u0026gt;% bake(new_data = NULL) head(d_train_baked2) ## # A tibble: 6 × 5 ## id popularity runtime budget revenue ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 6.58 93 16.5 16.3 ## 2 2 8.25 113 17.5 18.4 ## 3 3 64.3 105 15.0 16.4 ## 4 4 3.17 122 14.0 16.6 ## 5 5 1.15 118 15.8 15.2 ## 6 6 0.743 83 15.9 15.0 d_train_baked2 %\u0026gt;% map_df(sum_isna) ## # A tibble: 1 × 5 ## id popularity runtime budget revenue ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 0 0 0 0 0 Keine fehlenden Werte mehr in den Prädiktoren.\nNach fehlenden Werten könnte man z.B. auch so suchen:\ndatawizard::describe_distribution(d_train_baked2) ## Variable | Mean | SD | IQR | Range | Skewness | Kurtosis | n | n_Missing ## ----------------------------------------------------------------------------------------------------- ## id | 1500.50 | 866.17 | 1500.50 | [1.00, 3000.00] | 0.00 | -1.20 | 3000 | 0 ## popularity | 8.46 | 12.10 | 6.88 | [1.00e-06, 294.34] | 14.38 | 280.10 | 3000 | 0 ## runtime | 107.85 | 22.08 | 24.00 | [0.00, 338.00] | 1.02 | 8.20 | 3000 | 0 ## budget | 16.09 | 1.89 | 1.90 | [0.00, 19.76] | -2.93 | 18.71 | 3000 | 0 ## revenue | 15.97 | 3.04 | 3.37 | [2.30, 21.14] | -1.60 | 3.82 | 3000 | 0 So bekommt man gleich noch ein paar Infos über die Verteilung der Variablen. Praktische Sache.\n Check Test-Sample Das Test-Sample backen wir auch mal, um zu prüfen, das alles läuft:\nd_test_baked2 \u0026lt;- bake(rec2_prepped, new_data = d_test) d_test_baked2 %\u0026gt;% head() ## # A tibble: 6 × 4 ## id popularity runtime budget ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 3001 3.85 90 15.8 ## 2 3002 3.56 65 11.4 ## 3 3003 8.09 100 16.4 ## 4 3004 8.60 130 15.7 ## 5 3005 3.22 92 14.5 ## 6 3006 8.68 121 16.1 Sieht soweit gut aus.\n  Kreuzvalidierung / Resampling Hier ist nur aus Gründen der Rechenzeit auf kleine Werte von \\(v\\) und \\(r\\) ausgewichen worden. Besser wäre z.B. \\(v=10\\) und \\(r=3\\).\ncv_scheme \u0026lt;- vfold_cv(d_train, v = 3, repeats = 1)  Modelle LM mod_lm \u0026lt;- linear_reg()   Workflow-Set Hier nur ein sehr kleiner Workflow-Set.\nDas ist übrigens eine gute Strategie: Erstmal mit einem kleinen Prozess anfangen, und dann sukzessive erweitern.\npreproc2 \u0026lt;- list(rec1 = rec2) models2 \u0026lt;- list(lm1 = mod_lm) all_workflows2 \u0026lt;- workflow_set(preproc2, models2)  Fitten und tunen tmdb_model_set2 \u0026lt;- all_workflows2 %\u0026gt;% workflow_map(resamples = cv_scheme)  Finalisieren tmdb_model_set2 %\u0026gt;% collect_metrics() %\u0026gt;% arrange(-mean) %\u0026gt;% head(10) ## # A tibble: 2 × 9 ## wflow_id .config preproc model .metric .estimator mean n std_err ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 rec1_lm1 Preprocessor1_M… recipe line… rmse standard 2.51 3 0.0547 ## 2 rec1_lm1 Preprocessor1_M… recipe line… rsq standard 0.333 3 0.0205 best_model_params2 \u0026lt;- extract_workflow_set_result(tmdb_model_set2, \u0026quot;rec1_lm1\u0026quot;) %\u0026gt;% select_best() ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. best_model_params2 ## # A tibble: 1 × 1 ## .config ## \u0026lt;chr\u0026gt; ## 1 Preprocessor1_Model1 Finalisieren Finalisieren bedeutet:\n Besten Workflow identifizieren (zur Erinnerung: Workflow = Rezept + Modell) Den besten Workflow mit den optimalen Modell-Parametern ausstatten Damit dann den ganzen Train-Datensatz fitten Auf dieser Basis das Test-Sample vorhersagen  best_wf2 \u0026lt;- all_workflows2 %\u0026gt;% extract_workflow(\u0026quot;rec1_lm1\u0026quot;) best_wf2 ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: linear_reg() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 4 Recipe Steps ## ## • step_mutate() ## • step_log() ## • step_impute_knn() ## • step_dummy() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Linear Regression Model Specification (regression) ## ## Computational engine: lm best_wf_finalized2 \u0026lt;- best_wf2 %\u0026gt;% finalize_workflow(best_model_params2) best_wf_finalized2 ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: linear_reg() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 4 Recipe Steps ## ## • step_mutate() ## • step_log() ## • step_impute_knn() ## • step_dummy() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Linear Regression Model Specification (regression) ## ## Computational engine: lm  Final Fit fit_final2 \u0026lt;- best_wf_finalized2 %\u0026gt;% fit(d_train) fit_final2 ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: linear_reg() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 4 Recipe Steps ## ## • step_mutate() ## • step_log() ## • step_impute_knn() ## • step_dummy() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## ## Call: ## stats::lm(formula = ..y ~ ., data = data) ## ## Coefficients: ## (Intercept) popularity runtime budget ## 1.26186 0.03755 0.01289 0.80752 preds \u0026lt;- fit_final2 %\u0026gt;% predict(new_data = d_test) head(preds) ## # A tibble: 6 × 1 ## .pred ## \u0026lt;dbl\u0026gt; ## 1 15.3 ## 2 11.4 ## 3 16.1 ## 4 16.0 ## 5 14.3 ## 6 16.1 Achtung, wenn die Outcome-Variable im Rezept verändert wurde, dann würde obiger Code nicht durchlaufen.\nGrund ist hier beschrieben:\n When predict() is used, it only has access to the predictors (mirroring how this would work with new samples). Even if the outcome column is present, it is not exposed to the recipe. This is generally a good idea so that we can avoid information leakage.\n  One approach is the use the skip = TRUE option in step_log() so that it will avoid that step during predict() and/or bake(). However, if you are using this recipe with the tune package, there will still be an issue because the metric function(s) would get the predictions in log units and the observed outcome in the original units.\n  The better approach is, for simple transformations like yours, to log the outcome outside of the recipe (before data analysis and the initial split).\n  Submission df submission_df \u0026lt;- d_test %\u0026gt;% select(id) %\u0026gt;% bind_cols(preds) %\u0026gt;% rename(revenue = .pred) head(submission_df) ## # A tibble: 6 × 2 ## id revenue ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 3001 15.3 ## 2 3002 11.4 ## 3 3003 16.1 ## 4 3004 16.0 ## 5 3005 14.3 ## 6 3006 16.1  Zurücktransformieren submission_df \u0026lt;- submission_df %\u0026gt;% mutate(revenue = exp(revenue)-1) head(submission_df) ## # A tibble: 6 × 2 ## id revenue ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 3001 4435143. ## 2 3002 91755. ## 3 3003 9782986. ## 4 3004 8573795. ## 5 3005 1598106. ## 6 3006 10061439. Hier ein Beispiel, warum \\(e^x-1\\) genauer ist für kleine Zahlen als \\(e^x\\).\nAbspeichern und einreichen:\nwrite_csv(submission_df, file = \u0026quot;submission.csv\u0026quot;)   Kaggle Score Diese Submission erzielte einen Score von Score: 2.46249 (RMSLE).\nsol \u0026lt;- 2.5 Categories:\n ds1 21ss   ","permalink":"https://datenwerk.netlify.app/post/tmdb04/tmdb04/","summary":"Exercise Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall für Filme.\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\nd_train_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\u0026quot; d_test_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\u0026quot;  Aufgabe Reichen Sie bei Kaggle eine Submission für die Fallstudie ein! Berichten Sie den Score!\nHinweise:\n Sie müssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym möglich); alternativ können Sie sich mit einem Google-Konto anmelden.","title":"tmdb04"},{"content":" Exercise Melden Sie sich an für die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?.\nSie benötigen dazu ein Konto; es ist auch möglich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Prädiktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verfügung. Eine klassische “predictive Competition” also :-) Allerdings können immer ein paar Schwierigkeiten auftreten ;-)\nAufgabe\nErstellen Sie ein Boosting-Modell mit Tidymodels!\nHinweise\n Für den Start empfehle ich, etwaige Vorverarbeitung erstmal klein zu halten. Nach dem Motto: Erstmal das Modell zum Laufen kriegen, dann erst verbessern. Tunen Sie die typischen Parameter. Reichen Sie das Modell bei Kaggle ein und berichten Sie Ihren Score. Im Übrigen sind Sie frei in Ihrem Vorgehen.           \n Solution  Pakete starten  Daten importieren Werfen wir einen Blick in die Daten:\n## Rows: 3,000 ## Columns: 23 ## $ id \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1… ## $ belongs_to_collection \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 313576, \u0026#39;name\u0026#39;: \u0026#39;Hot Tub Time Machine C… ## $ budget \u0026lt;dbl\u0026gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00… ## $ genres \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 35, \u0026#39;name\u0026#39;: \u0026#39;Comedy\u0026#39;}]\u0026quot;, \u0026quot;[{\u0026#39;id\u0026#39;: 35, \u0026#39;… ## $ homepage \u0026lt;chr\u0026gt; NA, NA, \u0026quot;http://sonyclassics.com/whiplash/\u0026quot;, \u0026quot;ht… ## $ imdb_id \u0026lt;chr\u0026gt; \u0026quot;tt2637294\u0026quot;, \u0026quot;tt0368933\u0026quot;, \u0026quot;tt2582802\u0026quot;, \u0026quot;tt182148… ## $ original_language \u0026lt;chr\u0026gt; \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;hi\u0026quot;, \u0026quot;ko\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, … ## $ original_title \u0026lt;chr\u0026gt; \u0026quot;Hot Tub Time Machine 2\u0026quot;, \u0026quot;The Princess Diaries … ## $ overview \u0026lt;chr\u0026gt; \u0026quot;When Lou, who has become the \\\u0026quot;father of the In… ## $ popularity \u0026lt;dbl\u0026gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807… ## $ poster_path \u0026lt;chr\u0026gt; \u0026quot;/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\u0026quot;, \u0026quot;/w9Z7A0GHEh… ## $ production_companies \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;name\u0026#39;: \u0026#39;Paramount Pictures\u0026#39;, \u0026#39;id\u0026#39;: 4}, {\u0026#39;nam… ## $ production_countries \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_3166_1\u0026#39;: \u0026#39;US\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;United States of… ## $ release_date \u0026lt;chr\u0026gt; \u0026quot;2/20/15\u0026quot;, \u0026quot;8/6/04\u0026quot;, \u0026quot;10/10/14\u0026quot;, \u0026quot;3/9/12\u0026quot;, \u0026quot;2/5/… ## $ runtime \u0026lt;dbl\u0026gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119… ## $ spoken_languages \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_639_1\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;English\u0026#39;}]\u0026quot;, \u0026quot;[{\u0026#39;… ## $ status \u0026lt;chr\u0026gt; \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, … ## $ tagline \u0026lt;chr\u0026gt; \u0026quot;The Laws of Space and Time are About to be Viol… ## $ title \u0026lt;chr\u0026gt; \u0026quot;Hot Tub Time Machine 2\u0026quot;, \u0026quot;The Princess Diaries … ## $ Keywords \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 4379, \u0026#39;name\u0026#39;: \u0026#39;time travel\u0026#39;}, {\u0026#39;id\u0026#39;: 96… ## $ cast \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;cast_id\u0026#39;: 4, \u0026#39;character\u0026#39;: \u0026#39;Lou\u0026#39;, \u0026#39;credit_id\u0026#39;… ## $ crew \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;credit_id\u0026#39;: \u0026#39;59ac067c92514107af02c8c8\u0026#39;, \u0026#39;dep… ## $ revenue \u0026lt;dbl\u0026gt; 12314651, 95149435, 13092000, 16000000, 3923970,… ## Rows: 4,398 ## Columns: 22 ## $ id \u0026lt;dbl\u0026gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, … ## $ belongs_to_collection \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 34055, \u0026#39;name\u0026#39;: \u0026#39;Pokémon Collection\u0026#39;, \u0026#39;p… ## $ budget \u0026lt;dbl\u0026gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06… ## $ genres \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 12, \u0026#39;name\u0026#39;: \u0026#39;Adventure\u0026#39;}, {\u0026#39;id\u0026#39;: 16, \u0026#39;n… ## $ homepage \u0026lt;chr\u0026gt; \u0026quot;http://www.pokemon.com/us/movies/movie-pokemon-… ## $ imdb_id \u0026lt;chr\u0026gt; \u0026quot;tt1226251\u0026quot;, \u0026quot;tt0051380\u0026quot;, \u0026quot;tt0118556\u0026quot;, \u0026quot;tt125595… ## $ original_language \u0026lt;chr\u0026gt; \u0026quot;ja\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;fr\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;de\u0026quot;, \u0026quot;en\u0026quot;, … ## $ original_title \u0026lt;chr\u0026gt; \u0026quot;ディアルガVSパルキアVSダークライ\u0026quot;, \u0026quot;Attack of t… ## $ overview \u0026lt;chr\u0026gt; \u0026quot;Ash and friends (this time accompanied by newco… ## $ popularity \u0026lt;dbl\u0026gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680… ## $ poster_path \u0026lt;chr\u0026gt; \u0026quot;/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\u0026quot;, \u0026quot;/9MgBNBqlH1… ## $ production_companies \u0026lt;chr\u0026gt; NA, \u0026quot;[{\u0026#39;name\u0026#39;: \u0026#39;Woolner Brothers Pictures Inc.\u0026#39;,… ## $ production_countries \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_3166_1\u0026#39;: \u0026#39;JP\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Japan\u0026#39;}, {\u0026#39;iso_3… ## $ release_date \u0026lt;chr\u0026gt; \u0026quot;7/14/07\u0026quot;, \u0026quot;5/19/58\u0026quot;, \u0026quot;5/23/97\u0026quot;, \u0026quot;9/4/10\u0026quot;, \u0026quot;2/11… ## $ runtime \u0026lt;dbl\u0026gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,… ## $ spoken_languages \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_639_1\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;English\u0026#39;}, {\u0026#39;iso_… ## $ status \u0026lt;chr\u0026gt; \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, … ## $ tagline \u0026lt;chr\u0026gt; \u0026quot;Somewhere Between Time \u0026amp; Space... A Legend Is B… ## $ title \u0026lt;chr\u0026gt; \u0026quot;Pokémon: The Rise of Darkrai\u0026quot;, \u0026quot;Attack of the 5… ## $ Keywords \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 11451, \u0026#39;name\u0026#39;: \u0026#39;pok√©mon\u0026#39;}, {\u0026#39;id\u0026#39;: 1155… ## $ cast \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;cast_id\u0026#39;: 3, \u0026#39;character\u0026#39;: \u0026#39;Tonio\u0026#39;, \u0026#39;credit_i… ## $ crew \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;credit_id\u0026#39;: \u0026#39;52fe44e7c3a368484e03d683\u0026#39;, \u0026#39;dep…  CV  Rezept 1 Begrenzen wir uns der Einfachheit halber auf folgende Prädiktoren, zumindest fürs Erste:\n## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 3 ## ## Operations: ## ## K-nearest neighbor imputation for \u0026lt;none\u0026gt; ## Centering for all_numeric_predictors() ## Scaling for all_numeric_predictors() Boosting braucht nicht unbedingt skalierte Prädiktoren (sd=1), aber es kann helfen, zu z-transformieren.\nRezept checken ## # A tibble: 3,000 × 4 ## budget popularity runtime revenue ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 -0.230 -0.156 -0.673 12314651 ## 2 0.472 -0.0177 0.233 95149435 ## 3 -0.519 4.61 -0.129 13092000 ## 4 -0.576 -0.437 0.640 16000000 ## 5 -0.609 -0.604 0.459 3923970 ## 6 -0.392 -0.638 -1.13 3261638 ## 7 -0.230 -0.0972 -0.718 85446075 ## 8 -0.609 -0.538 -1.08 2586511 ## 9 -0.609 -0.129 -0.356 34327391 ## 10 -0.446 -0.313 -0.763 18750246 ## # … with 2,990 more rows Viele Modelle können nicht arbeiten mit nominalen Prädiktoren oder mit fehlenden Werten. Daher sollte man im Rezept diese Fehler vorab abfangen.\nEin letzter Blick:\n## Variable | Mean | SD | IQR | Range | Skewness | Kurtosis | n | n_Missing ## -------------------------------------------------------------------------------------------------------- ## budget | -1.33e-18 | 1.00 | 0.78 | [-0.61, 9.65] | 3.10 | 13.23 | 3000 | 0 ## popularity | -6.08e-17 | 1.00 | 0.57 | [-0.70, 23.62] | 14.38 | 280.10 | 3000 | 0 ## runtime | 3.63e-17 | 1.00 | 1.09 | [-4.88, 10.42] | 1.02 | 8.19 | 2998 | 2 ## revenue | 6.67e+07 | 1.38e+08 | 6.66e+07 | [1.00, 1.52e+09] | 4.54 | 27.78 | 3000 | 0 Sieht ok aus.\n  Modell 1 Tipp: Mit {usemodels} kann man sich den Code für einen Workflow (inkl. dem typischen Kladderadatsch) schon mal ausgeben lassen. Praktisch.\n Workflow 1 Tipp: Gewöhnen Sie sich ein konsistentes Schema zu Benennung Ihrer Objekte an. Z.B. Workflow-Objekte mit wf1, wf2 etc. Fit-Objekte mit fit_boost1, fit_rf1, etc. Da gibt’s viele Wege, keine einzelne richtige Lösung.\n Modell fitten (und tunen) Tipp: Wenn Sie Ihr Rezept ändern, nicht vergessen, das Workflow-Objekt, wf1 in diesem Fall, neu zu berechnen. Vergisst man gerne mal…\nEine professioneller Lösung wäre ein Tool, das für Sie prüft, welche Objekte Sie aktualisieren müssen, z.B. das R-Paket {targets}.\nSchalten wir, um Zeit zu sparen, noch mehrere Rechenkerne frei.\n## [1] 8 Wenn man auf mehreren Kernen gleichzeitig rechnet, braucht man natürlich auch mehr (Arbeits-)Speicher (RAM). Wenn Ihre Maschine wenig (freien) Arbeitsspeicher hat, dann kann man nicht (oder nicht sinnvoll) auf mehreren Kernen gleichzeitig arbeiten.\n## 5.56 sec elapsed Rechenzeit auf diesem Rechner:\nEs könnte sich lohnen, das Modellobjekt abzuspeichern, da die Rechenzeit doch ganz schön lang sein kann. ABER Achtung: Sie dürfen dann nicht vergessen, das Objekt auf der Festplatte zu aktualisieren. Diese Strategie ist nicht ungefährlich: Leicht vergisst man das Aktualisieren.\nMit dem Parameter grid kann man die Anzahl der Tuningparameter-Kandidaten festlegen, vgl. hier:\ngrid\n A data frame of tuning combinations or a positive integer. The data frame should have columns for each parameter being tuned and rows for tuning parameter candidates. An integer denotes the number of candidate parameter sets to be created automatically.\n Der Standardwert (Default) beträgt 10.\nEin Blick in die Hinweise zum Fitten, ob beim Fitten etwas Ungewöhnliches passiert ist:\n## # A tibble: 0 × 3 ## # … with 3 variables: location \u0026lt;chr\u0026gt;, type \u0026lt;chr\u0026gt;, note \u0026lt;chr\u0026gt; Und weiter reingezoomt, falls es Hinweise geben sollte (ist hier nicht der Fall, nur der Info halber):\n## # A tibble: 0 × 1 ## # … with 1 variable: note \u0026lt;chr\u0026gt; Dran denken: Wenn Sie das Modell aus irgendwelchen Gründen neu fitten, müssen Sie “flussabwärts”, also danach kommenden Objekte, auch neu berechnen.\n Bester Modellkandidat ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: boost_tree() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 3 Recipe Steps ## ## • step_impute_knn() ## • step_center() ## • step_scale() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Boosted Tree Model Specification (regression) ## ## Main Arguments: ## mtry = 2 ## min_n = 16 ## tree_depth = 13 ## learn_rate = 0.128257288834097 ## ## Engine-Specific Arguments: ## num.threads = cores ## ## Computational engine: xgboost  Final fit ## [10:25:11] WARNING: amalgamation/../src/learner.cc:627: ## Parameters: { \u0026quot;num_threads\u0026quot; } might not be used. ## ## This could be a false alarm, with some parameters getting used by language bindings but ## then being mistakenly passed down to XGBoost core, or some parameter actually being used ## but getting flagged wrongly here. Please open an issue if you find any such cases.  Final Predict ## Rows: 4,398 ## Columns: 3 ## $ budget \u0026lt;dbl\u0026gt; -0.60852594, -0.60614924, -0.60852594, -0.42487164, -0.5545… ## $ popularity \u0026lt;dbl\u0026gt; -0.38100960, -0.40511279, -0.03123597, 0.01096644, -0.43337… ## $ runtime \u0026lt;dbl\u0026gt; -0.80848591, -1.94040243, -0.35571930, 1.00258052, -0.71793… Categories:\n ds1 21ss   ","permalink":"https://datenwerk.netlify.app/post/tmdb05/tmdb05/","summary":"Exercise Melden Sie sich an für die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?.\nSie benötigen dazu ein Konto; es ist auch möglich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Prädiktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verfügung. Eine klassische “predictive Competition” also :-) Allerdings können immer ein paar Schwierigkeiten auftreten ;-)","title":"tmdb05"},{"content":" Exercise Melden Sie sich an für die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?.\nSie benötigen dazu ein Konto; es ist auch möglich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Prädiktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verfügung. Eine klassische “predictive Competition” also :-) Allerdings können immer ein paar Schwierigkeiten auftreten ;-)\nAufgabe\nErstellen Sie ein Lineares-Modell mit Tidymodels!\nHinweise\n Verzichten Sie auf Vorverarbeitung. Tunen Sie die typischen Parameter. Reichen Sie das Modell ein und berichten Sie Ihren Score. Begrenzen Sie sich auf folgende Prädiktoren. Verwenden Sie (langweiligerweise) nur ein lineares Modell.  preds_chosen \u0026lt;- c(\u0026quot;id\u0026quot;, \u0026quot;budget\u0026quot;, \u0026quot;popularity\u0026quot;, \u0026quot;runtime\u0026quot;)          \n Solution  Pakete starten library(tidyverse) library(tidymodels) library(tictoc)  Daten importieren d_train_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\u0026quot; d_test_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\u0026quot; d_train \u0026lt;- read_csv(d_train_path) d_test \u0026lt;- read_csv(d_test_path) Werfen wir einen Blick in die Daten:\nglimpse(d_train) ## Rows: 3,000 ## Columns: 23 ## $ id \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1… ## $ belongs_to_collection \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 313576, \u0026#39;name\u0026#39;: \u0026#39;Hot Tub Time Machine C… ## $ budget \u0026lt;dbl\u0026gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00… ## $ genres \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 35, \u0026#39;name\u0026#39;: \u0026#39;Comedy\u0026#39;}]\u0026quot;, \u0026quot;[{\u0026#39;id\u0026#39;: 35, \u0026#39;… ## $ homepage \u0026lt;chr\u0026gt; NA, NA, \u0026quot;http://sonyclassics.com/whiplash/\u0026quot;, \u0026quot;ht… ## $ imdb_id \u0026lt;chr\u0026gt; \u0026quot;tt2637294\u0026quot;, \u0026quot;tt0368933\u0026quot;, \u0026quot;tt2582802\u0026quot;, \u0026quot;tt182148… ## $ original_language \u0026lt;chr\u0026gt; \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;hi\u0026quot;, \u0026quot;ko\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, … ## $ original_title \u0026lt;chr\u0026gt; \u0026quot;Hot Tub Time Machine 2\u0026quot;, \u0026quot;The Princess Diaries … ## $ overview \u0026lt;chr\u0026gt; \u0026quot;When Lou, who has become the \\\u0026quot;father of the In… ## $ popularity \u0026lt;dbl\u0026gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807… ## $ poster_path \u0026lt;chr\u0026gt; \u0026quot;/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\u0026quot;, \u0026quot;/w9Z7A0GHEh… ## $ production_companies \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;name\u0026#39;: \u0026#39;Paramount Pictures\u0026#39;, \u0026#39;id\u0026#39;: 4}, {\u0026#39;nam… ## $ production_countries \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_3166_1\u0026#39;: \u0026#39;US\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;United States of… ## $ release_date \u0026lt;chr\u0026gt; \u0026quot;2/20/15\u0026quot;, \u0026quot;8/6/04\u0026quot;, \u0026quot;10/10/14\u0026quot;, \u0026quot;3/9/12\u0026quot;, \u0026quot;2/5/… ## $ runtime \u0026lt;dbl\u0026gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119… ## $ spoken_languages \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_639_1\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;English\u0026#39;}]\u0026quot;, \u0026quot;[{\u0026#39;… ## $ status \u0026lt;chr\u0026gt; \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, … ## $ tagline \u0026lt;chr\u0026gt; \u0026quot;The Laws of Space and Time are About to be Viol… ## $ title \u0026lt;chr\u0026gt; \u0026quot;Hot Tub Time Machine 2\u0026quot;, \u0026quot;The Princess Diaries … ## $ Keywords \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 4379, \u0026#39;name\u0026#39;: \u0026#39;time travel\u0026#39;}, {\u0026#39;id\u0026#39;: 96… ## $ cast \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;cast_id\u0026#39;: 4, \u0026#39;character\u0026#39;: \u0026#39;Lou\u0026#39;, \u0026#39;credit_id\u0026#39;… ## $ crew \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;credit_id\u0026#39;: \u0026#39;59ac067c92514107af02c8c8\u0026#39;, \u0026#39;dep… ## $ revenue \u0026lt;dbl\u0026gt; 12314651, 95149435, 13092000, 16000000, 3923970,… glimpse(d_test) ## Rows: 4,398 ## Columns: 22 ## $ id \u0026lt;dbl\u0026gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, … ## $ belongs_to_collection \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 34055, \u0026#39;name\u0026#39;: \u0026#39;Pokémon Collection\u0026#39;, \u0026#39;p… ## $ budget \u0026lt;dbl\u0026gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06… ## $ genres \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 12, \u0026#39;name\u0026#39;: \u0026#39;Adventure\u0026#39;}, {\u0026#39;id\u0026#39;: 16, \u0026#39;n… ## $ homepage \u0026lt;chr\u0026gt; \u0026quot;http://www.pokemon.com/us/movies/movie-pokemon-… ## $ imdb_id \u0026lt;chr\u0026gt; \u0026quot;tt1226251\u0026quot;, \u0026quot;tt0051380\u0026quot;, \u0026quot;tt0118556\u0026quot;, \u0026quot;tt125595… ## $ original_language \u0026lt;chr\u0026gt; \u0026quot;ja\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;fr\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;de\u0026quot;, \u0026quot;en\u0026quot;, … ## $ original_title \u0026lt;chr\u0026gt; \u0026quot;ディアルガVSパルキアVSダークライ\u0026quot;, \u0026quot;Attack of t… ## $ overview \u0026lt;chr\u0026gt; \u0026quot;Ash and friends (this time accompanied by newco… ## $ popularity \u0026lt;dbl\u0026gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680… ## $ poster_path \u0026lt;chr\u0026gt; \u0026quot;/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\u0026quot;, \u0026quot;/9MgBNBqlH1… ## $ production_companies \u0026lt;chr\u0026gt; NA, \u0026quot;[{\u0026#39;name\u0026#39;: \u0026#39;Woolner Brothers Pictures Inc.\u0026#39;,… ## $ production_countries \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_3166_1\u0026#39;: \u0026#39;JP\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Japan\u0026#39;}, {\u0026#39;iso_3… ## $ release_date \u0026lt;chr\u0026gt; \u0026quot;7/14/07\u0026quot;, \u0026quot;5/19/58\u0026quot;, \u0026quot;5/23/97\u0026quot;, \u0026quot;9/4/10\u0026quot;, \u0026quot;2/11… ## $ runtime \u0026lt;dbl\u0026gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,… ## $ spoken_languages \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_639_1\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;English\u0026#39;}, {\u0026#39;iso_… ## $ status \u0026lt;chr\u0026gt; \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, … ## $ tagline \u0026lt;chr\u0026gt; \u0026quot;Somewhere Between Time \u0026amp; Space... A Legend Is B… ## $ title \u0026lt;chr\u0026gt; \u0026quot;Pokémon: The Rise of Darkrai\u0026quot;, \u0026quot;Attack of the 5… ## $ Keywords \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 11451, \u0026#39;name\u0026#39;: \u0026#39;pok√©mon\u0026#39;}, {\u0026#39;id\u0026#39;: 1155… ## $ cast \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;cast_id\u0026#39;: 3, \u0026#39;character\u0026#39;: \u0026#39;Tonio\u0026#39;, \u0026#39;credit_i… ## $ crew \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;credit_id\u0026#39;: \u0026#39;52fe44e7c3a368484e03d683\u0026#39;, \u0026#39;dep… preds_chosen sind alle Prädiktoren im Datensatz, oder nicht? Das prüfen wir mal kurz:\npreds_chosen %in% names(d_train) %\u0026gt;% all() ## [1] TRUE Ja, alle Elemente von preds_chosen sind Prädiktoren im (Train-)Datensatz.\n CV cv_scheme \u0026lt;- vfold_cv(d_train)  Rezept rec1 \u0026lt;- recipe(revenue ~ budget + popularity + runtime, data = d_train) %\u0026gt;% step_impute_bag(all_predictors()) %\u0026gt;% step_naomit(all_predictors()) rec1 ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 3 ## ## Operations: ## ## Bagged tree imputation for all_predictors() ## Removing rows with NA values in all_predictors() Man beachte, dass noch 21 Prädiktoren angezeigt werden, da das Rezept noch nicht auf den Datensatz angewandt (“gebacken”) wurde.\ntidy(rec1) ## # A tibble: 2 × 6 ## number operation type trained skip id ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 step impute_bag FALSE FALSE impute_bag_B9twc ## 2 2 step naomit FALSE FALSE naomit_udaqc Rezept checken:\nprep(rec1) ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 3 ## ## Training data contained 3000 data points and 2 incomplete rows. ## ## Operations: ## ## Bagged tree imputation for budget, popularity, runtime [trained] ## Removing rows with NA values in budget, popularity, runtime [trained] d_train_baked \u0026lt;- rec1 %\u0026gt;% prep() %\u0026gt;% bake(new_data = NULL) glimpse(d_train_baked) ## Rows: 3,000 ## Columns: 4 ## $ budget \u0026lt;dbl\u0026gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00, 8.00e+06,… ## $ popularity \u0026lt;dbl\u0026gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.148070, 0.743274… ## $ runtime \u0026lt;dbl\u0026gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119, 98, 122, … ## $ revenue \u0026lt;dbl\u0026gt; 12314651, 95149435, 13092000, 16000000, 3923970, 3261638, 8… Fehlende Werte noch übrig?\nlibrary(easystats) describe_distribution(d_train_baked) %\u0026gt;% select(Variable, n_Missing) ## Variable | n_Missing ## ---------------------- ## budget | 0 ## popularity | 0 ## runtime | 0 ## revenue | 0  Modell model_lm \u0026lt;- linear_reg()  Workflow wf1 \u0026lt;- workflow() %\u0026gt;% add_model(model_lm) %\u0026gt;% add_recipe(rec1)  Modell fitten (und tunen) doParallel::registerDoParallel(4) tic() lm_fit1 \u0026lt;- wf1 %\u0026gt;% tune_grid(resamples = cv_scheme) ## Warning: No tuning parameters have been detected, performance will be evaluated ## using the resamples with no tuning. Did you want to [tune()] parameters? toc() ## 3.32 sec elapsed lm_fit1[[\u0026quot;.notes\u0026quot;]][1] ## [[1]] ## # A tibble: 0 × 3 ## # … with 3 variables: location \u0026lt;chr\u0026gt;, type \u0026lt;chr\u0026gt;, note \u0026lt;chr\u0026gt;  Final Fit fit1_final \u0026lt;- wf1 %\u0026gt;% fit(d_train) fit1_final ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: linear_reg() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 2 Recipe Steps ## ## • step_impute_bag() ## • step_naomit() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## ## Call: ## stats::lm(formula = ..y ~ ., data = data) ## ## Coefficients: ## (Intercept) budget popularity runtime ## -2.901e+07 2.482e+00 2.604e+06 1.648e+05 preds \u0026lt;- fit1_final %\u0026gt;% predict(d_test)  Submission df submission_df \u0026lt;- d_test %\u0026gt;% select(id) %\u0026gt;% bind_cols(preds) %\u0026gt;% rename(revenue = .pred) head(submission_df) ## # A tibble: 6 × 2 ## id revenue ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 3001 -4147409. ## 2 3002 -8808305. ## 3 3003 8524140. ## 4 3004 31675553. ## 5 3005 -504235. ## 6 3006 13531732. Abspeichern und einreichen:\n#write_csv(submission_df, file = \u0026quot;submission.csv\u0026quot;)  Kaggle Score Diese Submission erzielte einen Score von Score: 6.14787 (RMSLE).\nsol \u0026lt;- 6.14787 Categories:\n ds1 21ss   ","permalink":"https://datenwerk.netlify.app/post/tmdb06/tmdb06/","summary":"Exercise Melden Sie sich an für die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?.\nSie benötigen dazu ein Konto; es ist auch möglich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Prädiktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verfügung. Eine klassische “predictive Competition” also :-) Allerdings können immer ein paar Schwierigkeiten auftreten ;-)","title":"tmdb06"},{"content":" Exercise Melden Sie sich an für die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?.\nSie benötigen dazu ein Konto; es ist auch möglich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Prädiktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verfügung. Eine klassische “predictive Competition” also :-) Allerdings können immer ein paar Schwierigkeiten auftreten ;-)\nAufgabe\nErstellen Sie ein Lineares-Modell mit Tidymodels!\nHinweise\n Verzichten Sie auf Vorverarbeitung. Tunen Sie die typischen Parameter. Reichen Sie das Modell ein und berichten Sie Ihren Score. Begrenzen Sie sich auf folgende Prädiktoren.  preds_chosen \u0026lt;- c(\u0026quot;id\u0026quot;, \u0026quot;budget\u0026quot;, \u0026quot;popularity\u0026quot;, \u0026quot;runtime\u0026quot;)          \n Solution  Pakete starten library(tidyverse) library(tidymodels)  Daten importieren d_train_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\u0026quot; d_test_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\u0026quot; d_train \u0026lt;- read_csv(d_train_path) d_test \u0026lt;- read_csv(d_test_path) Werfen wir einen Blick in die Daten:\nglimpse(d_train) ## Rows: 3,000 ## Columns: 23 ## $ id \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1… ## $ belongs_to_collection \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 313576, \u0026#39;name\u0026#39;: \u0026#39;Hot Tub Time Machine C… ## $ budget \u0026lt;dbl\u0026gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00… ## $ genres \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 35, \u0026#39;name\u0026#39;: \u0026#39;Comedy\u0026#39;}]\u0026quot;, \u0026quot;[{\u0026#39;id\u0026#39;: 35, \u0026#39;… ## $ homepage \u0026lt;chr\u0026gt; NA, NA, \u0026quot;http://sonyclassics.com/whiplash/\u0026quot;, \u0026quot;ht… ## $ imdb_id \u0026lt;chr\u0026gt; \u0026quot;tt2637294\u0026quot;, \u0026quot;tt0368933\u0026quot;, \u0026quot;tt2582802\u0026quot;, \u0026quot;tt182148… ## $ original_language \u0026lt;chr\u0026gt; \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;hi\u0026quot;, \u0026quot;ko\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, … ## $ original_title \u0026lt;chr\u0026gt; \u0026quot;Hot Tub Time Machine 2\u0026quot;, \u0026quot;The Princess Diaries … ## $ overview \u0026lt;chr\u0026gt; \u0026quot;When Lou, who has become the \\\u0026quot;father of the In… ## $ popularity \u0026lt;dbl\u0026gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807… ## $ poster_path \u0026lt;chr\u0026gt; \u0026quot;/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\u0026quot;, \u0026quot;/w9Z7A0GHEh… ## $ production_companies \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;name\u0026#39;: \u0026#39;Paramount Pictures\u0026#39;, \u0026#39;id\u0026#39;: 4}, {\u0026#39;nam… ## $ production_countries \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_3166_1\u0026#39;: \u0026#39;US\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;United States of… ## $ release_date \u0026lt;chr\u0026gt; \u0026quot;2/20/15\u0026quot;, \u0026quot;8/6/04\u0026quot;, \u0026quot;10/10/14\u0026quot;, \u0026quot;3/9/12\u0026quot;, \u0026quot;2/5/… ## $ runtime \u0026lt;dbl\u0026gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119… ## $ spoken_languages \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_639_1\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;English\u0026#39;}]\u0026quot;, \u0026quot;[{\u0026#39;… ## $ status \u0026lt;chr\u0026gt; \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, … ## $ tagline \u0026lt;chr\u0026gt; \u0026quot;The Laws of Space and Time are About to be Viol… ## $ title \u0026lt;chr\u0026gt; \u0026quot;Hot Tub Time Machine 2\u0026quot;, \u0026quot;The Princess Diaries … ## $ Keywords \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 4379, \u0026#39;name\u0026#39;: \u0026#39;time travel\u0026#39;}, {\u0026#39;id\u0026#39;: 96… ## $ cast \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;cast_id\u0026#39;: 4, \u0026#39;character\u0026#39;: \u0026#39;Lou\u0026#39;, \u0026#39;credit_id\u0026#39;… ## $ crew \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;credit_id\u0026#39;: \u0026#39;59ac067c92514107af02c8c8\u0026#39;, \u0026#39;dep… ## $ revenue \u0026lt;dbl\u0026gt; 12314651, 95149435, 13092000, 16000000, 3923970,… glimpse(d_test) ## Rows: 4,398 ## Columns: 22 ## $ id \u0026lt;dbl\u0026gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, … ## $ belongs_to_collection \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 34055, \u0026#39;name\u0026#39;: \u0026#39;Pokémon Collection\u0026#39;, \u0026#39;p… ## $ budget \u0026lt;dbl\u0026gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06… ## $ genres \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 12, \u0026#39;name\u0026#39;: \u0026#39;Adventure\u0026#39;}, {\u0026#39;id\u0026#39;: 16, \u0026#39;n… ## $ homepage \u0026lt;chr\u0026gt; \u0026quot;http://www.pokemon.com/us/movies/movie-pokemon-… ## $ imdb_id \u0026lt;chr\u0026gt; \u0026quot;tt1226251\u0026quot;, \u0026quot;tt0051380\u0026quot;, \u0026quot;tt0118556\u0026quot;, \u0026quot;tt125595… ## $ original_language \u0026lt;chr\u0026gt; \u0026quot;ja\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;fr\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;en\u0026quot;, \u0026quot;de\u0026quot;, \u0026quot;en\u0026quot;, … ## $ original_title \u0026lt;chr\u0026gt; \u0026quot;ディアルガVSパルキアVSダークライ\u0026quot;, \u0026quot;Attack of t… ## $ overview \u0026lt;chr\u0026gt; \u0026quot;Ash and friends (this time accompanied by newco… ## $ popularity \u0026lt;dbl\u0026gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680… ## $ poster_path \u0026lt;chr\u0026gt; \u0026quot;/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\u0026quot;, \u0026quot;/9MgBNBqlH1… ## $ production_companies \u0026lt;chr\u0026gt; NA, \u0026quot;[{\u0026#39;name\u0026#39;: \u0026#39;Woolner Brothers Pictures Inc.\u0026#39;,… ## $ production_countries \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_3166_1\u0026#39;: \u0026#39;JP\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Japan\u0026#39;}, {\u0026#39;iso_3… ## $ release_date \u0026lt;chr\u0026gt; \u0026quot;7/14/07\u0026quot;, \u0026quot;5/19/58\u0026quot;, \u0026quot;5/23/97\u0026quot;, \u0026quot;9/4/10\u0026quot;, \u0026quot;2/11… ## $ runtime \u0026lt;dbl\u0026gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,… ## $ spoken_languages \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;iso_639_1\u0026#39;: \u0026#39;en\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;English\u0026#39;}, {\u0026#39;iso_… ## $ status \u0026lt;chr\u0026gt; \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, \u0026quot;Released\u0026quot;, … ## $ tagline \u0026lt;chr\u0026gt; \u0026quot;Somewhere Between Time \u0026amp; Space... A Legend Is B… ## $ title \u0026lt;chr\u0026gt; \u0026quot;Pokémon: The Rise of Darkrai\u0026quot;, \u0026quot;Attack of the 5… ## $ Keywords \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;id\u0026#39;: 11451, \u0026#39;name\u0026#39;: \u0026#39;pok√©mon\u0026#39;}, {\u0026#39;id\u0026#39;: 1155… ## $ cast \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;cast_id\u0026#39;: 3, \u0026#39;character\u0026#39;: \u0026#39;Tonio\u0026#39;, \u0026#39;credit_i… ## $ crew \u0026lt;chr\u0026gt; \u0026quot;[{\u0026#39;credit_id\u0026#39;: \u0026#39;52fe44e7c3a368484e03d683\u0026#39;, \u0026#39;dep…  Resampling / Cross-Validation-Scheme cv_scheme \u0026lt;- vfold_cv(d_train, v = 3) \\(v=3\\) ist hier NUR gewählt, um Rechenzeit zu sparen. Für die “Wirklichkeit” wäre ein höherer Wert besser, z.B. \\(v=10\\).\n Rezept rec1 \u0026lt;- recipe(revenue ~ budget + popularity + runtime, data = d_train) %\u0026gt;% step_impute_bag(all_predictors()) %\u0026gt;% step_naomit(all_predictors()) rec1 ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 3 ## ## Operations: ## ## Bagged tree imputation for all_predictors() ## Removing rows with NA values in all_predictors()  Modell model_lm \u0026lt;- linear_reg()  Workflow wf1 \u0026lt;- workflow() %\u0026gt;% add_model(model_lm) %\u0026gt;% add_recipe(rec1)  Modell fitten (und tunen) Allerdings haben wir keine Tuning-Parameter beim LM.\nlm_fit1 \u0026lt;- wf1 %\u0026gt;% fit_resamples(resamples = cv_scheme) lm_fit1 ## # Resampling results ## # 3-fold cross-validation ## # A tibble: 3 × 4 ## splits id .metrics .notes ## \u0026lt;list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; ## 1 \u0026lt;split [2000/1000]\u0026gt; Fold1 \u0026lt;tibble [2 × 4]\u0026gt; \u0026lt;tibble [0 × 3]\u0026gt; ## 2 \u0026lt;split [2000/1000]\u0026gt; Fold2 \u0026lt;tibble [2 × 4]\u0026gt; \u0026lt;tibble [0 × 3]\u0026gt; ## 3 \u0026lt;split [2000/1000]\u0026gt; Fold3 \u0026lt;tibble [2 × 4]\u0026gt; \u0026lt;tibble [0 × 3]\u0026gt; collect_metrics(lm_fit1) ## # A tibble: 2 × 6 ## .metric .estimator mean n std_err .config ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 rmse standard 85685520. 3 2953145. Preprocessor1_Model1 ## 2 rsq standard 0.614 3 0.0171 Preprocessor1_Model1  Final Fit fit1_final \u0026lt;- wf1 %\u0026gt;% fit(d_train) fit1_final ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: linear_reg() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 2 Recipe Steps ## ## • step_impute_bag() ## • step_naomit() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## ## Call: ## stats::lm(formula = ..y ~ ., data = data) ## ## Coefficients: ## (Intercept) budget popularity runtime ## -2.901e+07 2.482e+00 2.604e+06 1.648e+05 preds \u0026lt;- fit1_final %\u0026gt;% predict(d_test)  Submission df submission_df \u0026lt;- d_test %\u0026gt;% select(id) %\u0026gt;% bind_cols(preds) %\u0026gt;% rename(revenue = .pred) head(submission_df) ## # A tibble: 6 × 2 ## id revenue ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 3001 -4147576. ## 2 3002 -8808347. ## 3 3003 8523960. ## 4 3004 31675238. ## 5 3005 -504415. ## 6 3006 13531450. Abspeichern und einreichen:\n#write_csv(submission_df, file = \u0026quot;submission.csv\u0026quot;)  Kaggle Score Diese Submission erzielte einen Score von Score: 6.14787 (RMSLE).\nsol \u0026lt;- 6.14787 Categories:\n ds1 21ss   ","permalink":"https://datenwerk.netlify.app/post/tmdb07/tmdb07/","summary":"Exercise Melden Sie sich an für die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?.\nSie benötigen dazu ein Konto; es ist auch möglich, sich mit seinem Google-Konto anzumelden.\nBei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Prädiktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verfügung. Eine klassische “predictive Competition” also :-) Allerdings können immer ein paar Schwierigkeiten auftreten ;-)","title":"tmdb07"},{"content":" Exercise Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall für Filme.\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\nd_train_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\u0026quot; d_test_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\u0026quot;  Aufgabe Reichen Sie bei Kaggle eine Submission für die Fallstudie ein! Berichten Sie den Score!\nHinweise:\n Sie müssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym möglich); alternativ können Sie sich mit einem Google-Konto anmelden. Halten Sie das Modell so einfach wie möglich. Verwenden Sie als Algorithmus die regularisierte lineare Regression . Minimieren Sie die Vorverarbeitung (steps) so weit als möglich. Verwenden Sie tidymodels.           \n Solution  Vorbereitung library(tidyverse) library(tidymodels) d_train_raw \u0026lt;- read_csv(d_train_path) d_test_raw \u0026lt;- read_csv(d_test_path) Train-Set verschlanken d_train \u0026lt;- d_train_raw %\u0026gt;% select(id, popularity, runtime, revenue, budget)   Test-Set verschlanken d_test \u0026lt;- d_test_raw %\u0026gt;% select(id,popularity, runtime, budget)    Rezept Rezept definieren rec2 \u0026lt;- recipe(revenue ~ ., data = d_train) %\u0026gt;% step_mutate(budget = ifelse(budget == 0, 1, budget)) %\u0026gt;% # log mag keine 0 step_log(budget) %\u0026gt;% step_impute_knn(all_predictors()) %\u0026gt;% step_dummy(all_nominal_predictors()) %\u0026gt;% update_role(id, new_role = \u0026quot;id\u0026quot;) rec2 ## Recipe ## ## Inputs: ## ## role #variables ## id 1 ## outcome 1 ## predictor 3 ## ## Operations: ## ## Variable mutation for ifelse(budget == 0, 1, budget) ## Log transformation on budget ## K-nearest neighbor imputation for all_predictors() ## Dummy variables from all_nominal_predictors()   Kreuzvalidierung / Resampling cv_scheme \u0026lt;- vfold_cv(d_train, v = 5, repeats = 3)  Modelle LM regularisiert mod_lm \u0026lt;- linear_reg(penalty = tune(), mixture = 1) %\u0026gt;% set_engine(\u0026quot;glmnet\u0026quot;)   Workflow-Set Hier nur ein sehr kleiner Workflow-Set.\nDas ist übrigens eine gute Strategie: Erstmal mit einem kleinen Prozess anfangen, und dann sukzessive erweitern.\npreproc2 \u0026lt;- list(rec1 = rec2) models2 \u0026lt;- list(lm1 = mod_lm) all_workflows2 \u0026lt;- workflow_set(preproc2, models2)  Fitten und tunen tmdb_model_set2 \u0026lt;- all_workflows2 %\u0026gt;% workflow_map(resamples = cv_scheme)  Finalisieren Wir müssen uns leider händisch das beste Modell raussuchen:\ntmdb_model_set2 %\u0026gt;% collect_metrics() %\u0026gt;% arrange(mean) %\u0026gt;% filter(.metric == \u0026quot;rmse\u0026quot;) %\u0026gt;% select(1,2, mean, std_err) ## # A tibble: 10 × 4 ## wflow_id .config mean std_err ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 rec1_lm1 Preprocessor1_Model01 116748717. 2625141. ## 2 rec1_lm1 Preprocessor1_Model02 116748717. 2625141. ## 3 rec1_lm1 Preprocessor1_Model03 116748717. 2625141. ## 4 rec1_lm1 Preprocessor1_Model04 116748717. 2625141. ## 5 rec1_lm1 Preprocessor1_Model05 116748717. 2625141. ## 6 rec1_lm1 Preprocessor1_Model06 116748717. 2625141. ## 7 rec1_lm1 Preprocessor1_Model07 116748717. 2625141. ## 8 rec1_lm1 Preprocessor1_Model08 116748717. 2625141. ## 9 rec1_lm1 Preprocessor1_Model09 116748717. 2625141. ## 10 rec1_lm1 Preprocessor1_Model10 116748717. 2625141. best_model_params2 \u0026lt;- extract_workflow_set_result(tmdb_model_set2, \u0026quot;rec1_lm1\u0026quot;) %\u0026gt;% select_best() ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. best_model_params2 ## # A tibble: 1 × 2 ## penalty .config ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 5.14e-10 Preprocessor1_Model01 Finalisieren Finalisieren bedeutet:\n Besten Workflow identifizieren (zur Erinnerung: Workflow = Rezept + Modell) Den besten Workflow mit den optimalen Modell-Parametern ausstatten Damit dann den ganzen Train-Datensatz fitten Auf dieser Basis das Test-Sample vorhersagen  best_wf2 \u0026lt;- all_workflows2 %\u0026gt;% extract_workflow(\u0026quot;rec1_lm1\u0026quot;) best_wf2 ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: linear_reg() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 4 Recipe Steps ## ## • step_mutate() ## • step_log() ## • step_impute_knn() ## • step_dummy() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Linear Regression Model Specification (regression) ## ## Main Arguments: ## penalty = tune() ## mixture = 1 ## ## Computational engine: glmnet best_wf_finalized2 \u0026lt;- best_wf2 %\u0026gt;% finalize_workflow(best_model_params2) best_wf_finalized2 ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: linear_reg() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 4 Recipe Steps ## ## • step_mutate() ## • step_log() ## • step_impute_knn() ## • step_dummy() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Linear Regression Model Specification (regression) ## ## Main Arguments: ## penalty = 5.14103509558056e-10 ## mixture = 1 ## ## Computational engine: glmnet  Final Fit fit_final2 \u0026lt;- best_wf_finalized2 %\u0026gt;% fit(d_train) fit_final2 ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: linear_reg() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 4 Recipe Steps ## ## • step_mutate() ## • step_log() ## • step_impute_knn() ## • step_dummy() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## ## Call: glmnet::glmnet(x = maybe_matrix(x), y = y, family = \u0026quot;gaussian\u0026quot;, alpha = ~1) ## ## Df %Dev Lambda ## 1 0 0.00 63460000 ## 2 1 3.62 57820000 ## 3 1 6.62 52680000 ## 4 1 9.11 48000000 ## 5 1 11.18 43740000 ## 6 1 12.90 39850000 ## 7 2 15.24 36310000 ## 8 2 17.19 33090000 ## 9 2 18.81 30150000 ## 10 2 20.16 27470000 ## 11 2 21.28 25030000 ## 12 2 22.21 22800000 ## 13 3 23.10 20780000 ## 14 3 23.95 18930000 ## 15 3 24.66 17250000 ## 16 3 25.25 15720000 ## 17 3 25.74 14320000 ## 18 3 26.15 13050000 ## 19 3 26.49 11890000 ## 20 3 26.77 10830000 ## 21 3 27.00 9872000 ## 22 3 27.20 8995000 ## 23 3 27.36 8196000 ## 24 3 27.49 7467000 ## 25 3 27.60 6804000 ## 26 3 27.69 6200000 ## 27 3 27.77 5649000 ## 28 3 27.83 5147000 ## 29 3 27.88 4690000 ## 30 3 27.93 4273000 ## 31 3 27.96 3894000 ## 32 3 27.99 3548000 ## 33 3 28.02 3232000 ## 34 3 28.04 2945000 ## 35 3 28.06 2684000 ## 36 3 28.07 2445000 ## 37 3 28.08 2228000 ## 38 3 28.09 2030000 ## 39 3 28.10 1850000 ## 40 3 28.11 1685000 ## 41 3 28.11 1536000 ## 42 3 28.12 1399000 ## 43 3 28.12 1275000 ## 44 3 28.13 1162000 ## 45 3 28.13 1058000 ## 46 3 28.13 964500 ## ## ... ## and 12 more lines. preds \u0026lt;- fit_final2 %\u0026gt;% predict(new_data = d_test) head(preds) ## # A tibble: 6 × 1 ## .pred ## \u0026lt;dbl\u0026gt; ## 1 -14840891. ## 2 10804710. ## 3 11698900. ## 4 99190531. ## 5 41798496. ## 6 29974421.  Submission df Wir brauchen die ID-Spalte und die Vorhersagen für die Einreichung:\nsubmission_df \u0026lt;- d_test %\u0026gt;% select(id) %\u0026gt;% bind_cols(preds) %\u0026gt;% rename(revenue = .pred) head(submission_df) ## # A tibble: 6 × 2 ## id revenue ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 3001 -14840891. ## 2 3002 10804710. ## 3 3003 11698900. ## 4 3004 99190531. ## 5 3005 41798496. ## 6 3006 29974421. Abspeichern und einreichen:\nwrite_csv(submission_df, file = \u0026quot;submission_regul_lm.csv\u0026quot;) Leider ein schlechter Score: 5.77945.\nCategories:\n ds1 21ss    ","permalink":"https://datenwerk.netlify.app/post/tmdb08/tmdb08/","summary":"Exercise Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall für Filme.\nDie Daten können Sie von der Kaggle-Projektseite beziehen oder so:\nd_train_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\u0026quot; d_test_path \u0026lt;- \u0026quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\u0026quot;  Aufgabe Reichen Sie bei Kaggle eine Submission für die Fallstudie ein! Berichten Sie den Score!\nHinweise:\n Sie müssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym möglich); alternativ können Sie sich mit einem Google-Konto anmelden.","title":"tmdb08"},{"content":" Exercise Vorhersagen, etwa in einem Regressionsmodell, sind mit mehreren Arten von Unsicherheit konfrontiert.\nBerechnen Sie dazu ein Regressionsmodell, Datensatz mtcars, mit hp als Prädiktor (UV) und mpg als AV (Kriterium)!\nDann sagen Sie bitte den Wert der AV für eine Beobachtungseinheit mit mittlerer Ausprägung im Präktor vorher:\nEinmal nur unter Berücksichtigung der Unsicherheit innerhalb des Modells (“Konfidenzintervall”); einmal unter Berüksichtigung der Unsicherheit innerhalb des Modells sowie die Unsicherheit durch die Koffizienten (“Vohersageintervall”).\nHinweise:\n predict() ist eine Funktion, die Sie zur Vorhersage von Regressionsmodellen verwenden können. Verwenden Sie lm() zur Berechnung eines Regressionsmodells. Das Argument type von predict() erlaubt Ihnen die Wahl der Art der Vorhersage, betrachten Sie Hilfe der Funktion z.B. hier.  Bei welchem Intervall ist die Ungewissheit in der Vorhersage größer?\nAnswerlist  Konfidenzintervall Vohersageintervall Gleich groß Kommt auf weitere Faktoren an, keine pauschale Antwort möglich           \n  Solution Der mittlere Wert von hp beträgt:\nmtcars %\u0026gt;% summarise(mean(hp)) ## mean(hp) ## 1 146.6875 lm1 \u0026lt;- lm(mpg ~ hp, data = mtcars) Konfidenzintervall:\npredict(lm1, newdata = tibble(hp = mean(147)), interval = \u0026quot;confidence\u0026quot;) ## fit lwr upr ## 1 20.0693 18.67466 21.46395 Vorhersageintervall:\npredict(lm1, newdata = tibble(hp = mean(147)), interval = \u0026quot;prediction\u0026quot;) ## fit lwr upr ## 1 20.0693 12.05776 28.08085 Answerlist  Falsch Wahr Falsch Falsch  Categories:\n qm2 qm2-thema01 ws22    ","permalink":"https://datenwerk.netlify.app/post/vorhersageintervall1/vorhersageintervall1/","summary":"Exercise Vorhersagen, etwa in einem Regressionsmodell, sind mit mehreren Arten von Unsicherheit konfrontiert.\nBerechnen Sie dazu ein Regressionsmodell, Datensatz mtcars, mit hp als Prädiktor (UV) und mpg als AV (Kriterium)!\nDann sagen Sie bitte den Wert der AV für eine Beobachtungseinheit mit mittlerer Ausprägung im Präktor vorher:\nEinmal nur unter Berücksichtigung der Unsicherheit innerhalb des Modells (“Konfidenzintervall”); einmal unter Berüksichtigung der Unsicherheit innerhalb des Modells sowie die Unsicherheit durch die Koffizienten (“Vohersageintervall”).","title":"vorhersageintervall1"},{"content":" Exercise Für Statistiken (Stichprobe) verwendet man meist lateinische Buchstaben; für Parameter (Population) verwendet man meist (die entsprechenden) griechischen Buchstaben.\nVervollständigen Sie folgende Tabelle entsprechend!\n  Kennwert Statistik Parameter    Mittelwert \\(\\bar{X}\\) NA  Mittelwertsdifferenz \\(\\bar{X}_1-\\bar{X}_2\\) NA  Streuung sd NA  Anteil p NA  Korrelation r NA  Regressionsgewicht b NA             \n Solution   Kennwert Statistik Parameter    Mittelwert \\[\\bar{X}\\] \\[\\mu\\]  Mittelwertsdifferenz \\[d=\\bar{X}_1-\\bar{X}_2\\] \\[\\mu_1\\]- \\[\\mu_2\\]  Streuung sd \\[\\sigma\\]  Anteil p \\[\\pi\\]  Korrelation r \\[\\rho\\]  Regressionsgewicht b \\[\\beta\\]    Categories:\n qm2 qm2-thema01   ","permalink":"https://datenwerk.netlify.app/post/griech-buchstaben/griech-buchstaben-inferenz/","summary":"Exercise Für Statistiken (Stichprobe) verwendet man meist lateinische Buchstaben; für Parameter (Population) verwendet man meist (die entsprechenden) griechischen Buchstaben.\nVervollständigen Sie folgende Tabelle entsprechend!\n  Kennwert Statistik Parameter    Mittelwert \\(\\bar{X}\\) NA  Mittelwertsdifferenz \\(\\bar{X}_1-\\bar{X}_2\\) NA  Streuung sd NA  Anteil p NA  Korrelation r NA  Regressionsgewicht b NA             \n Solution   Kennwert Statistik Parameter    Mittelwert \\[\\bar{X}\\] \\[\\mu\\]  Mittelwertsdifferenz \\[d=\\bar{X}_1-\\bar{X}_2\\] \\[\\mu_1\\]- \\[\\mu_2\\]  Streuung sd \\[\\sigma\\]  Anteil p \\[\\pi\\]  Korrelation r \\[\\rho\\]  Regressionsgewicht b \\[\\beta\\]    Categories:","title":"Griech-Buchstaben-Inferenz"},{"content":" Exercise Die Inferenzstatistik ist eine Sammlung an Verfahren zur Bemessung von Unsicherheit in statistischen Schlüssen.\nFür welche Statistiken - also Kennzahlen der Deskriptivstatistik wie etwa \\(\\bar{X}, sd, r\\) - kann man die Inferenzstatistik verwenden?\n Für welche Forschungsfragen oder -bereiche kann man die Inferenzstatistik verwenden?\n Gibt es besondere Fälle, in denen man nicht die Inferenzstatistik verwenden möchte? Wenn ja, welche?\n           \n Solution Für (grundsätzlich) alle: Für jede Statistik kann man prinzipiell von der jeweiligen Stichprobe (auf Basis derer die Statistik berechnet wurde) auf eine zugehörige Grundgesamtheit schließen.\n Für (grundsätzlich) alle: Die Methoden der Inferenzstatistik sind prinzipiell unabhängig von den Spezifika bestimmter Forschungsfragen oder -bereiche. In den meisten Forschungsfragen ist man daran interessiert allgemeingültige Aussagen zu treffen. Da Statistiken sich nur auf eine Stichprobe - also einen zumeist nur kleinen Teil einer Grundgesamtheit beziehen - wird man sich kaum mit einer Statistik zufrieden geben, sondern nach Inferenzstatistik verlangen.\n In einigen Ausnahmefällen wird man auf eine Inferenzstatistik verzichten. Etwa wenn man bereits eine Vollerhebung durchgeführt hat, z.B. alle Mitarbeitis eines Unternehmens befragt hat, dann kennt man ja bereits den wahren Populationswert. Ein anderer Fall ist, wenn man nicht an Verallgemeinerungen interessiert ist: Kennt man etwa die Überlebenschance \\(p\\) des Titanic-Unglücks, so ist es fraglich auf welche Grundgesamtheit man die Statistik \\(p\\) bzw. zu welchem Paramter \\(\\pi\\) (kleines Pi) man generalisieren möchte.\n  Categories:\n qm2 qm2-thema01   ","permalink":"https://datenwerk.netlify.app/post/inferenz-fuer-alle/inferenz-fuer-alle/","summary":"Exercise Die Inferenzstatistik ist eine Sammlung an Verfahren zur Bemessung von Unsicherheit in statistischen Schlüssen.\nFür welche Statistiken - also Kennzahlen der Deskriptivstatistik wie etwa \\(\\bar{X}, sd, r\\) - kann man die Inferenzstatistik verwenden?\n Für welche Forschungsfragen oder -bereiche kann man die Inferenzstatistik verwenden?\n Gibt es besondere Fälle, in denen man nicht die Inferenzstatistik verwenden möchte? Wenn ja, welche?","title":"Inferenz-fuer-alle"},{"content":" Exercise Man kann angeben, wie genau eine Schätzung von Regressionskoeffizienten die Grundgesamtheit widerspiegelt. Zumeist wird dazu der Standardfehler (engl. standard error, SE) verwendet.\nIn dieser Übung untersuchen wir, wie sich der SE als Funktion der Stichprobengröße, \\(n\\), verhält.\nErstellen Sie dazu folgenden Datensatz:\nlibrary(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✔ ggplot2 3.3.6 ✔ purrr 0.3.4 ## ✔ tibble 3.1.7 ✔ dplyr 1.0.9 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.0 ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() n \u0026lt;- 2^4 d \u0026lt;- tibble(x = rnorm(n = n), # im Default: mean = 0, sd = 1 y = x + rnorm(n, mean = 0, sd = .5)) Hier ist das Ergebnis. Uns interessiert v.a. Std. Error für den Prädiktor x:\nlm(y ~ x, data = d) %\u0026gt;% summary() ## ## Call: ## lm(formula = y ~ x, data = d) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.4691 -0.1671 0.1412 0.3928 1.0587 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.1400 0.1726 0.811 0.431 ## x 0.9091 0.1454 6.254 2.11e-05 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.6801 on 14 degrees of freedom ## Multiple R-squared: 0.7364, Adjusted R-squared: 0.7176 ## F-statistic: 39.11 on 1 and 14 DF, p-value: 2.114e-05 Hier haben wir eine Tabelle mit zwei Variablen, x und y, definiert mit n=16.\nVerdoppeln Sie die Stichprobengröße 5 Mal und betrachten Sie, wie sich die Schätzgenauigkeit, gemessen über den SE, verändert. Berechnen Sie dazu für jedes n eine Regression mit x als Prädiktor und y als AV!\nBei welcher Stichprobengröße ist SE am kleinsten?\nAnswerlist  \\(2^5\\) \\(2^6\\) \\(2^7\\) \\(2^8\\) \\(2^9\\)           \n  Solution Probieren wir es aus!\nErste Verdopplung, \\(n=2^5\\):\nn \u0026lt;- 2^5 d5 \u0026lt;- tibble(x = rnorm(n = n), # im Default: mean = 0, sd = 1 y = x + rnorm(n, mean = 0, sd = .5)) lm5 \u0026lt;- lm(y ~ x, data = d5) lm5 %\u0026gt;% summary() ## ## Call: ## lm(formula = y ~ x, data = d5) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.68715 -0.28669 -0.00344 0.19131 0.94701 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -0.01049 0.07392 -0.142 0.888 ## x 1.08799 0.07182 15.150 1.35e-15 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.4181 on 30 degrees of freedom ## Multiple R-squared: 0.8844, Adjusted R-squared: 0.8805 ## F-statistic: 229.5 on 1 and 30 DF, p-value: 1.346e-15 Man kann sich den Standardfehler komfortabler ausgeben lassen, wenn man das Paket broom verwendet:\nlibrary(broom) lm5 %\u0026gt;% tidy() ## # A tibble: 2 × 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) -0.0105 0.0739 -0.142 8.88e- 1 ## 2 x 1.09 0.0718 15.1 1.35e-15 Dann könnte man z.B. die Spalte std.error selektieren und nach term==x filtern:\nlm5 %\u0026gt;% tidy() %\u0026gt;% filter(term == \u0026quot;x\u0026quot;) %\u0026gt;% select(std.error)  ## # A tibble: 1 × 1 ## std.error ## \u0026lt;dbl\u0026gt; ## 1 0.0718 Jetzt mit den anderen Stichprobengrößen:\nn \u0026lt;- 2^6 d \u0026lt;- tibble(x = rnorm(n = n), # im Default: mean = 0, sd = 1 y = x + rnorm(n, mean = 0, sd = .5)) mein_lm \u0026lt;- lm(y ~ x, data = d) mein_lm %\u0026gt;% tidy() %\u0026gt;% filter(term == \u0026quot;x\u0026quot;) %\u0026gt;% select(std.error)  ## # A tibble: 1 × 1 ## std.error ## \u0026lt;dbl\u0026gt; ## 1 0.0829 n \u0026lt;- 2^7 d \u0026lt;- tibble(x = rnorm(n = n), # im Default: mean = 0, sd = 1 y = x + rnorm(n, mean = 0, sd = .5)) mein_lm \u0026lt;- lm(y ~ x, data = d) mein_lm %\u0026gt;% tidy() %\u0026gt;% filter(term == \u0026quot;x\u0026quot;) %\u0026gt;% select(std.error)  ## # A tibble: 1 × 1 ## std.error ## \u0026lt;dbl\u0026gt; ## 1 0.0425 n \u0026lt;- 2^8 d \u0026lt;- tibble(x = rnorm(n = n), # im Default: mean = 0, sd = 1 y = x + rnorm(n, mean = 0, sd = .5)) mein_lm \u0026lt;- lm(y ~ x, data = d) mein_lm %\u0026gt;% tidy() %\u0026gt;% filter(term == \u0026quot;x\u0026quot;) %\u0026gt;% select(std.error)  ## # A tibble: 1 × 1 ## std.error ## \u0026lt;dbl\u0026gt; ## 1 0.0308 n \u0026lt;- 2^9 d \u0026lt;- tibble(x = rnorm(n = n), # im Default: mean = 0, sd = 1 y = x + rnorm(n, mean = 0, sd = .5)) mein_lm \u0026lt;- lm(y ~ x, data = d) mein_lm %\u0026gt;% tidy() %\u0026gt;% filter(term == \u0026quot;x\u0026quot;) %\u0026gt;% select(std.error)  ## # A tibble: 1 × 1 ## std.error ## \u0026lt;dbl\u0026gt; ## 1 0.0228 Answerlist  Falsch Falsch Falsch Falsch Wahr. Die größte Stichprobe impliziert den kleinsten SE, ceteris paribus.  Categories:\n qm2 qm2-thema01 ws22    ","permalink":"https://datenwerk.netlify.app/post/lm-standardfehler/lm-standardfehler/","summary":"Exercise Man kann angeben, wie genau eine Schätzung von Regressionskoeffizienten die Grundgesamtheit widerspiegelt. Zumeist wird dazu der Standardfehler (engl. standard error, SE) verwendet.\nIn dieser Übung untersuchen wir, wie sich der SE als Funktion der Stichprobengröße, \\(n\\), verhält.\nErstellen Sie dazu folgenden Datensatz:\nlibrary(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✔ ggplot2 3.3.6 ✔ purrr 0.3.4 ## ✔ tibble 3.1.7 ✔ dplyr 1.0.9 ## ✔ tidyr 1.","title":"lm-Standardfehler"},{"content":" Exercise Wir suchen ein Modell, das einen nichtlinearen Zusammenhang von PS-Zahl und Spritverbrauch darstellt (Datensatz mtcars).\nGeben Sie dafür ein mögliches Modell an! Nutzen Sie den R-Befehl lm.\n         \n Solution mtcars \u0026lt;- mtcars %\u0026gt;% mutate(mpg_log = log(mpg)) lm1 \u0026lt;- lm(mpg_log ~ hp, data = mtcars) summary(lm1) ## ## Call: ## lm(formula = mpg_log ~ hp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.41577 -0.06583 -0.01737 0.09827 0.39621 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 3.4604669 0.0785838 44.035 \u0026lt; 2e-16 *** ## hp -0.0034287 0.0004867 -7.045 7.85e-08 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.1858 on 30 degrees of freedom ## Multiple R-squared: 0.6233, Adjusted R-squared: 0.6107 ## F-statistic: 49.63 on 1 and 30 DF, p-value: 7.853e-08 Visualisieren wir die Vorhersagen des Modells:\nmtcars \u0026lt;- mtcars %\u0026gt;% mutate(pred = predict(lm1)) mtcars %\u0026gt;% ggplot() + aes(x = hp) + geom_line(aes( y = pred), color = \u0026quot;blue\u0026quot;) + geom_point(aes(y = mpg_log)) + labs(y = \u0026quot;log(mpg)\u0026quot;, title = \u0026quot;Vorhersage von log-mpg in einem Log-Y-Modell\u0026quot;) Möchte man auf der Y-Achse mpg und nicht log(mpg) anzeigen, muss man den Logarithmus wieder “auflösen”, das erreicht man mit der Umkehrfunktion des Logarithmus, das Exponentieren (man “delogarithmiert”):\n\\[\\begin{aligned} log(y) \u0026amp;= x \\qquad | \\text{Y in Log-Form}\\\\ exp(log(y)) \u0026amp;= exp(x) \\qquad | \\text{Jetzt exponenzieren wir beide Seiten}\\\\ y = exp(x) \\end{aligned}\\]\nDabei gilt \\(exp(x) = e^x\\), mit \\(e\\) als Eulersche Zahl (2.71…).\nmtcars \u0026lt;- mtcars %\u0026gt;% mutate(pred_delog = exp(pred)) # delogarithmieren mtcars %\u0026gt;% ggplot() + aes(x = hp) + geom_line(aes( y = pred_delog), color = \u0026quot;blue\u0026quot;) + geom_point(aes(y = mpg_log)) + labs(y = \u0026quot;mpg\u0026quot;, title = \u0026quot;Vorhersage von mpg in einem Log-Y-Modell\u0026quot;) Categories:\n qm2 qm2-thema01 ws22   ","permalink":"https://datenwerk.netlify.app/post/nichtlineareregr1/nichtlineare-regr1/","summary":"Exercise Wir suchen ein Modell, das einen nichtlinearen Zusammenhang von PS-Zahl und Spritverbrauch darstellt (Datensatz mtcars).\nGeben Sie dafür ein mögliches Modell an! Nutzen Sie den R-Befehl lm.\n         \n Solution mtcars \u0026lt;- mtcars %\u0026gt;% mutate(mpg_log = log(mpg)) lm1 \u0026lt;- lm(mpg_log ~ hp, data = mtcars) summary(lm1) ## ## Call: ## lm(formula = mpg_log ~ hp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.","title":"nichtlineare-regr1"},{"content":" Exercise Erstellen Sie eine Analyse, die einem typischen Vorhersageprojekt entspricht!\nNutzen Sie den Datensatz palmerpenguins!\nSagen Sie die Variable body_mass_g vorher.\nHinweise:\n Halten Sie die Analyse einfach. Teilen Sie Test- vs. Train-Set hälftig auf. Teilen Sie Analysis vs. Assessment-Set 3:1 auf.           \n Solution Pakete laden:\nlibrary(tidymodels) ## ── Attaching packages ────────────────────────────────────── tidymodels 0.2.0 ── ## ✔ broom 0.8.0 ✔ recipes 0.2.0 ## ✔ dials 0.1.1 ✔ rsample 0.1.1 ## ✔ dplyr 1.0.9 ✔ tibble 3.1.7 ## ✔ ggplot2 3.3.6 ✔ tidyr 1.2.0 ## ✔ infer 1.0.2 ✔ tune 0.2.0 ## ✔ modeldata 0.1.1 ✔ workflows 0.2.6 ## ✔ parsnip 0.2.1 ✔ workflowsets 0.2.1 ## ✔ purrr 0.3.4 ✔ yardstick 1.0.0 ## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ── ## ✖ purrr::discard() masks scales::discard() ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ✖ recipes::step() masks stats::step() ## • Search for functions across packages at https://www.tidymodels.org/find/ library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ✔ stringr 1.4.0 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ readr::col_factor() masks scales::col_factor() ## ✖ purrr::discard() masks scales::discard() ## ✖ dplyr::filter() masks stats::filter() ## ✖ stringr::fixed() masks recipes::fixed() ## ✖ dplyr::lag() masks stats::lag() ## ✖ readr::spec() masks yardstick::spec() library(easystats) ## # Attaching packages: easystats 0.5.0 (red = needs update) ## ✖ insight 0.17.1.8 ✔ datawizard 0.4.1.3 ## ✔ bayestestR 0.12.1.1 ✖ performance 0.9.0.6 ## ✔ parameters 0.18.1.2 ✔ effectsize 0.7.0 ## ✔ modelbased 0.8.1.1 ✔ correlation 0.8.1.1 ## ✖ see 0.7.0.2 ✔ report 0.5.1.2 ## ## Restart the R-Session and update packages in red with \u0026#39;easystats::easystats_update()\u0026#39;. data(\u0026quot;penguins\u0026quot;, package = \u0026quot;palmerpenguins\u0026quot;) Zeilen mischen und Train- vs. Testset aufteilen:\npenguins2 \u0026lt;- penguins %\u0026gt;% sample_n(size = nrow(.)) d_train \u0026lt;- penguins2 %\u0026gt;% slice(1:(344/2)) d_test \u0026lt;- penguins2 %\u0026gt;% slice(173:nrow(penguins)) Das Trainset weiter aufteilen:\nd_split \u0026lt;- initial_split(d_train) d_analysis \u0026lt;- training(d_split) d_assessment \u0026lt;- testing(d_split) Rezept definieren:\nrec1 \u0026lt;- recipe(body_mass_g ~ ., data = d_analysis) %\u0026gt;% step_impute_knn(all_predictors()) %\u0026gt;% step_normalize(all_numeric(), -all_outcomes()) Rezept prüfen:\nd_analysis_baked \u0026lt;- rec1 %\u0026gt;% prep() %\u0026gt;% bake(new_data = NULL) describe_distribution(d_analysis_baked) ## Variable | Mean | SD | IQR | Range | Skewness | Kurtosis | n | n_Missing ## ------------------------------------------------------------------------------------------------------------- ## bill_length_mm | -5.23e-16 | 1.00 | 1.79 | [-2.09, 1.65] | -0.13 | -1.22 | 129 | 0 ## bill_depth_mm | 5.14e-16 | 1.00 | 1.61 | [-1.97, 2.09] | -0.14 | -0.95 | 129 | 0 ## flipper_length_mm | 4.38e-16 | 1.00 | 1.66 | [-1.77, 2.13] | 0.41 | -0.94 | 129 | 0 ## year | -1.11e-14 | 1.00 | 2.52 | [-1.21, 1.31] | 0.07 | -1.41 | 129 | 0 ## body_mass_g | 4164.73 | 749.70 | 1137.50 | [2700.00, 5800.00] | 0.37 | -0.68 | 129 | 0 Workflow und CV definieren:\nm1 \u0026lt;- linear_reg() wf1 \u0026lt;- workflow() %\u0026gt;% add_recipe(rec1) %\u0026gt;% add_model(m1) cv_scheme \u0026lt;- vfold_cv(d_analysis, v = 2) Fitten (hier kein Tuning):\nfit1 \u0026lt;- wf1 %\u0026gt;% tune_grid(resamples = cv_scheme) ## Warning: No tuning parameters have been detected, performance will be evaluated ## using the resamples with no tuning. Did you want to [tune()] parameters? Finalisieren:\nshow_best(fit1) ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. ## # A tibble: 1 × 6 ## .metric .estimator mean n std_err .config ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 rmse standard 293. 2 9.97 Preprocessor1_Model1 wf1_final \u0026lt;- wf1 %\u0026gt;% finalize_workflow(show_best(fit1)) ## Warning: No value of `metric` was given; metric \u0026#39;rmse\u0026#39; will be used. wf1_final ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: linear_reg() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 2 Recipe Steps ## ## • step_impute_knn() ## • step_normalize() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Linear Regression Model Specification (regression) ## ## Computational engine: lm Modellgüte:\nfit1_final \u0026lt;- wf1_final %\u0026gt;% last_fit(d_split) collect_metrics(fit1_final) ## # A tibble: 2 × 4 ## .metric .estimator .estimate .config ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 rmse standard 287. Preprocessor1_Model1 ## 2 rsq standard 0.863 Preprocessor1_Model1 fit1_train \u0026lt;- wf1_final %\u0026gt;% fit(d_train) fit1_test \u0026lt;- fit1_train %\u0026gt;% predict(d_test) head(fit1_test) ## # A tibble: 6 × 1 ## .pred ## \u0026lt;dbl\u0026gt; ## 1 4714. ## 2 4060. ## 3 3407. ## 4 3311. ## 5 4238. ## 6 4919. Vgl https://workflows.tidymodels.org/reference/predict-workflow.html\nSubmitten:\nsubm_df \u0026lt;- d_test %\u0026gt;% mutate(id = 173:344) %\u0026gt;% bind_cols(fit1_test) %\u0026gt;% select(id, .pred) %\u0026gt;% rename(pred = .pred) Und als CSV-Datei speichern:\n#write_csv(subm_df, file = \u0026quot;submission_blabla.csv\u0026quot;) Categories:\n R ds1 sose22   ","permalink":"https://datenwerk.netlify.app/post/predictioncontest1/predictioncontest1/","summary":"Exercise Erstellen Sie eine Analyse, die einem typischen Vorhersageprojekt entspricht!\nNutzen Sie den Datensatz palmerpenguins!\nSagen Sie die Variable body_mass_g vorher.\nHinweise:\n Halten Sie die Analyse einfach. Teilen Sie Test- vs. Train-Set hälftig auf. Teilen Sie Analysis vs. Assessment-Set 3:1 auf.           \n Solution Pakete laden:\nlibrary(tidymodels) ## ── Attaching packages ────────────────────────────────────── tidymodels 0.2.0 ── ## ✔ broom 0.","title":"predictioncontest1"},{"content":" Exercise Zwei Modelle, m1 und m2 produzieren jeweils die gleiche Vorhersage (den gleichen Punktschätzer).\nm1:\n## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.196567 -0.069054 0.005416 0.049245 0.261177 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.009946 0.009594 1.037 0.302 ## x 1.006439 0.009749 103.240 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.0959 on 98 degrees of freedom ## Multiple R-squared: 0.9909, Adjusted R-squared: 0.9908 ## F-statistic: 1.066e+04 on 1 and 98 DF, p-value: \u0026lt; 2.2e-16 m2:\n## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.69275 -0.70654 0.01495 0.66760 2.99572 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -0.001719 0.104292 -0.016 0.987 ## x 0.906466 0.109446 8.282 6.31e-13 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 1.041 on 98 degrees of freedom ## Multiple R-squared: 0.4118, Adjusted R-squared: 0.4057 ## F-statistic: 68.6 on 1 and 98 DF, p-value: 6.315e-13 Die Modelle unterscheiden sich aber in ihrer Ungewissheit bezüglich \\(\\beta\\), wie in der Spalte Std. Error ausgedrückt.\nWelches der beiden Modelle ist zu bevorzugen? Begründen Sie.\n         \n Solution Modell m1 hat eine kleinere Ungewissheit im Hinblick auf die Modellkoeffizienten \\(\\beta_0, \\beta_1\\) und ist daher gegenüber m2 zu bevorzugen.\nCategories:\n qm2 qm2-thema01 ws22   ","permalink":"https://datenwerk.netlify.app/post/punktschaetzer-reicht-nicht/punktschaetzer-reicht-nicht/","summary":"Exercise Zwei Modelle, m1 und m2 produzieren jeweils die gleiche Vorhersage (den gleichen Punktschätzer).\nm1:\n## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.196567 -0.069054 0.005416 0.049245 0.261177 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.009946 0.009594 1.037 0.302 ## x 1.006439 0.009749 103.240 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.","title":"punktschaetzer-reicht-nicht"},{"content":" Exercise In dieser Übung untersuchen wir den Effekt der Stichprobengröße auf die Genauigkeit der Schätzung. Und zwar auf praktische Art und Weise.\nAls praktisches Beispiel soll uns dabei die Körpergröße dienen. Wir erfragen die Körpergröße der Studis und betrachten den Mittelwert einer Stichrpobe in Abhängigkeit der Größe der Stichprobe.\nGeben Sie anonym Ihre Körpergröße hier ein. Sie können die Daten hier beziehen. Berechnen Sie den Mittelwert der Körpergröße für eine zufällige Stichprobe der Größen \\(n=5\\) und \\(n=50\\) Dann berechnen Sie die den “echten” Mittelwert der Studis; damit ist der Mittelwert aller Werte der Tabelle gemeint. Diskutieren Sie die Ergebnisse! Wird die Schätzung genauer bei größerer Stichprobe? Wird die Schätzung “robuster” (weniger schwankend) bei größerer Stichprobe?           \n Solution Individuell\nCategories:\n qm2 qm2-thema01 ws22   ","permalink":"https://datenwerk.netlify.app/post/stichprobenziehen1/stichprobenziehen1/","summary":"Exercise In dieser Übung untersuchen wir den Effekt der Stichprobengröße auf die Genauigkeit der Schätzung. Und zwar auf praktische Art und Weise.\nAls praktisches Beispiel soll uns dabei die Körpergröße dienen. Wir erfragen die Körpergröße der Studis und betrachten den Mittelwert einer Stichrpobe in Abhängigkeit der Größe der Stichprobe.\nGeben Sie anonym Ihre Körpergröße hier ein. Sie können die Daten hier beziehen. Berechnen Sie den Mittelwert der Körpergröße für eine zufällige Stichprobe der Größen \\(n=5\\) und \\(n=50\\) Dann berechnen Sie die den “echten” Mittelwert der Studis; damit ist der Mittelwert aller Werte der Tabelle gemeint.","title":"Stichprobenziehen1"},{"content":" Exercise Eine statistische Analyse, wie eine Regression, ist mit mehreren Arten an Ungewissheit konfrontiert. Zum einen gibt es die Ungewissheit in den Modellparametern. Für die Regression bedeutet das: “Liegt die Regressionsgerade in”Wahrheit” (in der Population) genauso wie in der Stichprobe, sind Achsenabschnitt und Steigung in der Stichprobe also identisch zur Popuation?“. Zum anderen die Ungewissheit innerhalb des Modells. Auch wenn wir die”wahre” Regressionsgleichung kennen würden, wären (in aller Regel) die Vorhersagen trotzdem nicht perfekt. Auch wenn wir etwa wüssten, wieviel Klausurpunkte “in Wahrheit” pro Stunde Lernen herausspringen (und wenn wir den wahren Achsenabschnitt kennen würden), so würde das Modell trotzdem keine perfekten Vorhersagen zum Klausurerfolg liefern. Vermutlich fehlen dem Modell wichtige Informationen etwa zur Motivation der Studentis.\nVor diesem Hintergrund, betrachten Sie folgendes statistisches Modell, das mit den Methoden der Bayes-Statistik berechnet wurde:\ndata(mtcars) library(rstanarm)  ## Loading required package: Rcpp ## This is rstanarm version 2.21.3 ## - See https://mc-stan.org/rstanarm/articles/priors for changes to default priors! ## - Default priors may change, so it\u0026#39;s safest to specify priors, even if equivalent to the defaults. ## - For execution on a local, multicore CPU with excess RAM we recommend calling ## options(mc.cores = parallel::detectCores()) lm1 \u0026lt;- stan_glm(mpg ~ hp, data = mtcars, refresh = 0) # um nicht zu viel R-Ausgabe zu erhalten print(lm1) ## stan_glm ## family: gaussian [identity] ## formula: mpg ~ hp ## observations: 32 ## predictors: 2 ## ------ ## Median MAD_SD ## (Intercept) 30.0 1.6 ## hp -0.1 0.0 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 3.9 0.5 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg Für den Prädiktor hp ist das Regressionsgewicht angegeben unter der Spalte median. Dieser Wert entspricht der Punktschätzung in der Population und ist identisch zum Regressiongewicht der Stichprobe.\nDie Spalte MAD_SD gibt den Standardfehler zur Schätzung des Koeffizienten (der entsprechenden Zeile) wieder.\nWelche Zahl kennzeichnet die Ungewissheit des Modells zum Achsenabschnitt? Welche Zahl kennzeichnet die Ungewissheit des Modells zum Regressionsgewicht? Welche Zahl(en) kennzeichnet/kennzeichnen die Ungewissheit des Modells gegeben der Modellparameter (die Ungewissheit innerhalb des Modells)?           \n Solution 1.7 0.0 3.9 und auch dazu 0.5  Categories:\n qm2 qm2-thema01 ws22   ","permalink":"https://datenwerk.netlify.app/post/ungewiss-arten-regr/ungewiss-arten-regr/","summary":"Exercise Eine statistische Analyse, wie eine Regression, ist mit mehreren Arten an Ungewissheit konfrontiert. Zum einen gibt es die Ungewissheit in den Modellparametern. Für die Regression bedeutet das: “Liegt die Regressionsgerade in”Wahrheit” (in der Population) genauso wie in der Stichprobe, sind Achsenabschnitt und Steigung in der Stichprobe also identisch zur Popuation?“. Zum anderen die Ungewissheit innerhalb des Modells. Auch wenn wir die”wahre” Regressionsgleichung kennen würden, wären (in aller Regel) die Vorhersagen trotzdem nicht perfekt.","title":"ungewiss-arten-regr"},{"content":"Datenwerk ist eine Sammlung von Statistik-Aufgaben.\nAutor: Sebastian Sauer\nDer Quellcode findet sich hier.\nDie Lizenz ist permissiv, s. Hinweise hier.\n","permalink":"https://datenwerk.netlify.app/about/","summary":"Datenwerk ist eine Sammlung von Statistik-Aufgaben.\nAutor: Sebastian Sauer\nDer Quellcode findet sich hier.\nDie Lizenz ist permissiv, s. Hinweise hier.","title":""}]